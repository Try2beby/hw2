{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c427152e-fb64-4fd2-a1d5-e14f848019aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T07:57:48.815737Z",
     "iopub.status.busy": "2024-02-21T07:57:48.815737Z",
     "iopub.status.idle": "2024-02-21T07:57:48.819684Z",
     "shell.execute_reply": "2024-02-21T07:57:48.819684Z",
     "shell.execute_reply.started": "2024-02-21T07:57:48.815737Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GitHub\\kg\\.conda\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import torch\n",
    "from fuzzywuzzy import fuzz\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "dataDir = \"../data/\"\n",
    "dataName = \"Deep Learning.pdf\"\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# openai.api_base = \"https://api.chatanywhere.com.cn/\"\n",
    "# openai.api_base = \"https://api.chatanywhere.tech\"\n",
    "# openai.api_key = \"sk-LzwgVgu5xvNPpwoqCdeeVcAt7Tu7ZoZICXzzkheldIbXA60h\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f4fef-8b2d-41ae-8af6-552e79070234",
   "metadata": {},
   "source": [
    "# 1. 获取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9e3a41-3514-4a05-ba63-0459ef06b1d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T07:33:37.177648Z",
     "iopub.status.busy": "2024-02-21T07:33:37.176648Z",
     "iopub.status.idle": "2024-02-21T07:35:17.816953Z",
     "shell.execute_reply": "2024-02-21T07:35:17.816953Z",
     "shell.execute_reply.started": "2024-02-21T07:33:37.176648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"bert-large-cased\", cache_dir=\"../../../BERT/large\"\n",
    ")\n",
    "model = BertModel.from_pretrained(\"bert-large-cased\", cache_dir=\"../../../BERT/large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fe0c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 26349, 1811, 145, 1115, 1195, 2234, 1111, 1412, 3622, 1104, 149, 1475, 2366, 2734, 117, 1195, 1525, 1115, 100, 134, 145, 178, 117, 178, 192, 119, 1409, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 100 words- nums tokens\n",
    "str_test = 'Hessian H that we introduced for our analysis of L1 regularization, we find that [UNK] = H i, i w. If' \n",
    "token_test = tokenizer(str_test)\n",
    "# print(len(str_test.split(' ')))\n",
    "# print(len(token_test['input_ids']))\n",
    "# print(tokenizer.decode(token_test['input_ids']))\n",
    "print(token_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c028cd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:964\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, labels, task_ids)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[1;32m--> 964\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    966\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model(token_test['input_ids'], token_test['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364fd41-4285-4f7d-bdee-b743a822c9de",
   "metadata": {},
   "source": [
    "# 2. 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6304d6-f72e-4c38-b3a2-5548ca3a6459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T07:06:59.601657Z",
     "iopub.status.busy": "2024-02-21T07:06:59.601657Z",
     "iopub.status.idle": "2024-02-21T07:08:29.596720Z",
     "shell.execute_reply": "2024-02-21T07:08:29.596720Z",
     "shell.execute_reply.started": "2024-02-21T07:06:59.601657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f267b29fa8fc4b339b3f9c821d1534af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pdfplumber.open(dataDir + dataName) as f:\n",
    "    # 目录架构生成\n",
    "    c, p, n = [], [], []\n",
    "    for i in range(7):\n",
    "        page = f.pages[i]\n",
    "        text = page.extract_text()\n",
    "        text_split = text.split(\"\\n\")\n",
    "        for i in text_split:\n",
    "            if bool(re.match(\"[0-9]+\\.[0-9]+\", i.split(\" \")[0])):\n",
    "                c.append(i.split(\" \")[0])\n",
    "                p.append(int(i.split(\" \")[-1]) + 15)\n",
    "            if bool(re.match(\"[0-9]+\", i.split(\" \")[0])):\n",
    "                for j in i.split(\" \"):\n",
    "                    if bool(re.match(\"[A-Za-z]+\", j)):\n",
    "                        n.append((i.split(\" \")[0], j))\n",
    "\n",
    "p_range = list(zip(p, p[1:]))\n",
    "p_range.append((735, 800))\n",
    "c_p_range = list(zip(c, p_range))\n",
    "index_dict = collections.defaultdict(list)\n",
    "for k, v in c_p_range:\n",
    "    index_dict[k.split(\".\")[0]].append((k, v))\n",
    "\n",
    "with pdfplumber.open(dataDir + dataName) as f:\n",
    "    content_dict = collections.defaultdict(list)\n",
    "\n",
    "    for k, v in tqdm(index_dict.items(), total=len(index_dict)):\n",
    "        for i in v:\n",
    "            page_range = i[-1]\n",
    "            if page_range[0] == page_range[1]:\n",
    "                page_range = (page_range[0], page_range[1] + 1)\n",
    "            for j in range(int(page_range[0]) - 1, int(page_range[1]) - 1):\n",
    "                page = f.pages[j]\n",
    "\n",
    "                text = page.extract_text().replace(\"\\n\", \" \")\n",
    "\n",
    "                content_dict[i[0]].append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb403b",
   "metadata": {},
   "source": [
    "# 3. 定义ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f8717b-9aa9-42ad-9c14-290092ff25b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T09:33:34.102084Z",
     "iopub.status.busy": "2024-02-21T09:33:34.102084Z",
     "iopub.status.idle": "2024-02-21T09:33:34.105930Z",
     "shell.execute_reply": "2024-02-21T09:33:34.105930Z",
     "shell.execute_reply.started": "2024-02-21T09:33:34.102084Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, conversation_list=[]):\n",
    "        self.conversation_list = conversation_list\n",
    "        self.costs_list = []\n",
    "\n",
    "    def show_conversation(self, msg_list):\n",
    "        for msg in msg_list[-2:]:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                pass\n",
    "            else:\n",
    "                message = msg[\"content\"]\n",
    "                pass\n",
    "                # print(f\"\\U0001f47D: {message}\\n\")\n",
    "\n",
    "    def ask(self, prompt):\n",
    "        self.conversation_list.append({\"role\": \"user\", \"content\": prompt})\n",
    "        openai.api_key = \"sk-LzwgVgu5xvNPpwoqCdeeVcAt7Tu7ZoZICXzzkheldIbXA60h\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\", messages=self.conversation_list\n",
    "        )\n",
    "        answer = response.choices[0].message[\"content\"]\n",
    "\n",
    "        self.conversation_list.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.show_conversation(self.conversation_list)\n",
    "\n",
    "        # cost = total_counts(response)\n",
    "        # self.costs_list.append(cost)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d68d24",
   "metadata": {},
   "source": [
    "# 4. 设计Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3640d992-d4e0-4de4-8209-7ecabd55e5da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T09:36:08.229147Z",
     "iopub.status.busy": "2024-02-21T09:36:08.228147Z",
     "iopub.status.idle": "2024-02-21T09:36:08.231752Z",
     "shell.execute_reply": "2024-02-21T09:36:08.231752Z",
     "shell.execute_reply.started": "2024-02-21T09:36:08.229147Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NER_prompt = f\"\"\"\n",
    "Role:\n",
    "You are a physical annotation specialist in deep learning\n",
    "\n",
    "Missions:\n",
    "Given a string, find all deep learning domain entities 4. If there are no deep learning domain entities, return ()\n",
    "\n",
    "Steps:\n",
    "Follow these steps:\n",
    "1. Identify all deep learning domain entities in the sentence\n",
    "2. Check whether the entities belong to the deep learning domain\n",
    "3. Return entities that belong to the deep learning domain\n",
    "4. If there is no entity in the deep learning domain, return ()\n",
    "\n",
    "格式：\n",
    "请以以下格式返回：\n",
    "(entity1, entity2, ...)\n",
    "\n",
    "举例如下：\n",
    "An illustration of how the gradient descent algorithm uses the derivatives of a function can be used to follow the function downhill to a minimum.\n",
    "(gradient descent algorithm)\n",
    "\n",
    "an encoder or reader or input RNN processes the input sequence. The encoder emits the context C, usually as a simple function of its final hidden state.\n",
    "(encoder, RNN, hidden state)\n",
    "\n",
    "There is no constraint that the encoder must have the same size of hidden layer as the decoder\n",
    "(hidden layer, decoder)\n",
    "\n",
    "Computer vision has traditionally been one of the most active research areas for deep learning applications, because vision is a task that is effortless for humans and many animals but challenging for computers (Ballard et al., 1983)\n",
    "(Computer vision, deep learning)\n",
    "\n",
    "Dataset augmentation may be seen as a way of preprocessing the training set only.\n",
    "(Dataset augmentation)\n",
    "\n",
    "CHAPTER 1. INTRODUCTION of the flowchart of the computations needed to compute the representation of each concept may be much deeper than the graph of the concepts themselves.\n",
    "()\n",
    "\n",
    "Note:\n",
    "1. Strictly follow the original statement in the string\n",
    "2. Do not return anything other than the result\n",
    "\n",
    "now, please find all deep learning domain entities in the following sentence:\n",
    "<<<sentence>>>\n",
    "<<<entity_list>>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6277d2bc-5c2b-4aa1-a604-fb4b825ae6f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T09:48:04.087938Z",
     "iopub.status.busy": "2024-02-21T09:48:04.087938Z",
     "iopub.status.idle": "2024-02-21T09:48:04.090724Z",
     "shell.execute_reply": "2024-02-21T09:48:04.090724Z",
     "shell.execute_reply.started": "2024-02-21T09:48:04.087938Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_prompt = f\"\"\"\n",
    "Missions:\n",
    "Please check whether the given entity belongs to the deep learning domain\n",
    "\n",
    "Format:\n",
    "Please return in the following format:\n",
    "Return True if the entity is in the deep learning domain, False otherwise\n",
    "\n",
    "举例如下：\n",
    "input: deep learning\n",
    "output: True\n",
    "\n",
    "input: AI system\n",
    "output: True\n",
    "\n",
    "input: image\n",
    "output: False\n",
    "\n",
    "input: Image Net\n",
    "output: True\n",
    "\n",
    "input: face\n",
    "output: False\n",
    "\n",
    "Note:\n",
    "1. Return only True or False and nothing else if the entity is in the deep learning domain, return True, otherwise return False\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ab818",
   "metadata": {},
   "source": [
    "# 5. 处理数据，获取sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d20474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_position(content_token, entity_token):\n",
    "    \"\"\"\n",
    "    Finds the position of an entity token within a content token.\n",
    "\n",
    "    Args:\n",
    "        content_token (torch.Tensor): A tensor representing the content token.\n",
    "        entity_token (torch.Tensor): A tensor representing the entity token.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor representing the position of the entity token within the content token.\n",
    "                      Each element in the tensor represents the position of a token in the content token:\n",
    "                      - 0: Token does not match the entity token.\n",
    "                      - 1: Token matches the entity token, but is not the first token.\n",
    "                      - 2: Token matches the entity token and is the first token.\n",
    "    \"\"\"\n",
    "    position = torch.zeros_like(content_token)\n",
    "    for entity in entity_token:\n",
    "        for i in range(len(content_token) - len(entity) + 1):\n",
    "            if torch.all(content_token[i : i + len(entity)] == entity):\n",
    "                position[i] = 2\n",
    "                position[i + 1 : i + len(entity)] = 1\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caabba2f-9476-43b1-8e7f-61c96d38080d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T10:45:57.615752Z",
     "iopub.status.busy": "2024-02-21T10:45:57.615752Z",
     "iopub.status.idle": "2024-02-21T10:49:32.176168Z",
     "shell.execute_reply": "2024-02-21T10:49:32.176168Z",
     "shell.execute_reply.started": "2024-02-21T10:45:57.615752Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_content(content_dict, content_list):\n",
    "    \"\"\"\n",
    "    Process the content dictionary to extract named entities and save them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        content_dict (dict): A dictionary containing the content to process.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for k, v in content_dict.items():\n",
    "        if k in content_list:\n",
    "            print(k + \":\", end=\"\\n\")\n",
    "            if total >= 1500:\n",
    "                break\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=100, chunk_overlap=20\n",
    "            )\n",
    "            docs = text_splitter.split_text(\" \".join(i for i in v))\n",
    "\n",
    "            # Process each document\n",
    "            for index, content in enumerate(docs):\n",
    "                total += 1\n",
    "                if total == 1500:\n",
    "                    break\n",
    "\n",
    "                # Initialize NER chatbot\n",
    "                if index % 5 == 0:\n",
    "                    conversation_list = [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": NER_prompt,\n",
    "                        }\n",
    "                    ]\n",
    "                    bot_ner = Chat(conversation_list)\n",
    "\n",
    "                # Extract named entities using NER chatbot\n",
    "                answer_ner = bot_ner.ask(\"input: \" + content)\n",
    "                entity_list_temp = re.sub(\"\\(|\\)|\", \"\", answer_ner).split(\", \")\n",
    "                # Initialize check chatbot\n",
    "                conversation_list = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": check_prompt,\n",
    "                    }\n",
    "                ]\n",
    "                bot_check = Chat(conversation_list)\n",
    "\n",
    "                entity_list = []\n",
    "                # Check if each entity is valid using check chatbot\n",
    "                for e in entity_list_temp:\n",
    "                    answer_check = bot_check.ask(\"input: \" + e)\n",
    "                    if answer_check == \"True\":\n",
    "                        entity_list.append(e)\n",
    "\n",
    "                if entity_list:\n",
    "                    # Tokenize content and entities\n",
    "                    content_token = tokenizer(content, return_tensors=\"pt\")[\n",
    "                        \"input_ids\"\n",
    "                    ].squeeze(0)\n",
    "                    entity_token = []\n",
    "                    for e in entity_list:\n",
    "                        entity_token.append(\n",
    "                            tokenizer(e, return_tensors=\"pt\")[\"input_ids\"].squeeze(0)[\n",
    "                                1:-1\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                    # Find position of entities in content\n",
    "                    label = find_position(content_token, entity_token)\n",
    "\n",
    "                    # Save the results to a CSV file\n",
    "                    df = pd.DataFrame(\n",
    "                        [\n",
    "                            [\n",
    "                                tokenizer.batch_decode(content_token),\n",
    "                                tokenizer.batch_decode(entity_token),\n",
    "                                label,\n",
    "                            ]\n",
    "                        ],\n",
    "                        columns=[\"text\", \"entity\", \"label\"],\n",
    "                    )\n",
    "                    df.to_csv(\n",
    "                        os.path.join(dataDir + \"/relations\", f\"sample.csv\"),\n",
    "                        mode=\"a\",\n",
    "                        header=not os.path.exists(\n",
    "                            os.path.join(dataDir + \"/relations\", f\"sample.csv\")\n",
    "                        ),\n",
    "                        index=False,\n",
    "                    )\n",
    "                    # Print the content, tokens, entity list, and label\n",
    "                    print(\n",
    "                        \"content: \" + str(content),\n",
    "                        \"content_token: \" + str(content_token),\n",
    "                        \"entity_list: \" + str(entity_list),\n",
    "                        \"entity_token: \" + str(entity_token),\n",
    "                        sep=\"\\n\",\n",
    "                    )\n",
    "                    print(\"label: \" + str(label))\n",
    "                    print(\n",
    "                        \"----------------------------------------------------------------------------------------------------------\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87cb9aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1:\n",
      "content: Chapter 12 Applications In this chapter, we describe how to use deep learning to solve applications\n",
      "content_token: tensor([  101,  2943,  1367, 20603,  1130,  1142,  6073,   117,  1195,  5594,\n",
      "         1293,  1106,  1329,  1996,  3776,  1106,  9474,  4683,   102])\n",
      "entity_list: ['deep learning']\n",
      "entity_token: [tensor([1996, 3776])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: solve applications in com- puter vision, speech recognition, natural language processing, and other\n",
      "content_token: tensor([ 101, 9474, 4683, 1107, 3254,  118, 1508, 1200, 4152,  117, 4055, 4453,\n",
      "         117, 2379, 1846, 6165,  117, 1105, 1168,  102])\n",
      "entity_list: ['computer vision', 'speech recognition', 'natural language processing']\n",
      "entity_token: [tensor([2775, 4152]), tensor([4055, 4453]), tensor([2379, 1846, 6165])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 1, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: and other application areas of commercial interest. We begin by discussing the large scale neural\n",
      "content_token: tensor([  101,  1105,  1168,  4048,  1877,  1104,  2595,  2199,   119,  1284,\n",
      "         3295,  1118, 10751,  1103,  1415,  3418, 18250,   102])\n",
      "entity_list: ['large scale neural']\n",
      "entity_token: [tensor([ 1415,  3418, 18250])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: Next, we review several specific application areas that deep learning has been used to solve. While\n",
      "content_token: tensor([ 101, 5893,  117, 1195, 3189, 1317, 2747, 4048, 1877, 1115, 1996, 3776,\n",
      "        1144, 1151, 1215, 1106, 9474,  119, 1799,  102])\n",
      "entity_list: ['deep learning']\n",
      "entity_token: [tensor([1996, 3776])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: to solve. While one goal of deep learning is to design algorithms that are capable of solving a\n",
      "content_token: tensor([  101,  1106,  9474,   119,  1799,  1141,  2273,  1104,  1996,  3776,\n",
      "         1110,  1106,  1902, 14975,  1115,  1132,  4451,  1104, 15097,   170,\n",
      "          102])\n",
      "entity_list: ['deep learning']\n",
      "entity_token: [tensor([1996, 3776])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of solving a broad variety of tasks, so far some degree of specialization is needed. For example,\n",
      "content_token: tensor([  101,  1104, 15097,   170,  4728,  2783,  1104,  8249,   117,  1177,\n",
      "         1677,  1199,  2178,  1104,  1957,  2734,  1110,  1834,   119,  1370,\n",
      "         1859,   117,   102])\n",
      "entity_list: ['deep learning']\n",
      "entity_token: [tensor([1996, 3776])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: (words in the vocabulary) per input feature. 12.1 Large-Scale Deep Learning Deep learning is based\n",
      "content_token: tensor([  101,   113,  1734,  1107,  1103, 18074,   114,  1679,  7758,  2672,\n",
      "          119,  1367,   119,   122, 10236,   118, 20334,  7786,  9681,  7786,\n",
      "         3776,  1110,  1359,   102])\n",
      "entity_list: ['deep learning']\n",
      "entity_token: [tensor([1996, 3776])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: must be large. One of the key factors responsible for the improvement in neural network’s accuracy\n",
      "content_token: tensor([  101,  1538,  1129,  1415,   119,  1448,  1104,  1103,  2501,  5320,\n",
      "         2784,  1111,  1103,  8331,  1107, 18250,  2443,   787,   188, 10893,\n",
      "          102])\n",
      "entity_list: ['neural network']\n",
      "entity_token: [tensor([18250,  2443])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: for the past three decades, yet artificial neural networks are only as large as the nervous systems\n",
      "content_token: tensor([  101,  1111,  1103,  1763,  1210,  4397,   117,  1870,  8246, 18250,\n",
      "         6379,  1132,  1178,  1112,  1415,  1112,  1103,  5604,  2344,   102])\n",
      "entity_list: ['artificial neural networks']\n",
      "entity_token: [tensor([ 8246, 18250,  6379])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: the nervous systems of insects. Because the size of neural networks is of paramount importance,\n",
      "content_token: tensor([  101,  1103,  5604,  2344,  1104,  9895,   119,  2279,  1103,  2060,\n",
      "         1104, 18250,  6379,  1110,  1104, 18311, 15364,  4495,   117,   102])\n",
      "entity_list: ['neural networks']\n",
      "entity_token: [tensor([18250,  6379])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: importance, deep learning 443 CHAPTER 12. APPLICATIONS requires high performance hardware and\n",
      "content_token: tensor([  101,  4495,   117,  1996,  3776,  3140,  1495,  8203,  1367,   119,\n",
      "        10997, 27258,  9741, 13821, 24805,  1708,  5315,  1344,  2099,  8172,\n",
      "         1105,   102])\n",
      "entity_list: ['deep learning']\n",
      "entity_token: [tensor([1996, 3776])]\n",
      "label: tensor([0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: hardware and software infrastructure. 12.1.1 Fast CPU Implementations Traditionally, neural\n",
      "content_token: tensor([  101,  8172,  1105,  3594,  6557,   119,  1367,   119,   122,   119,\n",
      "          122, 13227, 18701,   146, 26318, 18415,  1116, 19324,   117, 18250,\n",
      "          102])\n",
      "entity_list: ['deep learning']\n",
      "entity_token: [tensor([1996, 3776])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: neural networks were trained using the CPU of a single machine. Today, this approach is generally\n",
      "content_token: tensor([  101, 18250,  6379,  1127,  3972,  1606,  1103, 18701,  1104,   170,\n",
      "         1423,  3395,   119,  3570,   117,  1142,  3136,  1110,  2412,   102])\n",
      "entity_list: ['neural networks']\n",
      "entity_token: [tensor([18250,  6379])]\n",
      "label: tensor([0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: workload required by neural networks. A description of how to implement efficient numerical CPU\n",
      "content_token: tensor([  101,  1250,  9607,  2320,  1118, 18250,  6379,   119,   138,  6136,\n",
      "         1104,  1293,  1106, 10407,  7856, 18294, 18701,   102])\n",
      "entity_list: ['neural networks']\n",
      "entity_token: [tensor([18250,  6379])]\n",
      "label: tensor([0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: improvements. For example, in 2011, the best CPUs available could run neural network workloads\n",
      "content_token: tensor([  101,  8313,   119,  1370,  1859,   117,  1107,  1349,   117,  1103,\n",
      "         1436, 18701,  1116,  1907,  1180,  1576, 18250,  2443,  1250,  9607,\n",
      "         1116,   102])\n",
      "entity_list: ['neural network workloads']\n",
      "entity_token: [tensor([18250,  2443,  1250,  9607,  1116])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: is that careful specialization of numerical computation routines can yield a large payoff. Other\n",
      "content_token: tensor([  101,  1110,  1115,  5784,  1957,  2734,  1104, 18294,  3254, 19675,\n",
      "        27393,  1169, 10972,   170,  1415,  2653,  5792,   119,  2189,   102])\n",
      "entity_list: ['numerical computation routines']\n",
      "entity_token: [tensor([18294,  3254, 19675, 27393])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: instructions. Many machine learning researchers neglect these implementation details, but when the\n",
      "content_token: tensor([  101,  7953,   119,  2408,  3395,  3776,  6962, 21398,  1292,  7249,\n",
      "         4068,   117,  1133,  1165,  1103,   102])\n",
      "entity_list: ['machine learning researchers']\n",
      "entity_token: [tensor([3395, 3776, 6962])]\n",
      "label: tensor([0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: neural network implementations are based on graphics processing units. Graphics processing units\n",
      "content_token: tensor([  101, 18250,  2443,  7249,  1116,  1132,  1359,  1113,  9043,  6165,\n",
      "         2338,   119, 24318,  1116,  6165,  2338,   102])\n",
      "entity_list: ['neural network implementations']\n",
      "entity_token: [tensor([18250,  2443,  7249,  1116])]\n",
      "label: tensor([0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: processing units (GPUs) are specialized hardware components that were originally developed for\n",
      "content_token: tensor([  101,  6165,  2338,   113, 15175,  2591,  1116,   114,  1132,  7623,\n",
      "         8172,  5644,  1115,  1127,  2034,  1872,  1111,   102])\n",
      "entity_list: ['GPUs']\n",
      "entity_token: [tensor([15175,  2591,  1116])]\n",
      "label: tensor([0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: systems spurred development of graphics processing hardware. The performance characteristics needed\n",
      "content_token: tensor([  101,  2344, 26222,  1718,  1104,  9043,  6165,  8172,   119,  1109,\n",
      "         2099,  5924,  1834,   102])\n",
      "entity_list: ['graphics processing hardware']\n",
      "entity_token: [tensor([9043, 6165, 8172])]\n",
      "label: tensor([0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of 3-D coordinates of vertices. Graphics cards must perform matrix multiplication and division on\n",
      "content_token: tensor([  101,  1104,   124,   118,   141, 12570,  1104, 20803,   119, 24318,\n",
      "         1116,  4802,  1538,  3870,  8952,  4321, 15534,  1105,  2417,  1113,\n",
      "          102])\n",
      "entity_list: ['matrix multiplication']\n",
      "entity_token: [tensor([ 8952,  4321, 15534])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: and division on many vertices in parallel to convert these 3-D coordinates into 2-D on-screen\n",
      "content_token: tensor([  101,  1105,  2417,  1113,  1242, 20803,  1107,  5504,  1106, 10454,\n",
      "         1292,   124,   118,   141, 12570,  1154,   123,   118,   141,  1113,\n",
      "          118,  3251,   102])\n",
      "entity_list: ['parallel computation']\n",
      "entity_token: [tensor([ 5504,  3254, 19675])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: relative to traditional CPUs. Neural network algorithms require the same performance\n",
      "content_token: tensor([  101,  5236,  1106,  2361, 18701,  1116,   119,   151,  8816,  1348,\n",
      "         2443, 14975,  4752,  1103,  1269,  2099,   102])\n",
      "entity_list: ['Neural network algorithms']\n",
      "entity_token: [tensor([  151,  8816,  1348,  2443, 14975])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: above. Neural networks usually involve large and numerous buffers of parameters, activation values,\n",
      "content_token: tensor([  101,  1807,   119,   151,  8816,  1348,  6379,  1932,  8803,  1415,\n",
      "         1105,  2567, 20232,  1116,  1104, 11934,   117, 14915,  4718,   117,\n",
      "          102])\n",
      "entity_list: ['Neural networks']\n",
      "entity_token: [tensor([ 151, 8816, 1348, 6379])]\n",
      "label: tensor([0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: often becomes the rate limiting factor. GPUs offer a compelling advantage over CPUs due to their\n",
      "content_token: tensor([  101,  1510,  3316,  1103,  2603, 15816,  5318,   119, 15175,  2591,\n",
      "         1116,  2906,   170, 18397,  4316,  1166, 18701,  1116,  1496,  1106,\n",
      "         1147,   102])\n",
      "entity_list: ['GPUs']\n",
      "entity_token: [tensor([15175,  2591,  1116])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: CPUs due to their high memory bandwidth. Neural network training algorithms typically do not\n",
      "content_token: tensor([  101, 18701,  1116,  1496,  1106,  1147,  1344,  2962, 22965,   119,\n",
      "          151,  8816,  1348,  2443,  2013, 14975,  3417,  1202,  1136,   102])\n",
      "entity_list: ['neural network training algorithms']\n",
      "entity_token: [tensor([18250,  2443,  2013, 14975])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: typically do not involve much branching or sophisticated control, so they are appropriate for GPU\n",
      "content_token: tensor([  101,  3417,  1202,  1136,  8803,  1277, 27021,  1137, 12580,  1654,\n",
      "          117,  1177,  1152,  1132,  5806,  1111, 15175,  2591,   102])\n",
      "entity_list: ['GPU']\n",
      "entity_token: [tensor([15175,  2591])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: appropriate for GPU hardware. Since neural networks can be divided into multiple individual\n",
      "content_token: tensor([  101,  5806,  1111, 15175,  2591,  8172,   119,  1967, 18250,  6379,\n",
      "         1169,  1129,  3233,  1154,  2967,  2510,   102])\n",
      "entity_list: ['GPU hardware']\n",
      "entity_token: [tensor([15175,  2591,  8172])]\n",
      "label: tensor([0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: neurons in the same layer, neural networks easily benefit from the parallelism of GPU computing.\n",
      "content_token: tensor([  101, 16993,  1107,  1103,  1269,  6440,   117, 18250,  6379,  3253,\n",
      "         5257,  1121,  1103,  5504,  1863,  1104, 15175,  2591, 12783,   119,\n",
      "          102])\n",
      "entity_list: ['neural networks', 'GPU computing']\n",
      "entity_token: [tensor([18250,  6379]), tensor([15175,  2591, 12783])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of GPU computing. GPU hardware was originally so specialized that it could only be used for\n",
      "content_token: tensor([  101,  1104, 15175,  2591, 12783,   119, 15175,  2591,  8172,  1108,\n",
      "         2034,  1177,  7623,  1115,  1122,  1180,  1178,  1129,  1215,  1111,\n",
      "          102])\n",
      "entity_list: ['GPU computing', 'GPU hardware']\n",
      "entity_token: [tensor([15175,  2591, 12783]), tensor([15175,  2591,  8172])]\n",
      "label: tensor([0, 0, 2, 1, 1, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: values actually be based on a rendering task. These GPUs could be used for scientific computing by\n",
      "content_token: tensor([  101,  4718,  2140,  1129,  1359,  1113,   170, 15171,  4579,   119,\n",
      "         1636, 15175,  2591,  1116,  1180,  1129,  1215,  1111,  3812, 12783,\n",
      "         1118,   102])\n",
      "entity_list: ['GPUs']\n",
      "entity_token: [tensor([15175,  2591,  1116])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: Steinkrau et al. (2005) implemented a two-layer fully connected neural network on a GPU and\n",
      "content_token: tensor([  101, 14981, 27311,  1358,  3084,  2393,   119,   113,  1478,   114,\n",
      "         7042,   170,  1160,   118,  6440,  3106,  3387, 18250,  2443,  1113,\n",
      "          170, 15175,  2591,  1105,   102])\n",
      "entity_list: ['fully connected neural network']\n",
      "entity_token: [tensor([ 3106,  3387, 18250,  2443])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: on a GPU and reported a threefold speedup over their CPU-based baseline. Shortly thereafter,\n",
      "content_token: tensor([  101,  1113,   170, 15175,  2591,  1105,  2103,   170,  1210, 10787,\n",
      "         2420,  4455,  1166,  1147, 18701,   118,  1359,  2259,  2568,   119,\n",
      "         6480,  7321,   117,   102])\n",
      "entity_list: ['GPU']\n",
      "entity_token: [tensor([15175,  2591])]\n",
      "label: tensor([0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: could be used to accelerate supervised convolutional networks. The popularity of graphics cards for\n",
      "content_token: tensor([  101,  1180,  1129,  1215,  1106, 26872, 14199, 14255,  6005, 18404,\n",
      "         1348,  6379,   119,  1109,  5587,  1104,  9043,  4802,  1111,   102])\n",
      "entity_list: ['supervised convolutional networks']\n",
      "entity_token: [tensor([14199, 14255,  6005, 18404,  1348,  6379])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: graphics cards for neural network training exploded after the advent of general purpose GPUs. These\n",
      "content_token: tensor([  101,  9043,  4802,  1111, 18250,  2443,  2013,  9736,  1170,  1103,\n",
      "        16889,  1104,  1704,  3007, 15175,  2591,  1116,   119,  1636,   102])\n",
      "entity_list: ['neural network training', 'general purpose GPUs']\n",
      "entity_token: [tensor([18250,  2443,  2013]), tensor([ 1704,  3007, 15175,  2591,  1116])]\n",
      "label: tensor([0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: NVIDIA’s CUDA programming language provided a way to write this arbitrary code in a C-like\n",
      "content_token: tensor([  101,   151, 23314, 17243,  1592,   787,   188,   140,  2591, 11392,\n",
      "         4159,  1846,  2136,   170,  1236,  1106,  3593,  1142, 16439,  3463,\n",
      "         1107,   170,   140,   118,  1176,   102])\n",
      "entity_list: ['CUDA']\n",
      "entity_token: [tensor([  140,  2591, 11392])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: now offer an ideal platform for neural network programming. This platform was rapidly adopted by\n",
      "content_token: tensor([  101,  1208,  2906,  1126,  7891,  3482,  1111, 18250,  2443,  4159,\n",
      "          119,  1188,  3482,  1108,  5223,  3399,  1118,   102])\n",
      "entity_list: ['neural network programming']\n",
      "entity_token: [tensor([18250,  2443,  4159])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: good performance on GPU are very different from those used on CPU. For example, good CPU-based code\n",
      "content_token: tensor([  101,  1363,  2099,  1113, 15175,  2591,  1132,  1304,  1472,  1121,\n",
      "         1343,  1215,  1113, 18701,   119,  1370,  1859,   117,  1363, 18701,\n",
      "          118,  1359,  3463,   102])\n",
      "entity_list: ['GPU']\n",
      "entity_token: [tensor([15175,  2591])]\n",
      "label: tensor([0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of a single memory transaction. Different models of GPUs are able to coalesce different kinds of\n",
      "content_token: tensor([  101,  1104,   170,  1423,  2962, 13618,   119, 14380,  3584,  1104,\n",
      "        15175,  2591,  1116,  1132,  1682,  1106,  5289,  1279,  2093,  1472,\n",
      "         7553,  1104,   102])\n",
      "entity_list: ['GPUs']\n",
      "entity_token: [tensor([15175,  2591,  1116])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: a multiple of some power of 2. The exact specifications differ between models of GPU. Another\n",
      "content_token: tensor([  101,   170,  2967,  1104,  1199,  1540,  1104,   123,   119,  1109,\n",
      "         6129, 17285, 11271,  1206,  3584,  1104, 15175,  2591,   119,  2543,\n",
      "          102])\n",
      "entity_list: ['GPU']\n",
      "entity_token: [tensor([15175,  2591])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of GPU. Another common consideration for GPUs is making sure that each thread in a group executes\n",
      "content_token: tensor([  101,  1104, 15175,  2591,   119,  2543,  1887,  9486,  1111, 15175,\n",
      "         2591,  1116,  1110,  1543,  1612,  1115,  1296, 12473,  1107,   170,\n",
      "         1372, 16621,  1116,   102])\n",
      "entity_list: ['GPU']\n",
      "entity_token: [tensor([15175,  2591])]\n",
      "label: tensor([0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: can be difficult on GPU. Threads are divided into small groups called warps. Each thread in a warp\n",
      "content_token: tensor([  101,  1169,  1129,  2846,  1113, 15175,  2591,   119,   157,  8167,\n",
      "        12393,  1116,  1132,  3233,  1154,  1353,  2114,  1270,  1594,  3491,\n",
      "          119,  2994, 12473,  1107,   170,  1594,  1643,   102])\n",
      "entity_list: ['GPU']\n",
      "entity_token: [tensor([15175,  2591])]\n",
      "label: tensor([0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of writing high performance GPU code, researchers should structure their workflow to avoid needing\n",
      "content_token: tensor([  101,  1104,  2269,  1344,  2099, 15175,  2591,  3463,   117,  6962,\n",
      "         1431,  2401,  1147,  1250, 12712,  1106,  3644, 12038,   102])\n",
      "entity_list: ['GPU code']\n",
      "entity_token: [tensor([15175,  2591,  3463])]\n",
      "label: tensor([0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: to avoid needing to write new GPU code in order to test new models or algorithms. Typically, one\n",
      "content_token: tensor([  101,  1106,  3644, 12038,  1106,  3593,  1207, 15175,  2591,  3463,\n",
      "         1107,  1546,  1106,  2774,  1207,  3584,  1137, 14975,   119, 16304,\n",
      "          117,  1141,   102])\n",
      "entity_list: ['GPU code']\n",
      "entity_token: [tensor([15175,  2591,  3463])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: operations like convolution and matrix multiplication, then specifying models in terms of calls to\n",
      "content_token: tensor([  101,  2500,  1176, 14255,  6005, 18404,  1105,  8952,  4321, 15534,\n",
      "          117,  1173, 22829,  1158,  3584,  1107,  2538,  1104,  3675,  1106,\n",
      "          102])\n",
      "entity_list: ['convolution']\n",
      "entity_token: [tensor([14255,  6005, 18404])]\n",
      "label: tensor([0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: terms of calls to this library of operations. For example, the machine learning library Pylearn2\n",
      "content_token: tensor([  101,  2538,  1104,  3675,  1106,  1142,  3340,  1104,  2500,   119,\n",
      "         1370,  1859,   117,  1103,  3395,  3776,  3340,   153, 12415,  1813,\n",
      "         1179,  1477,   102])\n",
      "entity_list: ['machine learning library', 'Pylearn2']\n",
      "entity_token: [tensor([3395, 3776, 3340]), tensor([  153, 12415,  1813,  1179,  1477])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 2, 1, 1, 1, 1, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: library Pylearn2 (Goodfellow et al., 2013c) specifies all of its machine learning algorithms in\n",
      "content_token: tensor([  101,  3340,   153, 12415,  1813,  1179,  1477,   113,  2750, 27610,\n",
      "         4064,  3084,  2393,   119,   117,  1381,  1665,   114,   188, 25392,\n",
      "         9387,  1155,  1104,  1157,  3395,  3776, 14975,  1107,   102])\n",
      "entity_list: ['Pylearn2']\n",
      "entity_token: [tensor([  153, 12415,  1813,  1179,  1477])]\n",
      "label: tensor([0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: algorithms in terms of calls to Theano (Bergstra et al., 2010; Bastien et al., 2012) and\n",
      "content_token: tensor([  101, 14975,  1107,  2538,  1104,  3675,  1106,  1109,  7428,   113,\n",
      "        16218, 16468,  3084,  2393,   119,   117,  1333,   132, 18757,  2050,\n",
      "         8584,  3084,  2393,   119,   117,  1368,   114,  1105,   102])\n",
      "entity_list: ['Theano']\n",
      "entity_token: [tensor([1109, 7428])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of hardware. For example, the same Theano program can run on either CPU or GPU, without needing to\n",
      "content_token: tensor([  101,  1104,  8172,   119,  1370,  1859,   117,  1103,  1269,  1109,\n",
      "         7428,  1788,  1169,  1576,  1113,  1719, 18701,  1137, 15175,  2591,\n",
      "          117,  1443, 12038,  1106,   102])\n",
      "entity_list: ['theano']\n",
      "entity_token: [tensor([1103, 7428])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: without needing to change any of the calls to Theano itself. Other libraries like TensorFlow (Abadi\n",
      "content_token: tensor([  101,  1443, 12038,  1106,  1849,  1251,  1104,  1103,  3675,  1106,\n",
      "         1109,  7428,  2111,   119,  2189,  9818,  1176,  5157, 21484,  2271,\n",
      "         6737,   113,   138,  8330,  1182,   102])\n",
      "entity_list: ['Theano', 'TensorFlow']\n",
      "entity_token: [tensor([1109, 7428]), tensor([ 5157, 21484,  2271,  6737])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: TensorFlow (Abadi et al., 2015) and Torch (Collobert et al., 2011b) provide similar features. 446\n",
      "content_token: tensor([  101,  5157, 21484,  2271,  6737,   113,   138,  8330,  1182,  3084,\n",
      "         2393,   119,   117,  1410,   114,  1105, 19928,  1732,   113,  9518,\n",
      "         2858,  7488,  3084,  2393,   119,   117,  1349,  1830,   114,  2194,\n",
      "         1861,  1956,   119,  3140,  1545,   102])\n",
      "entity_list: ['TensorFlow', 'Torch']\n",
      "entity_token: [tensor([ 5157, 21484,  2271,  6737]), tensor([19928,  1732])]\n",
      "label: tensor([0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: insufficient. We therefore want to distribute the workload of training and inference across many\n",
      "content_token: tensor([  101, 14733,   119,  1284,  3335,  1328,  1106, 17114,  1103,  1250,\n",
      "         9607,  1104,  2013,  1105,  1107, 16792,  1506,  1242,   102])\n",
      "entity_list: ['training', 'inference']\n",
      "entity_token: [tensor([2013]), tensor([ 1107, 16792])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: example we want to process can be run by a separate machine. This is known as data parallelism. It\n",
      "content_token: tensor([ 101, 1859, 1195, 1328, 1106, 1965, 1169, 1129, 1576, 1118,  170, 2767,\n",
      "        3395,  119, 1188, 1110, 1227, 1112, 2233, 5504, 1863,  119, 1135,  102])\n",
      "entity_list: ['data parallelism']\n",
      "entity_token: [tensor([2233, 5504, 1863])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: parallelism. It is also possible to get model parallelism, where multiple machines work together on\n",
      "content_token: tensor([ 101, 5504, 1863,  119, 1135, 1110, 1145, 1936, 1106, 1243, 2235, 5504,\n",
      "        1863,  117, 1187, 2967, 6555, 1250, 1487, 1113,  102])\n",
      "entity_list: ['model parallelism']\n",
      "entity_token: [tensor([2235, 5504, 1863])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: work together on a single datapoint, with each machine running a different part of the model. This\n",
      "content_token: tensor([ 101, 1250, 1487, 1113,  170, 1423, 2233, 7587,  117, 1114, 1296, 3395,\n",
      "        1919,  170, 1472, 1226, 1104, 1103, 2235,  119, 1188,  102])\n",
      "entity_list: ['model parallelism']\n",
      "entity_token: [tensor([2235, 5504, 1863])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of the model. This is feasible for both inference and training. Data parallelism during training is\n",
      "content_token: tensor([  101,  1104,  1103,  2235,   119,  1188,  1110, 25667,  1111,  1241,\n",
      "         1107, 16792,  1105,  2013,   119,  7154,  5504,  1863,  1219,  2013,\n",
      "         1110,   102])\n",
      "entity_list: ['training', 'data parallelism']\n",
      "entity_token: [tensor([2013]), tensor([2233, 5504, 1863])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: during training is somewhat harder. We can increase the size of the minibatch used for a single SGD\n",
      "content_token: tensor([  101,  1219,  2013,  1110,  4742,  5747,   119,  1284,  1169,  2773,\n",
      "         1103,  2060,  1104,  1103,  8715, 14602,  1732,  1215,  1111,   170,\n",
      "         1423,   156,  2349,  2137,   102])\n",
      "entity_list: ['minibatch', 'SGD']\n",
      "entity_token: [tensor([ 8715, 14602,  1732]), tensor([ 156, 2349, 2137])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 2, 1, 1,\n",
      "        0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: to compute multiple gradient descent steps in parallel. Unfortunately, the standard definition of\n",
      "content_token: tensor([  101,  1106,  3254, 22662,  2967, 19848,  6585,  3343,  1107,  5504,\n",
      "          119,  7595,   117,  1103,  2530,  5754,  1104,   102])\n",
      "entity_list: ['gradient descent']\n",
      "entity_token: [tensor([19848,  6585])]\n",
      "label: tensor([0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: definition of gradient descent is as a completely sequential algorithm: the gradient at step t is a\n",
      "content_token: tensor([  101,  5754,  1104, 19848,  6585,  1110,  1112,   170,  2423, 14516,\n",
      "        21967,  9932,   131,  1103, 19848,  1120,  2585,   189,  1110,   170,\n",
      "          102])\n",
      "entity_list: ['gradient descent']\n",
      "entity_token: [tensor([19848,  6585])]\n",
      "label: tensor([0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 23 is out of bounds for dimension 0 with size 23",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m content_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12.1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mprocess_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 69\u001b[0m, in \u001b[0;36mprocess_content\u001b[1;34m(content_dict, content_list)\u001b[0m\n\u001b[0;32m     64\u001b[0m     entity_token\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     65\u001b[0m         tokenizer(e, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     66\u001b[0m     )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Find position of entities in content\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[43mfind_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Save the results to a CSV file\u001b[39;00m\n\u001b[0;32m     72\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     73\u001b[0m     [\n\u001b[0;32m     74\u001b[0m         [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     81\u001b[0m )\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36mfind_position\u001b[1;34m(content_token, entity_token)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(content_token) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(entity) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(content_token[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(entity)] \u001b[38;5;241m==\u001b[39m entity):\n\u001b[1;32m---> 20\u001b[0m             \u001b[43mposition\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     21\u001b[0m             position[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(entity)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m position\n",
      "\u001b[1;31mIndexError\u001b[0m: index 23 is out of bounds for dimension 0 with size 23"
     ]
    }
   ],
   "source": [
    "content_list = [\"12.1\"]\n",
    "process_content(content_dict, content_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
