{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from TorchCRF import CRF\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import deque, defaultdict\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 加载BERT-large模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"bert-large-cased\", cache_dir=\"../../../BERT/large\"\n",
    ")\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-large-cased\", cache_dir=\"../../../BERT/large\")\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = torch.nn.Linear\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForTokenClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 1024)\n",
       "        (token_type_embeddings): Embedding(2, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = find_all_linear_names(model)\n",
    "config = LoraConfig(r=16,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        target_modules=['query', 'value'],\n",
    "        task_type=\"TOKEN_CLS\",\n",
    "    )\n",
    "lora_model = get_peft_model(model, config)\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.572864\n"
     ]
    }
   ],
   "source": [
    "# 模型大小\n",
    "print(sum(i.numel() for i in lora_model.parameters() if i.requires_grad) / 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './relations/sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./relations/sample.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[:]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m8\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m )\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './relations/sample.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./relations/sample.csv\")\n",
    "df = df[df['entity'].str[:]!='[]']\n",
    "df[\"label\"] = df[\"label\"].apply(\n",
    "    lambda x: x[8:-2].replace(\"\\n\", \"\").replace(\" \", \"\").split(\",\")\n",
    ")\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: [int(i) for i in x])\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: x[2:-2].split(\"', '\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 创建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data[\"text\"][index]\n",
    "        labels = self.data[\"label\"][index][1:-1]\n",
    "\n",
    "        # Convert tokens to token IDs\n",
    "        tokens = [i.replace(\" \", \"\") for i in text][1:-1]\n",
    "\n",
    "        return tokens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. 创建数据整理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenizer(input_text, max_len=50):\n",
    "    res = defaultdict(list)\n",
    "    max_len -= 2\n",
    "    for text in input_text:\n",
    "        ids = tokenizer.convert_tokens_to_ids(text)\n",
    "        valid_len = len(ids) + 2\n",
    "        if len(ids) > max_len:\n",
    "            ids = ids[:max_len]\n",
    "            ids = [101] + ids + [102]\n",
    "            attention_mask = [1] * (max_len + 2)\n",
    "        else:\n",
    "            ids = [101] + ids + [102] + [0] * (max_len - len(ids))\n",
    "            attention_mask = [1] * valid_len + [0] * (max_len - valid_len + 2)\n",
    "        res['input_ids'].append(ids)\n",
    "        res['attention_mask'].append(attention_mask)\n",
    "    res['input_ids'] = torch.tensor(res['input_ids']).to(device)\n",
    "    res['attention_mask'] = torch.tensor(res['attention_mask']).to(device)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据整理函数\n",
    "def collate_fn(data):\n",
    "    tokens = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "    inputs = batch_tokenizer(tokens)\n",
    "\n",
    "    lens = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = [3] + labels[i]\n",
    "        labels[i] += [3] * lens\n",
    "        labels[i] = labels[i][:lens]\n",
    "\n",
    "    return inputs, torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. 拆分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training dataset and dataloader\n",
    "train_dataset = NERDataset(train_df.reset_index(), tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# Create the validation dataset and dataloader\n",
    "val_dataset = NERDataset(val_df.reset_index(), tokenizer)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 1024])\n"
     ]
    }
   ],
   "source": [
    "# 模型试算\n",
    "for i, j in train_dataloader:\n",
    "    print(lora_model(i['input_ids'], i['attention_mask']).last_hidden_state.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 搭建微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义下游模型\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super().__init__()\n",
    "        self.pretrained = pretrained\n",
    "        self.hidden_size = deque(pretrained.parameters())[-1].shape[0]\n",
    "        self.fc1 = torch.nn.Linear(self.hidden_size, int(self.hidden_size / 2))\n",
    "        self.swish = torch.nn.SiLU()\n",
    "        self.fc2 = torch.nn.Linear(int(self.hidden_size / 2), 4)\n",
    "        self.crf = CRF(num_tags=4, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        with torch.no_grad():\n",
    "            out = self.pretrained(**inputs).last_hidden_state\n",
    "\n",
    "        out = self.fc2(self.swish(self.fc1(out))).softmax(dim=2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def loss(self, inputs, labels):\n",
    "        with torch.no_grad():\n",
    "            out = self.pretrained(**inputs).last_hidden_state\n",
    "\n",
    "        out = self.fc2(self.swish(self.fc1(out))).softmax(dim=2)\n",
    "        loss = -self.crf(\n",
    "            out, labels, inputs[\"attention_mask\"].to(torch.bool), reduction=\"mean\"\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "mymodel = Model(lora_model)\n",
    "mymodel = mymodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09974\n"
     ]
    }
   ],
   "source": [
    "print(sum(i.numel() for i in mymodel.parameters() if i.requires_grad) / 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对计算结果和label变形,并且移除pad\n",
    "def reshape_and_remove_pad(outs, labels, attention_mask):\n",
    "    # 变形,便于计算loss\n",
    "    # [b, lens, 8] -> [b*lens, 8]\n",
    "    outs = outs.reshape(-1, 4)\n",
    "    # [b, lens] -> [b*lens]\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    # 忽略对pad的计算结果\n",
    "    # [b, lens] -> [b*lens - pad]\n",
    "    select = attention_mask.reshape(-1) == 1\n",
    "    outs = outs[select]\n",
    "    labels = labels[select]\n",
    "\n",
    "    return outs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取正确数量和总数\n",
    "def get_correct_and_total_count(labels, outs):\n",
    "    # [b*lens, 8] -> [b*lens]\n",
    "    outs = outs.argmax(dim=1)\n",
    "    correct = (outs == labels).sum().item()\n",
    "    total = len(labels)\n",
    "\n",
    "    # 计算除了0以外元素的正确率,因为0太多了,包括的话,正确率很容易虚高\n",
    "    select = labels != 0\n",
    "    outs = outs[select]\n",
    "    labels = labels[select]\n",
    "    correct_content = (outs == labels).sum().item()\n",
    "    total_content = len(labels)\n",
    "\n",
    "    return correct, total, correct_content, total_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "def train(loader, epochs, model=None, optimizer=None, scheduler=None):\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # 训练\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    mymodel.train()\n",
    "    i = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for step, (inputs, labels) in tqdm(\n",
    "            enumerate(loader), desc=\"Epoch\" + str(epoch + 1), total=len(loader)\n",
    "        ):\n",
    "            i += 1\n",
    "            optimizer.zero_grad()\n",
    "            labels = labels.to(device)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outs = model(inputs)\n",
    "            loss = model.loss(inputs, labels)\n",
    "            writer.add_scalar(\"Loss/train\", loss, i)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            outs, labels = reshape_and_remove_pad(\n",
    "                outs, labels=labels, attention_mask=inputs[\"attention_mask\"]\n",
    "            )\n",
    "            counts = get_correct_and_total_count(labels, outs)\n",
    "\n",
    "            accuracy = counts[0] / counts[1]\n",
    "            accuracy_content = counts[2] / counts[3]\n",
    "\n",
    "            writer.add_scalar(\"accuracy/train\", accuracy, i)\n",
    "            writer.add_scalar(\"true_accuracy/train\", accuracy_content, i)\n",
    "        if scheduler is not None:\n",
    "            print(\"lr: \", optimizer.param_groups[0][\"lr\"])\n",
    "            scheduler.step()\n",
    "        torch.save(model.state_dict(), \"../../../BERT/NER_FT/NER_FT.pkl\")\n",
    "        torch.save(optimizer.state_dict(), \"../../../BERT/NER_FT/NER_FT_optimizer.pkl\")\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Hessian H that we introduced for our analysis of L1 regularization, we find that [UNK] = H i, i w. If [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS].......... L1 regularization............. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] ( Krizhevsky et al., 2012 ; Ioffe and Szegedy, 2015 ). Object recognition is the same basic technology [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]............................... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] decrease by various amounts. However, empirical risk minimization is prone to overfitting. Models [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]....... empirical risk minimization........ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] often becomes the rate limiting factor. GPUs offer a compelling advantage over CPUs due to their [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]....... GPUs.......... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] on convolution with kernel flipping will learn a kernel that is flipped relative to the kernel [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]. convolution.............. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] values. We must also design the architecture of the network, including how many layers the network [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]............... layers.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] examples and few labeled examples was made particularly clear in 2011 with unsupervised pretraining [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]............ unsupervised pretraining [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] as an average over the training set, such as J ( θ ) = E L ( f ( x ; θ ), y ), ( 8. 1 ) ( x, y ) [UNK] data [UNK] where L is [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]..... training set..................................... [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] gradient in this setting is given by [UNK] ( w ) = H ( w w ), ( 7. 21 ) w ∗ [UNK] − where, again, H is the Hessian [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS].................................. Hessian [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] phase, using early stopping on the unsupervised objective, which is not ideal but computationally [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]... early stopping.. unsupervised objective........ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] the differences between L1 and L2 forms 2As with L2 regularization, we could regularize the [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]............ L2 regularization...... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] graph. The unfolded computational graph of equation 10. 1 and equation 10. 3 is illustrated in figure [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS].... computational graph.............. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] are more likely to generalize ( to have a small gap between training and test error ) we must still [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]..................... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] correct? When performing a regression task, should we penalize the system more if it frequently [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]..... regression task............ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] In other 2 2 academic communities, L2 regularization is also known as ridge regression or [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]....... L2 regularization.... ridge regression. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] renewed interested in deep neural networks starting in 2006 ( Hinton et al., 529 CHAPTER 15. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]... deep neural networks............... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] hyperparameters. The performance of the second phase usually cannot be predicted during the first [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] hyperparameters.............. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] much variance by leaving the biases unregularized. Also, regularizing the bias parameters can [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]..................... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] first pass, each minibatch is used to compute an unbiased estimate of the true generalization [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS].... minibatch............... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] that is higher if the event to be detected occurred. For example, a feedforward 423 CHAPTER 11. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]............... feedforward..... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] a binary classifier that is intended to detect some rare event. For example, we might design a [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]. binary classifier................ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] “ batch gradient descent ” implies the use of the full training set, while the use of the term [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS].......... full training set....... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] of task is similar to → classification, except that the format of output is different. An example [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]...... classification............ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] well from a finite training set of examples. This seems to contradict some basic principles of [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS].... training set............. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] of writing high performance GPU code, researchers should structure their workflow to avoid needing [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS].... GPU code.......... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] Optimization algorithms used for training of deep models differ from traditional optimization [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] Optimization algorithms.. training. deep models.... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n",
      "[CLS] the best function within this family is a very difficult optimization problem. In practice, the [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS]................. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "# 检查训练数据\n",
    "for i, j in train_dataloader:\n",
    "    print(tokenizer.decode(i['input_ids'][0]))\n",
    "    list_a = []\n",
    "    for t in range(len(j[0])):\n",
    "        if j[0][t]!=0:\n",
    "            list_a.append(i['input_ids'][0][t])\n",
    "        else:\n",
    "            list_a.append(119)\n",
    "    print(tokenizer.decode(list_a))\n",
    "    print('===================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c1f8603d1a4dde96929f5800006838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch1:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54798b65527b4c54b9dfd31cc817e997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch2:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009997532801828658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46deb2efa02b47faa93243f868a5fb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch3:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009990133642141358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159f8065728346cd91bb2a3be5417a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch4:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00099778098230154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffe81a38f824806b1d53e8b3df5c8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch5:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.000996057350657239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de453b5840a84d439bb9e2cebca2beda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch6:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009938441702975688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e497a3be4c417ba715bd1b87ca6458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch7:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009911436253643444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbd3ea061af413dac6eef880720a400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch8:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009879583809693736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fa6a7d808c4dfe91f4e6f888e9f748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch9:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009842915805643154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a96131ae164c639094c8e75e5b2544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch10:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009801468428384714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5950856e029543b58680bc4047ec1a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch11:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009755282581475767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a8a46bd92f430bbc817f13d5300a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch12:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009704403844771127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa457e3b4d6945a0b83a2bf0dbf212b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch13:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009648882429441257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1261f4e650ed47b19f2c4f38ba7dd3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch14:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009588773128419905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2f1597822044008f85b1fa0b7f46e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch15:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009524135262330098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a81b9fc88d46149a20502b0356bc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch16:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009455032620941839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e993e1151444bc1a31c9c80e191028f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch17:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009381533400219318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f25f3a438e47e28f4ee8d8aef42f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch18:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009303710135019719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87b44b4eefb455895c3d7417f1e8219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch19:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009221639627510076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fef9af8bf043f4b414865640c85d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch20:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.000913540287137281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0785368b91d64241979abbfd6b3bdb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch21:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0009045084971874739\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22761c87af24491a4fce79be124a85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch22:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0008950775061878453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141e647398d4403ba64312f2538e765a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch23:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0008852566213878948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c640c7d96cf4a1489d8b3ae0bdfc5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch24:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0008750555348152299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc0ee88360f4d749b6c050a2c827019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch25:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0008644843137107058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb0cb0e6a4e40fa8ada706e69d0f12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch26:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0008535533905932738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7720fbd5f85a4454b4593bc3652d9856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch27:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0008422735529643445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217b5647e875409794ec5c992faa9888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch28:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.000830655932661826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dfa319d5b14bef9a8815144eafd018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch29:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.000818711994874345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8c9d1cbe07493a869312b0a1b1db06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch30:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0008064535268264884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23ee4304a9a480d935f3918cd97cc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch31:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0007938926261462368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a6b9091b3e4e6e90f1693de7119233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch32:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0007810416889260655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2637cb0d574bfda2eab484f4a22c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch33:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0007679133974894984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91965dc7d8954cce86f0fdbb83c78d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch34:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0007545207078751858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0e8eda6e17437f990e50d955e091d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch35:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0007408768370508578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65f5550dcaf4f0e92ec3e4a6f26fc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch36:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0007269952498697736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698a55d4379a4c3c84c1f537b4842e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch37:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0007128896457825365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd461a2165e4473bded7e4aa2eaddec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch38:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006985739453173904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd819367f4214b4ea30cb987ed9c9dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch39:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006840622763423392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d53e324896f45ccb8e446b35f1d94a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch40:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006693689601226459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73826f2863bf4e2eb70521dc0d882be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch41:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006545084971874739\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e2962fbf1c4fe9b67db8ee3f2af829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch42:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006394955530196148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f2fd980ffd409ea0d201748d796679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch43:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006243449435824275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f720a1047841b79b47af855180aee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch44:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006090716206982715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe628b165144627881761aaa6c87bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch45:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0005936906572928626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639a2da3d2164e5ea4145670d551992b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch46:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0005782172325201157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fde06241024deea9d08ef7008d41d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch47:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0005626666167821524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa41d73cb394cc0867320ec3449aa37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch48:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0005470541566592573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8352fa35f56744fb9963493ba5410415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch49:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.000531395259764657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17fea7ed6904b72ab81389a1a615973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch50:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0005157053795390644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c10fa2edf7247b98d000881b7fa68da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch51:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0005000000000000002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc49844aa644eceb9eee39c3d0f666a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch52:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00048429462046093607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449e3d91c16845c28a6440b65eceea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch53:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0004686047402353435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8930a8211054d2086525c96aa9caa44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch54:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.000452945843340743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6c75aa70e34dcb80a8c155acbc3c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch55:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00043733338321784806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92fa6933f0e407990cac8f1ec6b1003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch56:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0004217827674798847\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9eac2d2de714ac2936e3614094f7e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch57:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00040630934270713783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9892be42e3084bf7a27a5c0151f4b9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch58:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.000390928379301729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09bb176d8c140c6979dc4df1790128c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch59:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0003756550564175727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5f272846d841c08f969227113e691a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch60:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00036050444698038553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e6e6da8f414795b7400d4687950c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch61:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00034549150281252655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfedac3abefe4dd2b4b86dd2752e528b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch62:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0003306310398773544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40848bb0fcc640158b513091243d0f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch63:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00031593772365766127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418be9c3bbd94ca89a5f15e5b2a41c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch64:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0003014260546826097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c916473f68d4fef9a64a16cfacb54c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch65:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0002871103542174637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c464e9b6d34f4401af62ea853e1849de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch66:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0002730047501302267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6121c01b370c4468b038924246a6213b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch67:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00025912316294914234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f47a7d680794594ab83d01710c92128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch68:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0002454792921248144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95e911dab3a408c964c2f38b250144f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch69:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00023208660251050164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109c5e3d953143ffbd9849d548a5e73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch70:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00021895831107393473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a0f2e9984f4b1ca1c8b0445278b4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch71:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00020610737385376356\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bea25343084a0b8ed294b0235f7796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch72:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00019354647317351177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ce04df7c7b45efb2daea30982aef55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch73:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001812880051256552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3854138c6f044c929b687a7f42cddfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch74:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00016934406733817422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd1d33394e64a6b9d91923bb1f00c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch75:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001577264470356557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac399fdfb5d24a7d8a4b5de7806a019c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch76:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00014644660940672634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a481a6eeae435294de742f7b1e2fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch77:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001355156862892944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d134f1ffa8645499bf7e4f9bcb30ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch78:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001249444651847703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6e8886953e463387bd0a3bbeb2f51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch79:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00011474337861210548\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3664f36136742e7b0a12efc7683f1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch80:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00010492249381215483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ffa3bb6be2446c99cce0b99e6a47c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch81:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  9.549150281252637e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda4049fc8a441949a2f1a0fb9989ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch82:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  8.645971286271923e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0528d14548384975a4ea75392cf8abad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch83:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  7.78360372489926e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7385b74ef014d6c9fbf9af1a413e9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch84:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  6.962898649802815e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831d6d2bb75b462aadff3b9bcd34783d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch85:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  6.184665997806824e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58dc87ae50b48348298d6404e7a7cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch86:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  5.449673790581613e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746c68523a2441e9a3b94a1ce76e427d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch87:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  4.758647376699034e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72aadfd33084e1a9803fccdfab9ab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch88:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  4.112268715800956e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7532ba34924776a09bfa9ad5c72183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch89:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.511175705587434e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2e70ef96f04569b2aaef0b543d7a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch90:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.9559615522887284e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77c1e31e4af43469a4bc842cf6bede0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch91:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.447174185242324e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c10ed8bc34448f7b0ad0ac5706dde7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch92:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.9853157161528526e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401a49a330604fd9b71d2d969b8dd942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch93:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.570841943568452e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc08d60d460b42daa9ddfdc6b3eb65a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch94:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.204161903062634e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c6f0b6d9e646fdb723030dd6f5dced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch95:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  8.85637463565564e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3b8e2206e44bde86fa3e99801b842b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch96:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  6.155829702431171e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1139955b8c474e5bb0265a53f48d2582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch97:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.942649342761118e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8148dcd555f64a009aba7fbee9efba95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch98:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.2190176984600023e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2110e590420f441a8d75b029e2461a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch99:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  9.866357858642206e-07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f743145210444dd0bddbfa2aa9136c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch100:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.467198171342e-07\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 100\n",
    "optimizer = torch.optim.AdamW(mymodel.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, epochs, eta_min=0, last_epoch=-1\n",
    ")\n",
    "if os.path.exists(\"../../../BERT/NER_FT/NER_FT.pkl\"):\n",
    "    mymodel.load_state_dict(torch.load(\"../../../BERT/NER_FT/NER_FT.pkl\"))\n",
    "    optimizer.load_state_dict(torch.load(\"../../../BERT/NER_FT/NER_FT_optimizer.pkl\"))\n",
    "\n",
    "train(\n",
    "    epochs=epochs,\n",
    "    model=mymodel,\n",
    "    loader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.8875338753387534 0.8354430379746836\n",
      "1\n",
      "0.8782263401720715 0.7580645161290323\n",
      "2\n",
      "0.8779946761313221 0.7814207650273224\n",
      "3\n",
      "0.879124469127736 0.7879213483146067\n",
      "4\n",
      "0.8721234309623431 0.7956043956043956\n",
      "5\n",
      "0.8703301476976543 0.799625468164794\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "def test(loader_test=val_dataloader):\n",
    "    mymodel.load_state_dict(torch.load(\"../../../BERT/NER_FT/NER_FT.pkl\"))\n",
    "    mymodel.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    correct_content = 0\n",
    "    total_content = 0\n",
    "\n",
    "    for step, (inputs, labels) in enumerate(loader_test):\n",
    "        labels = labels.to(device)\n",
    "        print(step)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # [b, lens] -> [b, lens, 8] -> [b, lens]\n",
    "            outs = mymodel(inputs)\n",
    "\n",
    "        # 对outs和label变形,并且移除pad\n",
    "        # outs -> [b, lens, 8] -> [c, 8]\n",
    "        # labels -> [b, lens] -> [c]\n",
    "        outs, labels = reshape_and_remove_pad(outs, labels, inputs[\"attention_mask\"])\n",
    "\n",
    "        counts = get_correct_and_total_count(labels, outs)\n",
    "        correct += counts[0]\n",
    "        total += counts[1]\n",
    "        correct_content += counts[2]\n",
    "        total_content += counts[3]\n",
    "\n",
    "        print(correct / total, correct_content / total_content)\n",
    "\n",
    "\n",
    "test(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] “ batch gradient descent ” implies the use of the full training set, while the use of the term [SEP]\n",
      "label: [CLS]  ··········full  training  set  ·······[SEP]  \n",
      "predict: [CLS]  ·batch  gradient  descent  ·················\n",
      "==========================\n",
      "[CLS] about the whole pastsequence. Recurrent neural networks can be built in many different ways. Much [SEP]\n",
      "label: [CLS]  ·······Re  current  neural  networks  ·········[SEP]  \n",
      "predict: [CLS]  ·······Re  current  neural  networks  ··········\n",
      "==========================\n",
      "[CLS] of the ∈ ∞ norm penalty term, Ω, relative to the standard objective function J. Setting α to 0 [SEP]\n",
      "label: [CLS]  ········Ω  ··············[SEP]  \n",
      "predict: [CLS]  ························\n",
      "==========================\n",
      "[CLS] disadvantage of having two separate training phases is that each phase has its own hyperparameters. [SEP]\n",
      "label: [CLS]  ··············h  yper  par  ame  ters  ·[SEP]  \n",
      "predict: [CLS]  ··············h  yper  par  ame  ters  ··\n",
      "==========================\n",
      "[CLS] + + bbxx + + bbww + + ccxx + + ccww + + ddxx + + eeyy + + ffzz ffyy + + ggzz ggy [SEP]\n",
      "label: [CLS]  ·················································\n",
      "predict: [CLS]  ················································[SEP]  \n",
      "==========================\n",
      "[CLS] high. This is the underfitting regime. As we increase capacity, training error decreases, but the [SEP]\n",
      "label: [CLS]  ·············capacity  ·······[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] L2 constraint. Many different procedures are possible — some may use gradient descent, while others [SEP]\n",
      "label: [CLS]  ···············gradient  descent  ···[SEP]  \n",
      "predict: [CLS]  ·····················\n",
      "==========================\n",
      "[CLS] loss on the training set. This means replacing the true distribution p ( x, y ) with the empirical [SEP]\n",
      "label: [CLS]  ···training  set  ················[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] pretraining hasdeclined. Nevertheless, unsupervised pretraining remains an important milestone in [SEP]\n",
      "label: [CLS]  pre  tra  ining  ·······un  su  per  vise  d  pre  tra  ining  ·····[SEP]  \n",
      "predict: [CLS]  pre  tra  ining  ·······un  su  per  vise  d  pre  tra  ining  ······\n",
      "==========================\n",
      "[CLS] View task, the goal for the project was to reach human - level transcription accuracy while [SEP]\n",
      "label: [CLS]  ···········human  -  level  transcription  accuracy  ·[SEP]  \n",
      "predict: [CLS]  ···········human  -  level  transcription  accuracy  ··\n",
      "==========================\n",
      "[CLS] 8. 1. 2 Surrogate Loss Functions and Early Stopping Sometimes, the loss function we actually care [SEP]\n",
      "label: [CLS]  ···········Early  Stop  ping  ········[SEP]  \n",
      "predict: [CLS]  ···········Early  Stop  ping  ·········\n",
      "==========================\n",
      "[CLS] et al., 2011 ; Goodfellow et al., 2011 ), in settings where the number of labeled examples in the [SEP]\n",
      "label: [CLS]  ··························[SEP]  \n",
      "predict: [CLS]  ···························\n",
      "==========================\n",
      "[CLS] are described in section 6. 2. 2. 2. Evaluated on our whole training set, the MSE loss function is 1 2 [SEP]\n",
      "label: [CLS]  ······················MS  E  loss  function  ···[SEP]  \n",
      "predict: [CLS]  ······················MS  E  loss  function  ····\n",
      "==========================\n",
      "[CLS] regression model to our example training set from figure 5. 2. The true function is quadratic, but [SEP]\n",
      "label: [CLS]  ·······················[SEP]  \n",
      "predict: [CLS]  ························\n",
      "==========================\n",
      "[CLS] the nervous systems of insects. Because the size of neural networks is of paramount importance, [SEP]\n",
      "label: [CLS]  ··········neural  networks  ······[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] when working with deep learning algorithms. This is in part because the bounds are often quite [SEP]\n",
      "label: [CLS]  ···deep  learning  ············[SEP]  \n",
      "predict: [CLS]  ··················\n",
      "==========================\n",
      "[CLS] This recurrent network just processes information from the input x by incorporating it into the [SEP]\n",
      "label: [CLS]  ·re  current  network  ············[SEP]  \n",
      "predict: [CLS]  ·re  current  network  ·············\n",
      "==========================\n",
      "[CLS] must be large. One of the key factors responsible for the improvement in neural network ’ s accuracy [SEP]\n",
      "label: [CLS]  ···················[SEP]  \n",
      "predict: [CLS]  ····················\n",
      "==========================\n",
      "[CLS] algorithms are also expectations over the training set. For example, the 277 CHAPTER 8. [SEP]\n",
      "label: [CLS]  ······training  set  ··········[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] AI system observing an image of a face with one eye in shadow may initially only see one eye. After [SEP]\n",
      "label: [CLS]  AI  system  ···················[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] of computations includes 2n layers if we refine our estimate of each concept given the other n [SEP]\n",
      "label: [CLS]  ·······layers  ·············[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] acquire one and begin using deep learning in their product or platform. Deep learning has already [SEP]\n",
      "label: [CLS]  ·····deep  learning  ··········[SEP]  \n",
      "predict: [CLS]  ··················\n",
      "==========================\n",
      "[CLS] network training is non - deterministic, and converges to a different function every time it is run. [SEP]\n",
      "label: [CLS]  network  training  ······················[SEP]  \n",
      "predict: [CLS]  ·························\n",
      "==========================\n",
      "[CLS] of GPU. Another common consideration for GPUs is making sure that each thread in a group executes [SEP]\n",
      "label: [CLS]  ·GP  U  ·····GP  U  ············[SEP]  \n",
      "predict: [CLS]  ·······················\n",
      "==========================\n",
      "[CLS] i, j of the matrix computed by applying the function f to A. Tensors : In some cases we will need an [SEP]\n",
      "label: [CLS]  ················Ten  sors  ········[SEP]  \n",
      "predict: [CLS]  ···························\n",
      "==========================\n",
      "[CLS] above. Neural networks usually involve large and numerous buffers of parameters, activation values, [SEP]\n",
      "label: [CLS]  ··N  eur  al  networks  ·············[SEP]  \n",
      "predict: [CLS]  ··N  eur  al  networks  ··············\n",
      "==========================\n",
      "[CLS] recurrentnetwork is trainedto perform a task that requirespredicting the future from the past, the [SEP]\n",
      "label: [CLS]  ·······················[SEP]  \n",
      "predict: [CLS]  ························\n",
      "==========================\n",
      "[CLS] different ways. One way to draw the RNN is with a diagram containing one node for every component [SEP]\n",
      "label: [CLS]  ········R  N  N  ··········[SEP]  \n",
      "predict: [CLS]  ········R  N  N  ···········\n",
      "==========================\n",
      "[CLS] on minimizing this average training error is known as empirical risk minimization. In this setting, [SEP]\n",
      "label: [CLS]  ··········empirical  risk  mini  mi  zation  ·····[SEP]  \n",
      "predict: [CLS]  ··········empirical  risk  mini  mi  zation  ······\n",
      "==========================\n",
      "[CLS] further in section 12. 1. 3. An interesting motivation for minibatch stochastic gradient descent is [SEP]\n",
      "label: [CLS]  ·············mini  bat  ch  s  to  cha  stic  gradient  descent  ·[SEP]  \n",
      "predict: [CLS]  ·············mini  bat  ch  s  to  cha  stic  gradient  descent  ··\n",
      "==========================\n",
      "[CLS] often becomes the rate limiting factor. GPUs offer a compelling advantage over CPUs due to their [SEP]\n",
      "label: [CLS]  ·······GP  U  s  ··········[SEP]  \n",
      "predict: [CLS]  ·······GP  U  s  ···········\n",
      "==========================\n",
      "[CLS] space, while neural networks without pretraining consistently halt in another region. See figure [SEP]\n",
      "label: [CLS]  ···neural  networks  ·pre  tra  ining  ········[SEP]  \n",
      "predict: [CLS]  ··················\n",
      "==========================\n",
      "[CLS] network seen as an unfolded computational graph, where each node is now associated with one [SEP]\n",
      "label: [CLS]  ·····computational  graph  ·········[SEP]  \n",
      "predict: [CLS]  ·················\n",
      "==========================\n",
      "[CLS] the minibatches be selected randomly. Computing an unbiased estimate of the expected gradient from [SEP]\n",
      "label: [CLS]  ·mini  bat  ches  ···············[SEP]  \n",
      "predict: [CLS]  ·mini  bat  ches  ················\n",
      "==========================\n",
      "[CLS] = I ( m, n ) K ( i m, j n ). ( 9. 4 ) ∗ − − m n Convolution is commutative, meaning we can equivalently [SEP]\n",
      "label: [CLS]  ·······································[SEP]  \n",
      "predict: [CLS]  ········································\n",
      "==========================\n",
      "[CLS] gradient descent is that it follows the gradient of the true generalization error ( equation 8. 2 ) so [SEP]\n",
      "label: [CLS]  gradient  descent  ·········general  ization  error  ·······[SEP]  \n",
      "predict: [CLS]  ···········general  ization  error  ········\n",
      "==========================\n",
      "[CLS] L2 regularization is equivalent to MAP Bayesian inference with a Gaussian prior on the weights. For [SEP]\n",
      "label: [CLS]  L  2  regular  ization  ············G  aus  sian  prior  ·····[SEP]  \n",
      "predict: [CLS]  L  2  regular  ization  ······················\n",
      "==========================\n",
      "[CLS] pretraining follow this basic protocol. Greedy layer - wise unsupervised pretraining can also be used [SEP]\n",
      "label: [CLS]  pre  tra  ining  ·····G  reed  y  layer  -  wise  un  su  per  vise  d  pre  tra  ining  ····[SEP]  \n",
      "predict: [CLS]  pre  tra  ining  ····.  G  reed  y  layer  -  wise  un  su  per  vise  d  pre  tra  ining  ·····\n",
      "==========================\n",
      "[CLS] phase, using early stopping on the unsupervised objective, which is not ideal but computationally [SEP]\n",
      "label: [CLS]  ···early  stopping  ··un  su  per  vise  d  objective  ········[SEP]  \n",
      "predict: [CLS]  ·······un  su  per  vise  d  objective  ·········\n",
      "==========================\n",
      "[CLS] Chapter 20 Deep Generative Models In this chapter, we present several of the specific kinds of [SEP]\n",
      "label: [CLS]  ··················[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] To summarize, deep learning, the subject of this book, is an approach to AI. Specifically, it is a [SEP]\n",
      "label: [CLS]  ·····deep  learning  ···········AI  ······[SEP]  \n",
      "predict: [CLS]  ··························\n",
      "==========================\n",
      "[CLS] Today, unsupervised pretraining has been largely abandoned, except in the field of natural language [SEP]\n",
      "label: [CLS]  ··un  su  per  vise  d  pre  tra  ining  ············[SEP]  \n",
      "predict: [CLS]  ··un  su  per  vise  d  pre  tra  ining  ·············\n",
      "==========================\n",
      "[CLS] values. We must also design the architecture of the network, including how many layers the network [SEP]\n",
      "label: [CLS]  ···············layers  ··[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] This means the denominator of the softmax will become 0, so the final result is undefined. When c [SEP]\n",
      "label: [CLS]  ·········soft  max  ···············[SEP]  \n",
      "predict: [CLS]  ···························\n",
      "==========================\n",
      "[CLS] deep models also typically include some specialization on the specific structure of machine [SEP]\n",
      "label: [CLS]  deep  models  ············[SEP]  \n",
      "predict: [CLS]  ···············\n",
      "==========================\n",
      "[CLS] by the training set : J ( θ ) = E logp ( x, y ; θ ). ( 8. 5 ) x, y [UNK] model data [UNK] Most of the properties of the [SEP]\n",
      "label: [CLS]  ··training  set  ···································[SEP]  \n",
      "predict: [CLS]  ········································\n",
      "==========================\n",
      "[CLS] of jointly training the layers of a deep neural net for a supervised task. This approach dates back [SEP]\n",
      "label: [CLS]  ·······deep  neural  net  ·········[SEP]  \n",
      "predict: [CLS]  ·······deep  neural  net  ··········\n",
      "==========================\n",
      "[CLS] for information about reinforcement learning, and Mnih et al. ( 2013 ) for the deep learning approach [SEP]\n",
      "label: [CLS]  ···reinforce  ment  learning  ·············deep  learning  ·[SEP]  \n",
      "predict: [CLS]  ···reinforce  ment  learning  ·················\n",
      "==========================\n",
      "[CLS] of sentences ), and then use this representation or fine - tune it for a supervised task for which the [SEP]\n",
      "label: [CLS]  ················supervised  task  ···[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] for the length of a computer program. Nor is there a consensus about how much depth a model [SEP]\n",
      "label: [CLS]  ··················model  [SEP]  \n",
      "predict: [CLS]  ····················\n",
      "==========================\n",
      "[CLS] examples is very small. Because the source of information added by unsupervised pretraining is the [SEP]\n",
      "label: [CLS]  ············un  su  per  vise  d  pre  tra  ining  ··[SEP]  \n",
      "predict: [CLS]  ············un  su  per  vise  d  pre  tra  ining  ···\n",
      "==========================\n",
      "[CLS] MODELS than one but less than all of the training examples. These were traditionally called [SEP]\n",
      "label: [CLS]  ···················[SEP]  \n",
      "predict: [CLS]  ····················\n",
      "==========================\n",
      "[CLS] train a generative model of images of cars and motorcycles, it will need to know about wheels, and [SEP]\n",
      "label: [CLS]  ··genera  tive  model  ················[SEP]  \n",
      "predict: [CLS]  ··genera  tive  model  ·················\n",
      "==========================\n",
      "[CLS] the first argument ( in this example, the function x ) to the convolution is often referred to as the [SEP]\n",
      "label: [CLS]  ··············con  vo  lution  ······[SEP]  \n",
      "predict: [CLS]  ··············con  vo  lution  ·······\n",
      "==========================\n",
      "[CLS] to compute multiple gradient descent steps in parallel. Unfortunately, the standard definition of [SEP]\n",
      "label: [CLS]  ····gradient  descent  ··········[SEP]  \n",
      "predict: [CLS]  ·················\n",
      "==========================\n",
      "[CLS] situation, but we may find large numbers of examples that all make very similar contributions to [SEP]\n",
      "label: [CLS]  ······large  numbers  of  examples  ·······[SEP]  \n",
      "predict: [CLS]  ······large  numbers  of  examples  ········\n",
      "==========================\n",
      "[CLS] In directions that do not contribute to reducing the objective function, a small eigenvalue of the [SEP]\n",
      "label: [CLS]  ·········objective  function  ··········[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] LEARNING very many hyperparameters, whose effect may be measured after the fact but is often [SEP]\n",
      "label: [CLS]  ·······h  yper  par  ame  ters  ············[SEP]  \n",
      "predict: [CLS]  ·······h  yper  par  ame  ters  ·············\n",
      "==========================\n",
      "[CLS] layers that read information out of the state h to make predictions. When the recurrentnetwork is [SEP]\n",
      "label: [CLS]  ····················[SEP]  \n",
      "predict: [CLS]  ·····················\n",
      "==========================\n",
      "[CLS] to approach the origin. Explicit constraints implemented by re - projection only have an effect when [SEP]\n",
      "label: [CLS]  ···········re  -  projection  ·····[SEP]  \n",
      "predict: [CLS]  ···········re  -  projection  ······\n",
      "==========================\n",
      "[CLS] during the first phase, so there is a long delay between proposing hyperparameters for the first [SEP]\n",
      "label: [CLS]  ·············h  yper  par  ame  ters  ···[SEP]  \n",
      "predict: [CLS]  ·············h  yper  par  ame  ters  ····\n",
      "==========================\n",
      "[CLS] our analysis of L2 regularization. In particular, we are interested in delineating the differences [SEP]\n",
      "label: [CLS]  ···L  2  regular  ization  ·············[SEP]  \n",
      "predict: [CLS]  ···L  2  regular  ization  ··············\n",
      "==========================\n",
      "[CLS] spoken in the audio recording. Deep learning is a crucial component of modern speech recognition [SEP]\n",
      "label: [CLS]  ······Deep  learning  ······speech  recognition  [SEP]  \n",
      "predict: [CLS]  ·················\n",
      "==========================\n",
      "[CLS] the flu, this means something very different — we can not make infinitely many replicas of the [SEP]\n",
      "label: [CLS]  ····················[SEP]  \n",
      "predict: [CLS]  ·····················\n",
      "==========================\n",
      "[CLS] is just to minimize the mean squared error on the training set, MSE. train To minimize MSE, we [SEP]\n",
      "label: [CLS]  ·····mean  squared  error  ·····MS  E  ····MS  E  ··[SEP]  \n",
      "predict: [CLS]  ·····mean  squared  error  ················\n",
      "==========================\n",
      "[CLS] ( Marcotte and Savard, 1992 ). In such situations, one typically optimizes a surrogate loss function [SEP]\n",
      "label: [CLS]  ·····················sur  rogate  loss  function  [SEP]  \n",
      "predict: [CLS]  ·····················sur  rogate  loss  function  ·\n",
      "==========================\n",
      "[CLS] types of tasks we list here are intended only to provide examples of what machine learning can do, [SEP]\n",
      "label: [CLS]  ··············machine  learning  ···[SEP]  \n",
      "predict: [CLS]  ····················\n",
      "==========================\n",
      "[CLS] of GPU computing. GPU hardware was originally so specialized that it could only be used for [SEP]\n",
      "label: [CLS]  ·GP  U  computing  ·GP  U  hardware  ···········[SEP]  \n",
      "predict: [CLS]  ·GP  U  computing  .  GP  U  hardware  ············\n",
      "==========================\n",
      "[CLS] minibatches. Such asynchronous parallel distributed approaches are discussed further in section [SEP]\n",
      "label: [CLS]  ·····as  ync  hr  ono  us  parallel  distributed  ······[SEP]  \n",
      "predict: [CLS]  ·····as  ync  hr  ono  us  parallel  distributed  approaches  ······\n",
      "==========================\n",
      "[CLS] stochastic gradient descent minimizes generalization error is easiest to see in the online learning [SEP]\n",
      "label: [CLS]  s  to  cha  stic  gradient  descent  ··general  ization  error  ········online  learning  [SEP]  \n",
      "predict: [CLS]  s  to  cha  stic  gradient  descent  ··general  ization  error  ···········\n",
      "==========================\n",
      "[CLS] in section 4. 4, we can modify algorithms such as stochastic gradient descent to take a step [SEP]\n",
      "label: [CLS]  ············s  to  cha  stic  gradient  descent  ····[SEP]  \n",
      "predict: [CLS]  ············s  to  cha  stic  gradient  descent  ·····\n",
      "==========================\n",
      "[CLS] order to solve the classification task, the learning algorithm only has to define a single function [SEP]\n",
      "label: [CLS]  ····classification  task  ··learning  algorithm  ·······[SEP]  \n",
      "predict: [CLS]  ··················\n",
      "==========================\n",
      "[CLS] distribution over classes. An example of a classification task is object recognition, where the [SEP]\n",
      "label: [CLS]  ········classification  task  ·object  recognition  ···[SEP]  \n",
      "predict: [CLS]  ·················\n",
      "==========================\n",
      "[CLS] function J. We denote the regularized [UNK] objective function by J : [UNK] J ( θ ; X, y ) = J ( θ ; X, y ) + αΩ ( θ ) ( 7. 1 ) [SEP]\n",
      "label: [CLS]  ·········objective  function  ································[SEP]  \n",
      "predict: [CLS]  ············································\n",
      "==========================\n",
      "[CLS] decreases, but the gap between training and generalization error increases. Eventually, the size of [SEP]\n",
      "label: [CLS]  ········general  ization  error  ·······[SEP]  \n",
      "predict: [CLS]  ········general  ization  error  ········\n",
      "==========================\n",
      "[CLS] pretraining winning two international transfer learning competitions ( Mesnil et al., 2011 ; [SEP]\n",
      "label: [CLS]  pre  tra  ining  ···transfer  learning  ············[SEP]  \n",
      "predict: [CLS]  pre  tra  ining  ··················\n",
      "==========================\n",
      "[CLS] graphics cards for neural network training exploded after the advent of general purpose GPUs. These [SEP]\n",
      "label: [CLS]  ···neural  network  training  ·····general  purpose  GP  U  s  ··[SEP]  \n",
      "predict: [CLS]  ···neural  network  training  ·····general  purpose  GP  U  s  ···\n",
      "==========================\n",
      "[CLS] often halts while the surrogate loss function still has large derivatives, which is very different [SEP]\n",
      "label: [CLS]  ·····sur  rogate  loss  function  ·········[SEP]  \n",
      "predict: [CLS]  ·····sur  rogate  loss  function  ··········\n",
      "==========================\n",
      "[CLS] graph — is most relevant, and because different people choose different sets of smallest elements [SEP]\n",
      "label: [CLS]  ················[SEP]  \n",
      "predict: [CLS]  ·················\n",
      "==========================\n",
      "[CLS] training procedures usually do not arrive at a critical point of any kind. It remains possible that [SEP]\n",
      "label: [CLS]  ··················[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] that maps a circuit as in the left side of the figure to a computational graph with repeated pieces [SEP]\n",
      "label: [CLS]  ···················[SEP]  \n",
      "predict: [CLS]  ····················\n",
      "==========================\n",
      "[CLS], { [ 1, 0 ], and [ 1, 1 ]. We will train the network on all four of these points. The } only [SEP]\n",
      "label: [CLS]  ···················network  ··········[SEP]  \n",
      "predict: [CLS]  ·······························\n",
      "==========================\n",
      "[CLS] the world as a nested hierarchy of concepts, with each concept defined in relation to simpler [SEP]\n",
      "label: [CLS]  ··················[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] regularization, L1 regularization results in a solution that is more sparse. Sparsity in this [SEP]\n",
      "label: [CLS]  ···L  1  regular  ization  ··············[SEP]  \n",
      "predict: [CLS]  ···L  1  regular  ization  ···············\n",
      "==========================\n",
      "[CLS] task may also be useful for the supervised learning task. For example, if we train a generative [SEP]\n",
      "label: [CLS]  ·······supervised  learning  task  ··········[SEP]  \n",
      "predict: [CLS]  ·······supervised  learning  task  ···········\n",
      "==========================\n",
      "[CLS] importance, deep learning 443 CHAPTER 12. APPLICATIONS requires high performance hardware and [SEP]\n",
      "label: [CLS]  ··deep  learning  ················[SEP]  \n",
      "predict: [CLS]  ·····················\n",
      "==========================\n",
      "[CLS] RECURRENT AND RECURSIVE NETS where we seethat the state now containsinformation about the whole [SEP]\n",
      "label: [CLS]  R  EC  UR  RE  NT  AND  R  EC  UR  SI  VE  NE  TS  ··············[SEP]  \n",
      "predict: [CLS]  R  EC  UR  RE  NT  AND  R  EC  UR  SI  VE  NE  TS  ···············\n",
      "==========================\n",
      "[CLS] paradigms for performing semi - supervised learning with neural networks, such as virtual adversarial [SEP]\n",
      "label: [CLS]  ····semi  -  supervised  learning  ·neural  networks  ···virtual  ad  vers  aria  l  [SEP]  \n",
      "predict: [CLS]  ····semi  -  supervised  learning  ······virtual  ad  vers  aria  l  ·\n",
      "==========================\n",
      "[CLS] the training set, then use it to choose the parameters to reduce training set error, then sample [SEP]\n",
      "label: [CLS]  ·training  set  ··········training  set  ····[SEP]  \n",
      "predict: [CLS]  ····················\n",
      "==========================\n",
      "[CLS] CHAPTER 5. MACHINE LEARNING BASICS an optimization algorithm, a cost function, a model, and a [SEP]\n",
      "label: [CLS]  ····················cost  function  ··model  ···[SEP]  \n",
      "predict: [CLS]  ·····························\n",
      "==========================\n",
      "[CLS] H is the Hessian matrix of J with respect to w evaluated at w. ∗ Because the L1 penalty does not [SEP]\n",
      "label: [CLS]  ···················L  1  penalty  ··[SEP]  \n",
      "predict: [CLS]  ···················L  1  penalty  ···\n",
      "==========================\n",
      "[CLS] set, we can compute some error measure on the training set called the training error, and we reduce [SEP]\n",
      "label: [CLS]  ···········training  set  ········[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] both train and test reconstruction error for deep autoencoders ( Hinton and Salakhutdinov, 2006 ). [SEP]\n",
      "label: [CLS]  ·······deep  auto  en  code  rs  ··············[SEP]  \n",
      "predict: [CLS]  ·······deep  auto  en  code  rs  ···············\n",
      "==========================\n",
      "[CLS] [UNK] = H i, i w. If w was nonzero, then [UNK] remains i H + α ∗i ∗i i i, i nonzero. This demonstrates that [SEP]\n",
      "label: [CLS]  ·····································[SEP]  \n",
      "predict: [CLS]  ······································\n",
      "==========================\n",
      "[CLS] possible by simply minimizing the average 0 - 1 loss on the training set. A very important difference [SEP]\n",
      "label: [CLS]  ····················[SEP]  \n",
      "predict: [CLS]  ·····················\n",
      "==========================\n",
      "[CLS] do not just experience a fixed dataset. For example, reinforcement learning algorithms interact [SEP]\n",
      "label: [CLS]  ············reinforce  ment  learning  algorithms  ·[SEP]  \n",
      "predict: [CLS]  ············reinforce  ment  learning  algorithms  ··\n",
      "==========================\n",
      "[CLS] is stochastic gradient descent, presented in detail in section 8. 3. 1. Minibatch sizes are generally [SEP]\n",
      "label: [CLS]  ·s  to  cha  stic  gradient  descent  ··················[SEP]  \n",
      "predict: [CLS]  ·s  to  cha  stic  gradient  descent  ···················\n",
      "==========================\n",
      "[CLS] that works with matrix multiplication and does not depend on specific properties of the matrix [SEP]\n",
      "label: [CLS]  ···matrix  multi  plication  ··········[SEP]  \n",
      "predict: [CLS]  ···matrix  multi  plication  ···········\n",
      "==========================\n",
      "[CLS] proofs, it is not usually an important property of a neural network implementation. Instead, many [SEP]\n",
      "label: [CLS]  ············neural  network  implementation  ····[SEP]  \n",
      "predict: [CLS]  ············neural  network  implementation  ·····\n",
      "==========================\n",
      "[CLS] aspects of the past sequence with more precision than other aspects. For example, if the RNN is [SEP]\n",
      "label: [CLS]  ·················R  N  N  ·[SEP]  \n",
      "predict: [CLS]  ·················R  N  N  ··\n",
      "==========================\n",
      "[CLS] underlying loss function, such as 0 - 1 loss measured on a validation set, and is designed to cause [SEP]\n",
      "label: [CLS]  underlying  loss  function  ···················[SEP]  \n",
      "predict: [CLS]  underlying  loss  function  ····················\n",
      "==========================\n",
      "[CLS] could be used to accelerate supervised convolutional networks. The popularity of graphics cards for [SEP]\n",
      "label: [CLS]  ·····supervised  con  vo  lution  al  networks  ·······[SEP]  \n",
      "predict: [CLS]  ·····supervised  con  vo  lution  al  networks  ········\n",
      "==========================\n",
      "[CLS] of the value of the weights that obtains minimal unregularized training cost, w = argmin J ( w ). If [SEP]\n",
      "label: [CLS]  ···············training  cost  ············[SEP]  \n",
      "predict: [CLS]  ······························\n",
      "==========================\n",
      "[CLS] in the dataset. Unsupervised learning algorithms experience a dataset containing many features, [SEP]\n",
      "label: [CLS]  ····················[SEP]  \n",
      "predict: [CLS]  ·····················\n",
      "==========================\n",
      "[CLS] need to make more steps, both because of the reduced learning rate and because it takes more steps [SEP]\n",
      "label: [CLS]  ···········learning  rate  ······[SEP]  \n",
      "predict: [CLS]  ····················\n",
      "==========================\n",
      "[CLS] 10. 2, typical RNNs will add extra architectural features such as output layers that read [SEP]\n",
      "label: [CLS]  ·····R  N  N  s  ···········[SEP]  \n",
      "predict: [CLS]  ·····R  N  N  s  ············\n",
      "==========================\n",
      "[CLS] example, if we want to use a learning algorithm to perform object recognition from photographs, we [SEP]\n",
      "label: [CLS]  ············object  recognition  ····[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] sequence ( x ( t ), x ( t 1 ), x ( t 2 ),..., x ( 2 ), x ( 1 ) ) − − as input and produces the current state, but the [SEP]\n",
      "label: [CLS]  ·············································[SEP]  \n",
      "predict: [CLS]  ··············································\n",
      "==========================\n",
      "[CLS] during training is somewhat harder. We can increase the size of the minibatch used for a single SGD [SEP]\n",
      "label: [CLS]  ·············mini  bat  ch  ····S  G  D  [SEP]  \n",
      "predict: [CLS]  ·············mini  bat  ch  ····S  G  D  ·\n",
      "==========================\n",
      "[CLS] ( words in the vocabulary ) per input feature. 12. 1 Large - Scale Deep Learning Deep learning is based [SEP]\n",
      "label: [CLS]  ······················[SEP]  \n",
      "predict: [CLS]  ·······················\n",
      "==========================\n",
      "[CLS] from that of L2 regularization. Specifically, we can see that the regularization contribution to [SEP]\n",
      "label: [CLS]  ···L  2  regular  ization  ············[SEP]  \n",
      "predict: [CLS]  ···L  2  regular  ization  ·············\n",
      "==========================\n",
      "[CLS] Next, we review several specific application areas that deep learning has been used to solve. While [SEP]\n",
      "label: [CLS]  ·········deep  learning  ·······[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] is no reduction in the time to process a minibatch. If all examples in the batch are to be [SEP]\n",
      "label: [CLS]  ·········mini  bat  ch  ··········[SEP]  \n",
      "predict: [CLS]  ·········mini  bat  ch  ···········\n",
      "==========================\n",
      "[CLS] network. Many recurrent neural networks use equation 10. 5 or a similar equation to define the [SEP]\n",
      "label: [CLS]  ···re  current  neural  networks  ············[SEP]  \n",
      "predict: [CLS]  ···re  current  neural  networks  ·············\n",
      "==========================\n",
      "[CLS] Roughly speaking, unsupervised learning involves observing several examples of a random vector x, [SEP]\n",
      "label: [CLS]  ····un  su  per  vise  d  learning  ··········[SEP]  \n",
      "predict: [CLS]  ····un  su  per  vise  d  learning  ···········\n",
      "==========================\n",
      "[CLS] that maps a circuit as in the left side of the figure to a computational graph with repeated pieces [SEP]\n",
      "label: [CLS]  ··············computational  graph  ···[SEP]  \n",
      "predict: [CLS]  ····················\n",
      "==========================\n",
      "[CLS] can compute entire separate updates over different examples in parallel. In other words, we can [SEP]\n",
      "label: [CLS]  ··················[SEP]  \n",
      "predict: [CLS]  ···················\n",
      "==========================\n",
      "[CLS] for that minibatch : 1 [UNK] = L ( f ( x ( i ) ; θ ), y ( i ) ). ( 8. 9 ) θ [UNK] i Updating θ in the direction of [UNK] [SEP]\n",
      "label: [CLS]  ···········································[SEP]  \n",
      "predict: [CLS]  ············································\n",
      "==========================\n",
      "[CLS] maintaining some stability. In particular, Hinton et al. ( 2012c ) recommend a strategy introduced by [SEP]\n",
      "label: [CLS]  ·······Hi  nton  et  al  .  ·········[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] and division on many vertices in parallel to convert these 3 - D coordinates into 2 - D on - screen [SEP]\n",
      "label: [CLS]  ·····················[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n",
      "[CLS] million people has this disease. We can easily achieve 99. 9999 % accuracy on the detection task, by [SEP]\n",
      "label: [CLS]  ···················detection  task  ··[SEP]  \n",
      "predict: [CLS]  ························\n",
      "==========================\n",
      "[CLS] for the past three decades, yet artificial neural networks are only as large as the nervous systems [SEP]\n",
      "label: [CLS]  ·······artificial  neural  networks  ········[SEP]  \n",
      "predict: [CLS]  ·······artificial  neural  networks  ·········\n",
      "==========================\n",
      "[CLS] can be somewhat confusing because the word “ batch ” is also often used to describe the minibatch [SEP]\n",
      "label: [CLS]  ·················mini  bat  ch  [SEP]  \n",
      "predict: [CLS]  ·················mini  bat  ch  ·\n",
      "==========================\n",
      "[CLS] a survey of anomaly detection methods. Synthesis and sampling : In this type of task, the machine [SEP]\n",
      "label: [CLS]  ···an  oma  ly  detection  methods  ···············[SEP]  \n",
      "predict: [CLS]  ···an  oma  ly  detection  methods  ················\n",
      "==========================\n",
      "[CLS] capture the structure of the probability distribution. Density estimation allows us to explicitly [SEP]\n",
      "label: [CLS]  ·····probability  distribution  ·Den  sity  est  imation  ····[SEP]  \n",
      "predict: [CLS]  ·····probability  distribution  .  Den  sity  est  imation  ·····\n",
      "==========================\n",
      "[CLS] strategies that are formed by combining simple optimization algorithms into higher - level [SEP]\n",
      "label: [CLS]  ·······optimization  algorithms  ····[SEP]  \n",
      "predict: [CLS]  ··············\n",
      "==========================\n",
      "[CLS] others do not. In multi - instance learning, an entire collection of examples is labeled as [SEP]\n",
      "label: [CLS]  ·····multi  -  instance  learning  ·········[SEP]  \n",
      "predict: [CLS]  ·····multi  -  instance  learning  ··········\n",
      "==========================\n",
      "[CLS] most common form of weight decay, there are other ways to penalize the size of the model [SEP]\n",
      "label: [CLS]  ····weight  decay  ··············[SEP]  \n",
      "predict: [CLS]  ·····················\n",
      "==========================\n",
      "[CLS] category. For 101 CHAPTER 5. MACHINE LEARNING BASICS example, deep learning can be used to annotate [SEP]\n",
      "label: [CLS]  ·····················deep  learning  ·······[SEP]  \n",
      "predict: [CLS]  ·······························\n",
      "==========================\n",
      "[CLS] that are adapted by the learning algorithm. We will refer to these multidimensional arrays as [SEP]\n",
      "label: [CLS]  ·····learning  algorithm  ······multi  di  men  sional  array  s  ·[SEP]  \n",
      "predict: [CLS]  ·············multi  di  men  sional  array  s  ··\n",
      "==========================\n",
      "[CLS] more concrete, we begin with an example of a fully functioning feedforward network on a very simple [SEP]\n",
      "label: [CLS]  ············feed  fo  r  ward  network  ····[SEP]  \n",
      "predict: [CLS]  ············feed  fo  r  ward  network  ·····\n",
      "==========================\n",
      "[CLS] good performance on GPU are very different from those used on CPU. For example, good CPU - based code [SEP]\n",
      "label: [CLS]  ···GP  U  ·················[SEP]  \n",
      "predict: [CLS]  ·······················\n",
      "==========================\n",
      "[CLS] If Ω is the L1 norm, then the weights are constrained to lie in a region of 237 CHAPTER 7. [SEP]\n",
      "label: [CLS]  ····L  1  norm  ··················[SEP]  \n",
      "predict: [CLS]  ····L  1  norm  ···················\n",
      "==========================\n",
      "[CLS] weight decay at all layers just to reduce the size of search space. 230 CHAPTER 7. REGULARIZATION [SEP]\n",
      "label: [CLS]  weight  decay  ················R  EG  U  LA  RI  Z  AT  ION  [SEP]  \n",
      "predict: [CLS]  ··················R  EG  U  LA  RI  Z  AT  ION  ·\n",
      "==========================\n",
      "[CLS] correct value of multiple hyperparameters, it is still reasonable to use the same weight decay at [SEP]\n",
      "label: [CLS]  ··················weight  decay  ·[SEP]  \n",
      "predict: [CLS]  ······················\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "def predict(loader_test=val_dataloader):\n",
    "    mymodel.load_state_dict(torch.load(\"../../../BERT/NER_FT/NER_FT.pkl\"))\n",
    "    mymodel.eval()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader_test):\n",
    "\n",
    "        inputs[\"input_ids\"] = inputs[\"input_ids\"].to(device)\n",
    "        inputs[\"attention_mask\"] = inputs[\"attention_mask\"].to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outs = torch.tensor(mymodel.crf.decode(mymodel(inputs))).to(device)\n",
    "        for i in range(5):\n",
    "            # 移除pad\n",
    "            select = inputs[\"attention_mask\"][i] == 1\n",
    "            input_id = inputs[\"input_ids\"][i, select]\n",
    "            out = outs[i, select]\n",
    "            label = labels[i, select]\n",
    "\n",
    "            # 输出原句子\n",
    "            print(tokenizer.decode(input_id))\n",
    "\n",
    "            # 输出tag\n",
    "            for index, tag in enumerate([label, out]):\n",
    "                prefix = \"label\" if index == 0 else \"predict\"\n",
    "                s = \"\"\n",
    "                for j in range(len(tag)):\n",
    "                    if tag[j] == 0:\n",
    "                        s += \"·\"\n",
    "                        continue\n",
    "                    s += (\n",
    "                        tokenizer.decode(input_id[j]).replace(\" \", \"\").replace(\"##\", \"\")\n",
    "                        + \" \"\n",
    "                    )\n",
    "                    s += \" \"\n",
    "\n",
    "                print(prefix + \": \" + s)\n",
    "            print(\"==========================\")\n",
    "\n",
    "\n",
    "predict(train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
