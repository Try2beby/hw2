{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65544ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# from pdfminer.high_level import extract_text\n",
    "import re\n",
    "\n",
    "# import collections\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ef78c",
   "metadata": {},
   "source": [
    "# TARGET\n",
    "\n",
    "### 1. 抽取命名实体\n",
    "\n",
    "- 用 GPT3.5 抽取\n",
    "- 用 spaCy 抽取 (**prefer**)\n",
    "- 自定义规则抽取\n",
    "\n",
    "### 2. 抽取关系\n",
    "\n",
    "1. 参考知识图谱书本的结构，关系分为`目录`, `前置`, `句子共现`, `段落共现`, `频繁项集`  \n",
    "   以上关系**自定义规则**抽取即可\n",
    "2. 问题在于，以上关系仅考虑位置，未考虑**语义信息**  \n",
    "   需要对关系列表进行扩张，考虑实体与实体间的语义信息，如{`'LSTM'`, `'isA'`, `'RNN'`}  \n",
    "   需要先观察抽取出的命名实体，再进一步计划需要扩张哪些关系\n",
    "\n",
    "### 3. 实现知识图谱\n",
    "\n",
    "- 将数据储存为 json 格式，用 java 制作知识图谱 (pending to explore)\n",
    "\n",
    "# Work In Progress\n",
    "\n",
    "1. 制作**目录架构**，包括**名称与序号**的对应关系，以及**序号与页码**的对应关系，可以用来抽取`目录`和`前置`关系\n",
    "2. 制作**内容架构**，包括**段落表**和**句子表**，段落表目前基于页数划分，一页视为一个段落，句子表目前基于'`.`'划分，一个句号是一个句子\n",
    "3. 用 GPT3.5 尝试抽取命名实体\n",
    "\n",
    "# TO-DO List\n",
    "\n",
    "1. 探索 spaCy package，查看抽取出的实体的质量\n",
    "2. 自定义规则，实现`目录`, `前置`, `句子共现`, `段落共现`, `频繁项集`该 5 个关系\n",
    "3. 扩张关系列表，考虑语义信息\n",
    "4. 探索 java 生成多层级知识图谱的方式\n",
    "\n",
    "# Question\n",
    "\n",
    "1. 段落与句子的划分怎么样才能更加细致，目前段落的问题是太长，句子的问题是句号'`.`'会出现在人名/公式/...奇怪的地方，并不仅出现在句尾\n",
    "1. 新增的、考虑语义信息的关系应该如何抽取\n",
    "1. 如何设计 json 的架构，以更加方便地用 java 制作知识图谱\n",
    "1. etc...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad0e7c",
   "metadata": {},
   "source": [
    "# 设置 api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d6d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"https://api.chatanywhere.com.cn/v1\"\n",
    "# openai.api_base = 'https://api.chatanywhere.cn/v1'\n",
    "openai.api_key = \"sk-D1u13WweY1LhWLqv95Ml7e3y8f8ToSfsTkGnlgvSQLqZJptC\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b80029",
   "metadata": {},
   "source": [
    "# 读取数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa24280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不选择用这种方式读取，用pdfplumber更好\n",
    "# text = extract_text('./Deep Learning (Ian Goodfellow, Yoshua Bengio, Aaron Courville).pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590efdbd",
   "metadata": {},
   "source": [
    "## 生成目录架构\n",
    "\n",
    "- 生成**章节名称**与**章节序号**的对应：`name_dict`\n",
    "- 以及**章节序号**与**章节页码**范围的对应：`index_dict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1612cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(\"../data/Deep Learning.pdf\") as f:\n",
    "    # 目录架构生成\n",
    "    c, p, n = [], [], []\n",
    "    for i in range(7):\n",
    "        page = f.pages[i]\n",
    "        text = page.extract_text()\n",
    "        text_split = text.split(\"\\n\")\n",
    "        for i in text_split:\n",
    "            if bool(re.match(\"[0-9]+\\.[0-9]+\", i.split(\" \")[0])):\n",
    "                c.append(i.split(\" \")[0])\n",
    "                p.append(i.split(\" \")[-1])\n",
    "            if bool(re.match(\"[0-9]+\", i.split(\" \")[0])):\n",
    "                for j in i.split(\" \"):\n",
    "                    if bool(re.match(\"[A-Za-z]+\", j)):\n",
    "                        n.append((i.split(\" \")[0], j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65673d5",
   "metadata": {},
   "source": [
    "### name_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665533ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {}\n",
    "for i, j in n:\n",
    "    if i in name_dict:\n",
    "        name_dict[i] = name_dict.get(i, \"\") + \" \" + j\n",
    "    else:\n",
    "        name_dict[i] = name_dict.get(i, \"\") + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50443cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1.1',\n",
       "  '1.2',\n",
       "  '2.1',\n",
       "  '2.2',\n",
       "  '2.3',\n",
       "  '2.4',\n",
       "  '2.5',\n",
       "  '2.6',\n",
       "  '2.7',\n",
       "  '2.8',\n",
       "  '2.9',\n",
       "  '2.10',\n",
       "  '2.11',\n",
       "  '2.12',\n",
       "  '3.1',\n",
       "  '3.2',\n",
       "  '3.3',\n",
       "  '3.4',\n",
       "  '3.5',\n",
       "  '3.6',\n",
       "  '3.7',\n",
       "  '3.8',\n",
       "  '3.9',\n",
       "  '3.10',\n",
       "  '3.11',\n",
       "  '3.12',\n",
       "  '3.13',\n",
       "  '3.14',\n",
       "  '4.1',\n",
       "  '4.2',\n",
       "  '4.3',\n",
       "  '4.4',\n",
       "  '4.5',\n",
       "  '5.1',\n",
       "  '5.2',\n",
       "  '5.3',\n",
       "  '5.4',\n",
       "  '5.5',\n",
       "  '5.6',\n",
       "  '5.7',\n",
       "  '5.8',\n",
       "  '5.9',\n",
       "  '5.10',\n",
       "  '5.11',\n",
       "  '6.1',\n",
       "  '6.2',\n",
       "  '6.3',\n",
       "  '6.4',\n",
       "  '6.5',\n",
       "  '6.6',\n",
       "  '7.1',\n",
       "  '7.2',\n",
       "  '7.3',\n",
       "  '7.4',\n",
       "  '7.5',\n",
       "  '7.6',\n",
       "  '7.7',\n",
       "  '7.8',\n",
       "  '7.9',\n",
       "  '7.10',\n",
       "  '7.11',\n",
       "  '7.12',\n",
       "  '7.13',\n",
       "  '7.14',\n",
       "  '8.1',\n",
       "  '8.2',\n",
       "  '8.3',\n",
       "  '8.4',\n",
       "  '8.5',\n",
       "  '8.6',\n",
       "  '8.7',\n",
       "  '9.1',\n",
       "  '9.2',\n",
       "  '9.3',\n",
       "  '9.4',\n",
       "  '9.5',\n",
       "  '9.6',\n",
       "  '9.7',\n",
       "  '9.8',\n",
       "  '9.9',\n",
       "  '9.10',\n",
       "  '9.11',\n",
       "  '10.1',\n",
       "  '10.2',\n",
       "  '10.3',\n",
       "  '10.4',\n",
       "  '10.5',\n",
       "  '10.6',\n",
       "  '10.7',\n",
       "  '10.8',\n",
       "  '10.9',\n",
       "  '10.10',\n",
       "  '10.11',\n",
       "  '10.12',\n",
       "  '11.1',\n",
       "  '11.2',\n",
       "  '11.3',\n",
       "  '11.4',\n",
       "  '11.5',\n",
       "  '11.6',\n",
       "  '12.1',\n",
       "  '12.2',\n",
       "  '12.3',\n",
       "  '12.4',\n",
       "  '12.5',\n",
       "  '13.1',\n",
       "  '13.2',\n",
       "  '13.3',\n",
       "  '13.4',\n",
       "  '13.5',\n",
       "  '14.1',\n",
       "  '14.2',\n",
       "  '14.3',\n",
       "  '14.4',\n",
       "  '14.5',\n",
       "  '14.6',\n",
       "  '14.7',\n",
       "  '14.8',\n",
       "  '14.9',\n",
       "  '15.1',\n",
       "  '15.2',\n",
       "  '15.3',\n",
       "  '15.4',\n",
       "  '15.5',\n",
       "  '15.6',\n",
       "  '16.1',\n",
       "  '16.2',\n",
       "  '16.3',\n",
       "  '16.4',\n",
       "  '16.5',\n",
       "  '16.6',\n",
       "  '16.7',\n",
       "  '17.1',\n",
       "  '17.2',\n",
       "  '17.3',\n",
       "  '17.4',\n",
       "  '17.5',\n",
       "  '18.1',\n",
       "  '18.2',\n",
       "  '18.3',\n",
       "  '18.4',\n",
       "  '18.5',\n",
       "  '18.6',\n",
       "  '18.7',\n",
       "  '19.1',\n",
       "  '19.2',\n",
       "  '19.3',\n",
       "  '19.4',\n",
       "  '19.5',\n",
       "  '20.1',\n",
       "  '20.2',\n",
       "  '20.3',\n",
       "  '20.4',\n",
       "  '20.5',\n",
       "  '20.6',\n",
       "  '20.7',\n",
       "  '20.8',\n",
       "  '20.9',\n",
       "  '20.10',\n",
       "  '20.11',\n",
       "  '20.12',\n",
       "  '20.13',\n",
       "  '20.14',\n",
       "  '20.15'],\n",
       " ['8',\n",
       "  '11',\n",
       "  '31',\n",
       "  '34',\n",
       "  '36',\n",
       "  '37',\n",
       "  '39',\n",
       "  '40',\n",
       "  '42',\n",
       "  '44',\n",
       "  '45',\n",
       "  '46',\n",
       "  '47',\n",
       "  '48',\n",
       "  '54',\n",
       "  '56',\n",
       "  '56',\n",
       "  '58',\n",
       "  '59',\n",
       "  '59',\n",
       "  '60',\n",
       "  '60',\n",
       "  '62',\n",
       "  '67',\n",
       "  '70',\n",
       "  '71',\n",
       "  '73',\n",
       "  '75',\n",
       "  '80',\n",
       "  '82',\n",
       "  '82',\n",
       "  '93',\n",
       "  '96',\n",
       "  '99',\n",
       "  '110',\n",
       "  '120',\n",
       "  '122',\n",
       "  '131',\n",
       "  '135',\n",
       "  '140',\n",
       "  '146',\n",
       "  '151',\n",
       "  '153',\n",
       "  '155',\n",
       "  '171',\n",
       "  '177',\n",
       "  '191',\n",
       "  '197',\n",
       "  '204',\n",
       "  '224',\n",
       "  '230',\n",
       "  '237',\n",
       "  '239',\n",
       "  '240',\n",
       "  '242',\n",
       "  '243',\n",
       "  '244',\n",
       "  '246',\n",
       "  '253',\n",
       "  '254',\n",
       "  '256',\n",
       "  '258',\n",
       "  '268',\n",
       "  '270',\n",
       "  '275',\n",
       "  '282',\n",
       "  '294',\n",
       "  '301',\n",
       "  '306',\n",
       "  '310',\n",
       "  '317',\n",
       "  '331',\n",
       "  '335',\n",
       "  '339',\n",
       "  '345',\n",
       "  '347',\n",
       "  '358',\n",
       "  '360',\n",
       "  '362',\n",
       "  '363',\n",
       "  '364',\n",
       "  '371',\n",
       "  '375',\n",
       "  '378',\n",
       "  '394',\n",
       "  '396',\n",
       "  '398',\n",
       "  '400',\n",
       "  '401',\n",
       "  '404',\n",
       "  '406',\n",
       "  '408',\n",
       "  '413',\n",
       "  '416',\n",
       "  '422',\n",
       "  '425',\n",
       "  '426',\n",
       "  '427',\n",
       "  '436',\n",
       "  '440',\n",
       "  '443',\n",
       "  '452',\n",
       "  '458',\n",
       "  '461',\n",
       "  '478',\n",
       "  '490',\n",
       "  '491',\n",
       "  '493',\n",
       "  '496',\n",
       "  '499',\n",
       "  '503',\n",
       "  '504',\n",
       "  '508',\n",
       "  '509',\n",
       "  '510',\n",
       "  '515',\n",
       "  '521',\n",
       "  '523',\n",
       "  '524',\n",
       "  '528',\n",
       "  '536',\n",
       "  '541',\n",
       "  '546',\n",
       "  '553',\n",
       "  '554',\n",
       "  '559',\n",
       "  '563',\n",
       "  '580',\n",
       "  '582',\n",
       "  '582',\n",
       "  '584',\n",
       "  '585',\n",
       "  '590',\n",
       "  '592',\n",
       "  '595',\n",
       "  '599',\n",
       "  '599',\n",
       "  '606',\n",
       "  '607',\n",
       "  '615',\n",
       "  '617',\n",
       "  '619',\n",
       "  '620',\n",
       "  '623',\n",
       "  '633',\n",
       "  '634',\n",
       "  '635',\n",
       "  '638',\n",
       "  '651',\n",
       "  '654',\n",
       "  '656',\n",
       "  '660',\n",
       "  '663',\n",
       "  '676',\n",
       "  '683',\n",
       "  '685',\n",
       "  '686',\n",
       "  '687',\n",
       "  '692',\n",
       "  '711',\n",
       "  '714',\n",
       "  '716',\n",
       "  '717',\n",
       "  '720'],\n",
       " [('1', 'Introduction'),\n",
       "  ('1.1', 'Who'),\n",
       "  ('1.1', 'Should'),\n",
       "  ('1.1', 'Read'),\n",
       "  ('1.1', 'This'),\n",
       "  ('1.1', 'Book?'),\n",
       "  ('1.2', 'Historical'),\n",
       "  ('1.2', 'Trends'),\n",
       "  ('1.2', 'in'),\n",
       "  ('1.2', 'Deep'),\n",
       "  ('1.2', 'Learning'),\n",
       "  ('2', 'Linear'),\n",
       "  ('2', 'Algebra'),\n",
       "  ('2.1', 'Scalars,'),\n",
       "  ('2.1', 'Vectors,'),\n",
       "  ('2.1', 'Matrices'),\n",
       "  ('2.1', 'and'),\n",
       "  ('2.1', 'Tensors'),\n",
       "  ('2.2', 'Multiplying'),\n",
       "  ('2.2', 'Matrices'),\n",
       "  ('2.2', 'and'),\n",
       "  ('2.2', 'Vectors'),\n",
       "  ('2.3', 'Identity'),\n",
       "  ('2.3', 'and'),\n",
       "  ('2.3', 'Inverse'),\n",
       "  ('2.3', 'Matrices'),\n",
       "  ('2.4', 'Linear'),\n",
       "  ('2.4', 'Dependence'),\n",
       "  ('2.4', 'and'),\n",
       "  ('2.4', 'Span'),\n",
       "  ('2.5', 'Norms'),\n",
       "  ('2.6', 'Special'),\n",
       "  ('2.6', 'Kinds'),\n",
       "  ('2.6', 'of'),\n",
       "  ('2.6', 'Matrices'),\n",
       "  ('2.6', 'and'),\n",
       "  ('2.6', 'Vectors'),\n",
       "  ('2.7', 'Eigendecomposition'),\n",
       "  ('2.8', 'Singular'),\n",
       "  ('2.8', 'Value'),\n",
       "  ('2.8', 'Decomposition'),\n",
       "  ('2.9', 'The'),\n",
       "  ('2.9', 'Moore-Penrose'),\n",
       "  ('2.9', 'Pseudoinverse'),\n",
       "  ('2.10', 'The'),\n",
       "  ('2.10', 'Trace'),\n",
       "  ('2.10', 'Operator'),\n",
       "  ('2.11', 'The'),\n",
       "  ('2.11', 'Determinant'),\n",
       "  ('2.12', 'Example:'),\n",
       "  ('2.12', 'Principal'),\n",
       "  ('2.12', 'Components'),\n",
       "  ('2.12', 'Analysis'),\n",
       "  ('3', 'Probability'),\n",
       "  ('3', 'and'),\n",
       "  ('3', 'Information'),\n",
       "  ('3', 'Theory'),\n",
       "  ('3.1', 'Why'),\n",
       "  ('3.1', 'Probability?'),\n",
       "  ('3.2', 'Random'),\n",
       "  ('3.2', 'Variables'),\n",
       "  ('3.3', 'Probability'),\n",
       "  ('3.3', 'Distributions'),\n",
       "  ('3.4', 'Marginal'),\n",
       "  ('3.4', 'Probability'),\n",
       "  ('3.5', 'Conditional'),\n",
       "  ('3.5', 'Probability'),\n",
       "  ('3.6', 'The'),\n",
       "  ('3.6', 'Chain'),\n",
       "  ('3.6', 'Rule'),\n",
       "  ('3.6', 'of'),\n",
       "  ('3.6', 'Conditional'),\n",
       "  ('3.6', 'Probabilities'),\n",
       "  ('3.7', 'Independence'),\n",
       "  ('3.7', 'and'),\n",
       "  ('3.7', 'Conditional'),\n",
       "  ('3.7', 'Independence'),\n",
       "  ('3.8', 'Expectation,'),\n",
       "  ('3.8', 'Variance'),\n",
       "  ('3.8', 'and'),\n",
       "  ('3.8', 'Covariance'),\n",
       "  ('3.9', 'Common'),\n",
       "  ('3.9', 'Probability'),\n",
       "  ('3.9', 'Distributions'),\n",
       "  ('3.10', 'Useful'),\n",
       "  ('3.10', 'Properties'),\n",
       "  ('3.10', 'of'),\n",
       "  ('3.10', 'Common'),\n",
       "  ('3.10', 'Functions'),\n",
       "  ('3.11', 'Bayes’'),\n",
       "  ('3.11', 'Rule'),\n",
       "  ('3.12', 'Technical'),\n",
       "  ('3.12', 'Details'),\n",
       "  ('3.12', 'of'),\n",
       "  ('3.12', 'Continuous'),\n",
       "  ('3.12', 'Variables'),\n",
       "  ('3.13', 'Information'),\n",
       "  ('3.13', 'Theory'),\n",
       "  ('3.14', 'Structured'),\n",
       "  ('3.14', 'Probabilistic'),\n",
       "  ('3.14', 'Models'),\n",
       "  ('4', 'Numerical'),\n",
       "  ('4', 'Computation'),\n",
       "  ('4.1', 'Overflow'),\n",
       "  ('4.1', 'and'),\n",
       "  ('4.1', 'Underflow'),\n",
       "  ('4.2', 'Poor'),\n",
       "  ('4.2', 'Conditioning'),\n",
       "  ('4.3', 'Gradient-Based'),\n",
       "  ('4.3', 'Optimization'),\n",
       "  ('4.4', 'Constrained'),\n",
       "  ('4.4', 'Optimization'),\n",
       "  ('4.5', 'Example:'),\n",
       "  ('4.5', 'Linear'),\n",
       "  ('4.5', 'Least'),\n",
       "  ('4.5', 'Squares'),\n",
       "  ('5', 'Machine'),\n",
       "  ('5', 'Learning'),\n",
       "  ('5', 'Basics'),\n",
       "  ('5.1', 'Learning'),\n",
       "  ('5.1', 'Algorithms'),\n",
       "  ('5.2', 'Capacity,'),\n",
       "  ('5.2', 'Overfitting'),\n",
       "  ('5.2', 'and'),\n",
       "  ('5.2', 'Underfitting'),\n",
       "  ('5.3', 'Hyperparameters'),\n",
       "  ('5.3', 'and'),\n",
       "  ('5.3', 'Validation'),\n",
       "  ('5.3', 'Sets'),\n",
       "  ('5.4', 'Estimators,'),\n",
       "  ('5.4', 'Bias'),\n",
       "  ('5.4', 'and'),\n",
       "  ('5.4', 'Variance'),\n",
       "  ('5.5', 'Maximum'),\n",
       "  ('5.5', 'Likelihood'),\n",
       "  ('5.5', 'Estimation'),\n",
       "  ('5.6', 'Bayesian'),\n",
       "  ('5.6', 'Statistics'),\n",
       "  ('5.7', 'Supervised'),\n",
       "  ('5.7', 'Learning'),\n",
       "  ('5.7', 'Algorithms'),\n",
       "  ('5.8', 'Unsupervised'),\n",
       "  ('5.8', 'Learning'),\n",
       "  ('5.8', 'Algorithms'),\n",
       "  ('5.9', 'Stochastic'),\n",
       "  ('5.9', 'Gradient'),\n",
       "  ('5.9', 'Descent'),\n",
       "  ('5.10', 'Building'),\n",
       "  ('5.10', 'a'),\n",
       "  ('5.10', 'Machine'),\n",
       "  ('5.10', 'Learning'),\n",
       "  ('5.10', 'Algorithm'),\n",
       "  ('5.11', 'Challenges'),\n",
       "  ('5.11', 'Motivating'),\n",
       "  ('5.11', 'Deep'),\n",
       "  ('5.11', 'Learning'),\n",
       "  ('6', 'Deep'),\n",
       "  ('6', 'Feedforward'),\n",
       "  ('6', 'Networks'),\n",
       "  ('6.1', 'Example:'),\n",
       "  ('6.1', 'Learning'),\n",
       "  ('6.1', 'XOR'),\n",
       "  ('6.2', 'Gradient-Based'),\n",
       "  ('6.2', 'Learning'),\n",
       "  ('6.3', 'Hidden'),\n",
       "  ('6.3', 'Units'),\n",
       "  ('6.4', 'Architecture'),\n",
       "  ('6.4', 'Design'),\n",
       "  ('6.5', 'Back-Propagation'),\n",
       "  ('6.5', 'and'),\n",
       "  ('6.5', 'Other'),\n",
       "  ('6.5', 'Differentiation'),\n",
       "  ('6.5', 'Algorithms'),\n",
       "  ('6.6', 'Historical'),\n",
       "  ('6.6', 'Notes'),\n",
       "  ('7', 'Regularization'),\n",
       "  ('7', 'for'),\n",
       "  ('7', 'Deep'),\n",
       "  ('7', 'Learning'),\n",
       "  ('7.1', 'Parameter'),\n",
       "  ('7.1', 'Norm'),\n",
       "  ('7.1', 'Penalties'),\n",
       "  ('7.2', 'Norm'),\n",
       "  ('7.2', 'Penalties'),\n",
       "  ('7.2', 'as'),\n",
       "  ('7.2', 'Constrained'),\n",
       "  ('7.2', 'Optimization'),\n",
       "  ('7.3', 'Regularization'),\n",
       "  ('7.3', 'and'),\n",
       "  ('7.3', 'Under-Constrained'),\n",
       "  ('7.3', 'Problems'),\n",
       "  ('7.4', 'Dataset'),\n",
       "  ('7.4', 'Augmentation'),\n",
       "  ('7.5', 'Noise'),\n",
       "  ('7.5', 'Robustness'),\n",
       "  ('7.6', 'Semi-Supervised'),\n",
       "  ('7.6', 'Learning'),\n",
       "  ('7.7', 'Multi-Task'),\n",
       "  ('7.7', 'Learning'),\n",
       "  ('7.8', 'Early'),\n",
       "  ('7.8', 'Stopping'),\n",
       "  ('7.9', 'Parameter'),\n",
       "  ('7.9', 'Tying'),\n",
       "  ('7.9', 'and'),\n",
       "  ('7.9', 'Parameter'),\n",
       "  ('7.9', 'Sharing'),\n",
       "  ('7.10', 'Sparse'),\n",
       "  ('7.10', 'Representations'),\n",
       "  ('7.11', 'Bagging'),\n",
       "  ('7.11', 'and'),\n",
       "  ('7.11', 'Other'),\n",
       "  ('7.11', 'Ensemble'),\n",
       "  ('7.11', 'Methods'),\n",
       "  ('7.12', 'Dropout'),\n",
       "  ('7.13', 'Adversarial'),\n",
       "  ('7.13', 'Training'),\n",
       "  ('7.14', 'Tangent'),\n",
       "  ('7.14', 'Distance,'),\n",
       "  ('7.14', 'Tangent'),\n",
       "  ('7.14', 'Prop,'),\n",
       "  ('7.14', 'and'),\n",
       "  ('7.14', 'Manifold'),\n",
       "  ('7.14', 'Tangent'),\n",
       "  ('7.14', 'Classifier'),\n",
       "  ('8', 'Optimization'),\n",
       "  ('8', 'for'),\n",
       "  ('8', 'Training'),\n",
       "  ('8', 'Deep'),\n",
       "  ('8', 'Models'),\n",
       "  ('8.1', 'How'),\n",
       "  ('8.1', 'Learning'),\n",
       "  ('8.1', 'Differs'),\n",
       "  ('8.1', 'from'),\n",
       "  ('8.1', 'Pure'),\n",
       "  ('8.1', 'Optimization'),\n",
       "  ('8.2', 'Challenges'),\n",
       "  ('8.2', 'in'),\n",
       "  ('8.2', 'Neural'),\n",
       "  ('8.2', 'Network'),\n",
       "  ('8.2', 'Optimization'),\n",
       "  ('8.3', 'Basic'),\n",
       "  ('8.3', 'Algorithms'),\n",
       "  ('8.4', 'Parameter'),\n",
       "  ('8.4', 'Initialization'),\n",
       "  ('8.4', 'Strategies'),\n",
       "  ('8.5', 'Algorithms'),\n",
       "  ('8.5', 'with'),\n",
       "  ('8.5', 'Adaptive'),\n",
       "  ('8.5', 'Learning'),\n",
       "  ('8.5', 'Rates'),\n",
       "  ('8.6', 'Approximate'),\n",
       "  ('8.6', 'Second-Order'),\n",
       "  ('8.6', 'Methods'),\n",
       "  ('8.7', 'Optimization'),\n",
       "  ('8.7', 'Strategies'),\n",
       "  ('8.7', 'and'),\n",
       "  ('8.7', 'Meta-Algorithms'),\n",
       "  ('9', 'Convolutional'),\n",
       "  ('9', 'Networks'),\n",
       "  ('9.1', 'The'),\n",
       "  ('9.1', 'Convolution'),\n",
       "  ('9.1', 'Operation'),\n",
       "  ('9.2', 'Motivation'),\n",
       "  ('9.3', 'Pooling'),\n",
       "  ('9.4', 'Convolution'),\n",
       "  ('9.4', 'and'),\n",
       "  ('9.4', 'Pooling'),\n",
       "  ('9.4', 'as'),\n",
       "  ('9.4', 'an'),\n",
       "  ('9.4', 'Infinitely'),\n",
       "  ('9.4', 'Strong'),\n",
       "  ('9.4', 'Prior'),\n",
       "  ('9.5', 'Variants'),\n",
       "  ('9.5', 'of'),\n",
       "  ('9.5', 'the'),\n",
       "  ('9.5', 'Basic'),\n",
       "  ('9.5', 'Convolution'),\n",
       "  ('9.5', 'Function'),\n",
       "  ('9.6', 'Structured'),\n",
       "  ('9.6', 'Outputs'),\n",
       "  ('9.7', 'Data'),\n",
       "  ('9.7', 'Types'),\n",
       "  ('9.8', 'Efficient'),\n",
       "  ('9.8', 'Convolution'),\n",
       "  ('9.8', 'Algorithms'),\n",
       "  ('9.9', 'Random'),\n",
       "  ('9.9', 'or'),\n",
       "  ('9.9', 'Unsupervised'),\n",
       "  ('9.9', 'Features'),\n",
       "  ('9.10', 'The'),\n",
       "  ('9.10', 'Neuroscientific'),\n",
       "  ('9.10', 'Basis'),\n",
       "  ('9.10', 'for'),\n",
       "  ('9.10', 'Convolutional'),\n",
       "  ('9.10', 'Networks'),\n",
       "  ('9.11', 'Convolutional'),\n",
       "  ('9.11', 'Networks'),\n",
       "  ('9.11', 'and'),\n",
       "  ('9.11', 'the'),\n",
       "  ('9.11', 'History'),\n",
       "  ('9.11', 'of'),\n",
       "  ('9.11', 'Deep'),\n",
       "  ('9.11', 'Learning'),\n",
       "  ('10', 'Sequence'),\n",
       "  ('10', 'Modeling:'),\n",
       "  ('10', 'Recurrent'),\n",
       "  ('10', 'and'),\n",
       "  ('10', 'Recursive'),\n",
       "  ('10', 'Nets'),\n",
       "  ('10.1', 'Unfolding'),\n",
       "  ('10.1', 'Computational'),\n",
       "  ('10.1', 'Graphs'),\n",
       "  ('10.2', 'Recurrent'),\n",
       "  ('10.2', 'Neural'),\n",
       "  ('10.2', 'Networks'),\n",
       "  ('10.3', 'Bidirectional'),\n",
       "  ('10.3', 'RNNs'),\n",
       "  ('10.4', 'Encoder-Decoder'),\n",
       "  ('10.4', 'Sequence-to-Sequence'),\n",
       "  ('10.4', 'Architectures'),\n",
       "  ('10.5', 'Deep'),\n",
       "  ('10.5', 'Recurrent'),\n",
       "  ('10.5', 'Networks'),\n",
       "  ('10.6', 'Recursive'),\n",
       "  ('10.6', 'Neural'),\n",
       "  ('10.6', 'Networks'),\n",
       "  ('10.7', 'The'),\n",
       "  ('10.7', 'Challenge'),\n",
       "  ('10.7', 'of'),\n",
       "  ('10.7', 'Long-Term'),\n",
       "  ('10.7', 'Dependencies'),\n",
       "  ('10.8', 'Echo'),\n",
       "  ('10.8', 'State'),\n",
       "  ('10.8', 'Networks'),\n",
       "  ('10.9', 'Leaky'),\n",
       "  ('10.9', 'Units'),\n",
       "  ('10.9', 'and'),\n",
       "  ('10.9', 'Other'),\n",
       "  ('10.9', 'Strategies'),\n",
       "  ('10.9', 'for'),\n",
       "  ('10.9', 'Multiple'),\n",
       "  ('10.9', 'Time'),\n",
       "  ('10.9', 'Scales'),\n",
       "  ('10.10', 'The'),\n",
       "  ('10.10', 'Long'),\n",
       "  ('10.10', 'Short-Term'),\n",
       "  ('10.10', 'Memory'),\n",
       "  ('10.10', 'and'),\n",
       "  ('10.10', 'Other'),\n",
       "  ('10.10', 'Gated'),\n",
       "  ('10.10', 'RNNs'),\n",
       "  ('10.11', 'Optimization'),\n",
       "  ('10.11', 'for'),\n",
       "  ('10.11', 'Long-Term'),\n",
       "  ('10.11', 'Dependencies'),\n",
       "  ('10.12', 'Explicit'),\n",
       "  ('10.12', 'Memory'),\n",
       "  ('11', 'Practical'),\n",
       "  ('11', 'Methodology'),\n",
       "  ('11.1', 'Performance'),\n",
       "  ('11.1', 'Metrics'),\n",
       "  ('11.2', 'Default'),\n",
       "  ('11.2', 'Baseline'),\n",
       "  ('11.2', 'Models'),\n",
       "  ('11.3', 'Determining'),\n",
       "  ('11.3', 'Whether'),\n",
       "  ('11.3', 'to'),\n",
       "  ('11.3', 'Gather'),\n",
       "  ('11.3', 'More'),\n",
       "  ('11.3', 'Data'),\n",
       "  ('11.4', 'Selecting'),\n",
       "  ('11.4', 'Hyperparameters'),\n",
       "  ('11.5', 'Debugging'),\n",
       "  ('11.5', 'Strategies'),\n",
       "  ('11.6', 'Example:'),\n",
       "  ('11.6', 'Multi-Digit'),\n",
       "  ('11.6', 'Number'),\n",
       "  ('11.6', 'Recognition'),\n",
       "  ('12', 'Applications'),\n",
       "  ('12.1', 'Large-Scale'),\n",
       "  ('12.1', 'Deep'),\n",
       "  ('12.1', 'Learning'),\n",
       "  ('12.2', 'Computer'),\n",
       "  ('12.2', 'Vision'),\n",
       "  ('12.3', 'Speech'),\n",
       "  ('12.3', 'Recognition'),\n",
       "  ('12.4', 'Natural'),\n",
       "  ('12.4', 'Language'),\n",
       "  ('12.4', 'Processing'),\n",
       "  ('12.5', 'Other'),\n",
       "  ('12.5', 'Applications'),\n",
       "  ('13', 'Linear'),\n",
       "  ('13', 'Factor'),\n",
       "  ('13', 'Models'),\n",
       "  ('13.1', 'Probabilistic'),\n",
       "  ('13.1', 'PCA'),\n",
       "  ('13.1', 'and'),\n",
       "  ('13.1', 'Factor'),\n",
       "  ('13.1', 'Analysis'),\n",
       "  ('13.2', 'Independent'),\n",
       "  ('13.2', 'Component'),\n",
       "  ('13.2', 'Analysis'),\n",
       "  ('13.3', 'Slow'),\n",
       "  ('13.3', 'Feature'),\n",
       "  ('13.3', 'Analysis'),\n",
       "  ('13.4', 'Sparse'),\n",
       "  ('13.4', 'Coding'),\n",
       "  ('13.5', 'Manifold'),\n",
       "  ('13.5', 'Interpretation'),\n",
       "  ('13.5', 'of'),\n",
       "  ('13.5', 'PCA'),\n",
       "  ('14', 'Autoencoders'),\n",
       "  ('14.1', 'Undercomplete'),\n",
       "  ('14.1', 'Autoencoders'),\n",
       "  ('14.2', 'Regularized'),\n",
       "  ('14.2', 'Autoencoders'),\n",
       "  ('14.3', 'Representational'),\n",
       "  ('14.3', 'Power,'),\n",
       "  ('14.3', 'Layer'),\n",
       "  ('14.3', 'Size'),\n",
       "  ('14.3', 'and'),\n",
       "  ('14.3', 'Depth'),\n",
       "  ('14.4', 'Stochastic'),\n",
       "  ('14.4', 'Encoders'),\n",
       "  ('14.4', 'and'),\n",
       "  ('14.4', 'Decoders'),\n",
       "  ('14.5', 'Denoising'),\n",
       "  ('14.5', 'Autoencoders'),\n",
       "  ('14.6', 'Learning'),\n",
       "  ('14.6', 'Manifolds'),\n",
       "  ('14.6', 'with'),\n",
       "  ('14.6', 'Autoencoders'),\n",
       "  ('14.7', 'Contractive'),\n",
       "  ('14.7', 'Autoencoders'),\n",
       "  ('14.8', 'Predictive'),\n",
       "  ('14.8', 'Sparse'),\n",
       "  ('14.8', 'Decomposition'),\n",
       "  ('14.9', 'Applications'),\n",
       "  ('14.9', 'of'),\n",
       "  ('14.9', 'Autoencoders'),\n",
       "  ('15', 'Representation'),\n",
       "  ('15', 'Learning'),\n",
       "  ('15.1', 'Greedy'),\n",
       "  ('15.1', 'Layer-Wise'),\n",
       "  ('15.1', 'Unsupervised'),\n",
       "  ('15.1', 'Pretraining'),\n",
       "  ('15.2', 'Transfer'),\n",
       "  ('15.2', 'Learning'),\n",
       "  ('15.2', 'and'),\n",
       "  ('15.2', 'Domain'),\n",
       "  ('15.2', 'Adaptation'),\n",
       "  ('15.3', 'Semi-Supervised'),\n",
       "  ('15.3', 'Disentangling'),\n",
       "  ('15.3', 'of'),\n",
       "  ('15.3', 'Causal'),\n",
       "  ('15.3', 'Factors'),\n",
       "  ('15.4', 'Distributed'),\n",
       "  ('15.4', 'Representation'),\n",
       "  ('15.5', 'Exponential'),\n",
       "  ('15.5', 'Gains'),\n",
       "  ('15.5', 'from'),\n",
       "  ('15.5', 'Depth'),\n",
       "  ('15.6', 'Providing'),\n",
       "  ('15.6', 'Clues'),\n",
       "  ('15.6', 'to'),\n",
       "  ('15.6', 'Discover'),\n",
       "  ('15.6', 'Underlying'),\n",
       "  ('15.6', 'Causes'),\n",
       "  ('16', 'Structured'),\n",
       "  ('16', 'Probabilistic'),\n",
       "  ('16', 'Models'),\n",
       "  ('16', 'for'),\n",
       "  ('16', 'Deep'),\n",
       "  ('16', 'Learning'),\n",
       "  ('16.1', 'The'),\n",
       "  ('16.1', 'Challenge'),\n",
       "  ('16.1', 'of'),\n",
       "  ('16.1', 'Unstructured'),\n",
       "  ('16.1', 'Modeling'),\n",
       "  ('16.2', 'Using'),\n",
       "  ('16.2', 'Graphs'),\n",
       "  ('16.2', 'to'),\n",
       "  ('16.2', 'Describe'),\n",
       "  ('16.2', 'Model'),\n",
       "  ('16.2', 'Structure'),\n",
       "  ('16.3', 'Sampling'),\n",
       "  ('16.3', 'from'),\n",
       "  ('16.3', 'Graphical'),\n",
       "  ('16.3', 'Models'),\n",
       "  ('16.4', 'Advantages'),\n",
       "  ('16.4', 'of'),\n",
       "  ('16.4', 'Structured'),\n",
       "  ('16.4', 'Modeling'),\n",
       "  ('16.5', 'Learning'),\n",
       "  ('16.5', 'about'),\n",
       "  ('16.5', 'Dependencies'),\n",
       "  ('16.6', 'Inference'),\n",
       "  ('16.6', 'and'),\n",
       "  ('16.6', 'Approximate'),\n",
       "  ('16.6', 'Inference'),\n",
       "  ('16.7', 'The'),\n",
       "  ('16.7', 'Deep'),\n",
       "  ('16.7', 'Learning'),\n",
       "  ('16.7', 'Approach'),\n",
       "  ('16.7', 'to'),\n",
       "  ('16.7', 'Structured'),\n",
       "  ('16.7', 'Probabilistic'),\n",
       "  ('16.7', 'Models'),\n",
       "  ('17', 'Monte'),\n",
       "  ('17', 'Carlo'),\n",
       "  ('17', 'Methods'),\n",
       "  ('17.1', 'Sampling'),\n",
       "  ('17.1', 'and'),\n",
       "  ('17.1', 'Monte'),\n",
       "  ('17.1', 'Carlo'),\n",
       "  ('17.1', 'Methods'),\n",
       "  ('17.2', 'Importance'),\n",
       "  ('17.2', 'Sampling'),\n",
       "  ('17.3', 'Markov'),\n",
       "  ('17.3', 'Chain'),\n",
       "  ('17.3', 'Monte'),\n",
       "  ('17.3', 'Carlo'),\n",
       "  ('17.3', 'Methods'),\n",
       "  ('17.4', 'Gibbs'),\n",
       "  ('17.4', 'Sampling'),\n",
       "  ('17.5', 'The'),\n",
       "  ('17.5', 'Challenge'),\n",
       "  ('17.5', 'of'),\n",
       "  ('17.5', 'Mixing'),\n",
       "  ('17.5', 'between'),\n",
       "  ('17.5', 'Separated'),\n",
       "  ('17.5', 'Modes'),\n",
       "  ('18', 'Confronting'),\n",
       "  ('18', 'the'),\n",
       "  ('18', 'Partition'),\n",
       "  ('18', 'Function'),\n",
       "  ('18.1', 'The'),\n",
       "  ('18.1', 'Log-Likelihood'),\n",
       "  ('18.1', 'Gradient'),\n",
       "  ('18.2', 'Stochastic'),\n",
       "  ('18.2', 'Maximum'),\n",
       "  ('18.2', 'Likelihood'),\n",
       "  ('18.2', 'and'),\n",
       "  ('18.2', 'Contrastive'),\n",
       "  ('18.2', 'Divergence'),\n",
       "  ('18.3', 'Pseudolikelihood'),\n",
       "  ('18.4', 'Score'),\n",
       "  ('18.4', 'Matching'),\n",
       "  ('18.4', 'and'),\n",
       "  ('18.4', 'Ratio'),\n",
       "  ('18.4', 'Matching'),\n",
       "  ('18.5', 'Denoising'),\n",
       "  ('18.5', 'Score'),\n",
       "  ('18.5', 'Matching'),\n",
       "  ('18.6', 'Noise-Contrastive'),\n",
       "  ('18.6', 'Estimation'),\n",
       "  ('18.7', 'Estimating'),\n",
       "  ('18.7', 'the'),\n",
       "  ('18.7', 'Partition'),\n",
       "  ('18.7', 'Function'),\n",
       "  ('19', 'Approximate'),\n",
       "  ('19', 'Inference'),\n",
       "  ('19.1', 'Inference'),\n",
       "  ('19.1', 'as'),\n",
       "  ('19.1', 'Optimization'),\n",
       "  ('19.2', 'Expectation'),\n",
       "  ('19.2', 'Maximization'),\n",
       "  ('19.3', 'MAP'),\n",
       "  ('19.3', 'Inference'),\n",
       "  ('19.3', 'and'),\n",
       "  ('19.3', 'Sparse'),\n",
       "  ('19.3', 'Coding'),\n",
       "  ('19.4', 'Variational'),\n",
       "  ('19.4', 'Inference'),\n",
       "  ('19.4', 'and'),\n",
       "  ('19.4', 'Learning'),\n",
       "  ('19.5', 'Learned'),\n",
       "  ('19.5', 'Approximate'),\n",
       "  ('19.5', 'Inference'),\n",
       "  ('20', 'Deep'),\n",
       "  ('20', 'Generative'),\n",
       "  ('20', 'Models'),\n",
       "  ('20.1', 'Boltzmann'),\n",
       "  ('20.1', 'Machines'),\n",
       "  ('20.2', 'Restricted'),\n",
       "  ('20.2', 'Boltzmann'),\n",
       "  ('20.2', 'Machines'),\n",
       "  ('20.3', 'Deep'),\n",
       "  ('20.3', 'Belief'),\n",
       "  ('20.3', 'Networks'),\n",
       "  ('20.4', 'Deep'),\n",
       "  ('20.4', 'Boltzmann'),\n",
       "  ('20.4', 'Machines'),\n",
       "  ('20.5', 'Boltzmann'),\n",
       "  ('20.5', 'Machines'),\n",
       "  ('20.5', 'for'),\n",
       "  ('20.5', 'Real-Valued'),\n",
       "  ('20.5', 'Data'),\n",
       "  ('20.6', 'Convolutional'),\n",
       "  ('20.6', 'Boltzmann'),\n",
       "  ('20.6', 'Machines'),\n",
       "  ('20.7', 'Boltzmann'),\n",
       "  ('20.7', 'Machines'),\n",
       "  ('20.7', 'for'),\n",
       "  ('20.7', 'Structured'),\n",
       "  ('20.7', 'or'),\n",
       "  ('20.7', 'Sequential'),\n",
       "  ('20.7', 'Outputs'),\n",
       "  ('20.8', 'Other'),\n",
       "  ('20.8', 'Boltzmann'),\n",
       "  ('20.8', 'Machines'),\n",
       "  ('20.9', 'Back-Propagation'),\n",
       "  ('20.9', 'through'),\n",
       "  ('20.9', 'Random'),\n",
       "  ('20.9', 'Operations'),\n",
       "  ('20.10', 'Directed'),\n",
       "  ('20.10', 'Generative'),\n",
       "  ('20.10', 'Nets'),\n",
       "  ('20.11', 'Drawing'),\n",
       "  ('20.11', 'Samples'),\n",
       "  ('20.11', 'from'),\n",
       "  ('20.11', 'Autoencoders'),\n",
       "  ('20.12', 'Generative'),\n",
       "  ('20.12', 'Stochastic'),\n",
       "  ('20.12', 'Networks'),\n",
       "  ('20.13', 'Other'),\n",
       "  ('20.13', 'Generation'),\n",
       "  ('20.13', 'Schemes'),\n",
       "  ('20.14', 'Evaluating'),\n",
       "  ('20.14', 'Generative'),\n",
       "  ('20.14', 'Models'),\n",
       "  ('20.15', 'Conclusion')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, p, n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6bbf5",
   "metadata": {},
   "source": [
    "### index_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "98571f7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_range = list(zip(p, p[1:]))\n",
    "p_range.append((720, 800))\n",
    "c_p_range = list(zip(c, p_range))\n",
    "index_dict = collections.defaultdict(list)\n",
    "for k, v in c_p_range:\n",
    "    index_dict[k.split(\".\")[0]].append((k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f3cc333a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2.1', ('31', '34')),\n",
       " ('2.2', ('34', '36')),\n",
       " ('2.3', ('36', '37')),\n",
       " ('2.4', ('37', '39')),\n",
       " ('2.5', ('39', '40')),\n",
       " ('2.6', ('40', '42')),\n",
       " ('2.7', ('42', '44')),\n",
       " ('2.8', ('44', '45')),\n",
       " ('2.9', ('45', '46')),\n",
       " ('2.10', ('46', '47')),\n",
       " ('2.11', ('47', '48')),\n",
       " ('2.12', ('48', '54'))]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dict[\"2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b056028",
   "metadata": {},
   "source": [
    "## 生成内容表\n",
    "\n",
    "- 段落内容表：`content_dict`\n",
    "- 句子内容表：`sentence_dict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7993e527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pdfplumber.open(\n",
    "    \"./Deep Learning (Ian Goodfellow, Yoshua Bengio, Aaron Courville).pdf\"\n",
    ") as f:\n",
    "    content_dict = collections.defaultdict(list)\n",
    "\n",
    "    sentence_dict = collections.defaultdict(list)\n",
    "\n",
    "    for k, v in index_dict.items():\n",
    "        for i in v:\n",
    "            page_range = i[-1]\n",
    "\n",
    "            for j in range(int(page_range[0]), int(page_range[1])):\n",
    "                page = f.pages[j]\n",
    "\n",
    "                text = page.extract_text().replace(\"\\n\", \" \")\n",
    "\n",
    "                content_dict[i[0]].append(text)\n",
    "\n",
    "                text_split = text.split(\".\")\n",
    "\n",
    "                for t in text_split:\n",
    "                    sentence_dict[i[0]].append(t)\n",
    "\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab4ebf0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CONTENTS Chapter 15, Representation Learning: Kunal Ghosh. • Chapter 16, Structured Probabilistic Models for Deep Learning: Minh Lê • and Anton Varfolom. Chapter 18, Confronting the Partition Function: Sam Bowman. • Chapter 19, Approximate Inference: Yujia Bao. • Chapter 20, Deep Generative Models: Nicolas Chapados, Daniel Galvez, • Wenming Ma, Fady Medhat, Shakir Mohamed and Grégoire Montavon. Bibliography: Lukas Michelbacher and Leslie N. Smith. • We also want to thank those who allowed us to reproduce images, figures or data from their publications. We indicate their contributions in the figure captions throughout the text. We would like to thank Lu Wang for writing pdf2htmlEX, which we used to make the web version of the book, and for offering support to improve the quality of the resulting HTML. We would like to thank Ian’s wife Daniela Flori Goodfellow for patiently supporting Ian during the writing of the book as well as for help with proofreading. We would like to thank the Google Brain team for providing an intellectual environment where Ian could devote a tremendous amount of time to writing this book and receive feedback and guidance from colleagues. We would especially like to thank Ian’s former manager, Greg Corrado, and his current manager, Samy Bengio, for their support of this project. Finally, we would like to thank Geoffrey Hinton for encouragement when writing was difficult. x'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_dict[\"1.1\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "84fd4cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Acknowledgments This book would not have been possible without the contributions of many people'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_dict[\"1.1\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5849673",
   "metadata": {},
   "source": [
    "## 一些其他尝试\n",
    "\n",
    "N - Gram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "849fd60d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 暂时没有探索结果\n",
    "# all_text = re.sub('[^A-Za-z0-9\\.]+', ' ', text).lower().split(' ')\n",
    "# ng1 = collections.defaultdict(int)\n",
    "# ng2 = collections.defaultdict(int)\n",
    "# ng3 = collections.defaultdict(int)\n",
    "# ng4 = collections.defaultdict(int)\n",
    "# for i, j in enumerate(all_text):\n",
    "#     ng1[j] += 1\n",
    "#     if i > 0: ng2[(all_text[i-1], j)] += 1\n",
    "#     if i > 1: ng3[(all_text[i-2], all_text[i-1], j)] += 1\n",
    "#     if i > 2: ng4[(all_text[i-3], all_text[i-2], all_text[i-1], j)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c7e91ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sort_feq(dic):\n",
    "    return sorted([(k, v) for k, v in dic.items()], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad64b84f",
   "metadata": {},
   "source": [
    "# 定义 Chat 类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e486417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_counts(response):\n",
    "    tokens_nums = int(response[\"usage\"][\"total_tokens\"])\n",
    "    price = 0.002 / 1000\n",
    "    cost = \"{:.5f}\".format(price * tokens_nums * 7.5)\n",
    "    print(f\"tokens: {tokens_nums}, cost: {cost}\")\n",
    "\n",
    "    return float(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "aaf30deb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, conversation_list=[]):\n",
    "        self.conversation_list = conversation_list\n",
    "        self.costs_list = []\n",
    "\n",
    "    def show_conversation(self, msg_list):\n",
    "        for msg in msg_list[-2:]:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                pass\n",
    "            else:\n",
    "                message = msg[\"content\"]\n",
    "                print(f\"\\U0001f47D: {message}\\n\")\n",
    "            print()\n",
    "\n",
    "    def ask(self, prompt):\n",
    "        self.conversation_list.append({\"role\": \"user\", \"content\": prompt})\n",
    "        openai.api_key = \"sk-D1u13WweY1LhWLqv95Ml7e3y8f8ToSfsTkGnlgvSQLqZJptC\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\", messages=self.conversation_list\n",
    "        )\n",
    "        answer = response.choices[0].message[\"content\"]\n",
    "\n",
    "        self.conversation_list.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.show_conversation(self.conversation_list)\n",
    "\n",
    "        cost = total_counts(response)\n",
    "        self.costs_list.append(cost)\n",
    "        return answer\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda55af9",
   "metadata": {},
   "source": [
    "# 测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98291941",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = [\"目录\", \"前置\", \"句子共现\", \"段落共现\", \"频繁项集\"]  # pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c567c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_list = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"请只提取文本中的命名实体，格式为[{entity_A}, {entity_B}, ...], 不要返回任何其他内容\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a40caefe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👽: [{\"Charlie Gorichanaz\"}, {\"Brendan Loudermilk\"}, {\"Eric Morris\"}, {\"Cosmin Pârvulescu\"}, {\"Alfredo Solano\"}, {\"Chapter 2\"}, {\"Amjad Almahairi\"}, {\"Nikola Banić\"}, {\"Kevin Bennett\"}, {\"Philippe Castonguay\"}, {\"Oscar Chang\"}, {\"Eric Fosler-Lussier\"}, {\"Andrey Khalyavin\"}, {\"Sergey Oreshkov\"}, {\"István Petrás\"}, {\"Dennis Prangle\"}, {\"Thomas Rohée\"}, {\"Gitanjali Gulve Sehgal\"}, {\"Colby Toland\"}, {\"Alessandro Vitale\"}, {\"Bob Welland\"}, {\"Chapter 3\"}, {\"John Philip Anderson\"}, {\"Kai Arulkumaran\"}, {\"Vincent Dumoulin\"}, {\"Rui Fa\"}, {\"Stephan Gouws\"}, {\"Artem Oboturov\"}, {\"Antti Rasmus\"}, {\"Alexey Surkov\"}, {\"Volker Tresp\"}, {\"Chapter 4\"}, {\"Tran Lam AnIan Fischer\"}, {\"Hu Yuhuang\"}, {\"Chapter 5\"}, {\"Dzmitry Bahdanau\"}, {\"Justin Domingue\"}, {\"Nikhil Garg\"}, {\"Makoto Otsuka\"}, {\"Bob Pepin\"}, {\"Philip Popien\"}, {\"Emmanuel Rayner\"}, {\"Peter Shepard\"}, {\"Kee-Bong Song\"}, {\"Zheng Sun\"}, {\"Andy Wu\"}, {\"Chapter 6\"}, {\"Uriel Berdugo\"}, {\"Fabrizio Bottarel\"}, {\"Elizabeth Burl\"}, {\"Ishan Durugkar\"}, {\"Jeff Hlywa\"}, {\"Jong Wook Kim\"}, {\"David Krueger\"}, {\"Aditya Kumar Praharaj\"}, {\"Chapter 7\"}, {\"Morten Kolbæk\"}, {\"Kshitij Lauria\"}, {\"Inkyu Lee\"}, {\"Sunil Mohan\"}, {\"Hai Phong Phan\"}, {\"Joshua Salisbury\"}, {\"Chapter 8\"}, {\"Marcel Ackermann\"}, {\"Peter Armitage\"}, {\"Rowel Atienza\"}, {\"Andrew Brock\"}, {\"Tegan Maharaj\"}, {\"James Martens\"}, {\"Kashif Rasul\"}, {\"Klaus Strobl\"}, {\"Nicholas Turner\"}, {\"Chapter 9\"}, {\"Martín Arjovsky\"}, {\"Eugene Brevdo\"}, {\"Konstantin Divilov\"}, {\"Eric Jensen\"}, {\"Mehdi Mirza\"}, {\"Alex Paino\"}, {\"Marjorie Sayer\"}, {\"Ryan Stout\"}, {\"Wentao Wu\"}, {\"Chapter 10\"}, {\"Gökçen Eraslan\"}, {\"Steven Hickson\"}, {\"Razvan Pascanu\"}, {\"Lorenzo von Ritter\"}, {\"Rui Rodrigues\"}, {\"Dmitriy Serdyuk\"}, {\"Dongyu Shi\"}, {\"Kaiyu Yang\"}, {\"Chapter 11\"}, {\"Daniel Beckstein\"}, {\"Chapter 12\"}, {\"George Dahl\"}, {\"Vladimir Nekrasov\"}, {\"Ribana Roscher\"}, {\"Chapter 13\"}, {\"Jayanth Koushik\"}]\n",
      "\n",
      "\n",
      "tokens: 4006, cost: 0.06009\n"
     ]
    }
   ],
   "source": [
    "bot = Chat(conversation_list)\n",
    "answer = bot.ask(content_dict[\"1.1\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e817f706",
   "metadata": {},
   "source": [
    "### 测试结果\n",
    "\n",
    "可以看到效果还不错，但是 GPT3.5 有一些比较致命的问题，它抽出的命名实体甚至有可能都**不在原文中**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c2292fbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Charlie Gorichanaz',\n",
       " 'Brendan Loudermilk',\n",
       " 'Eric Morris',\n",
       " 'Cosmin Pârvulescu',\n",
       " 'Alfredo Solano',\n",
       " 'Chapter 2',\n",
       " 'Amjad Almahairi',\n",
       " 'Nikola Banić',\n",
       " 'Kevin Bennett',\n",
       " 'Philippe Castonguay',\n",
       " 'Oscar Chang',\n",
       " 'Eric Fosler-Lussier',\n",
       " 'Andrey Khalyavin',\n",
       " 'Sergey Oreshkov',\n",
       " 'István Petrás',\n",
       " 'Dennis Prangle',\n",
       " 'Thomas Rohée',\n",
       " 'Gitanjali Gulve Sehgal',\n",
       " 'Colby Toland',\n",
       " 'Alessandro Vitale',\n",
       " 'Bob Welland',\n",
       " 'Chapter 3',\n",
       " 'John Philip Anderson',\n",
       " 'Kai Arulkumaran',\n",
       " 'Vincent Dumoulin',\n",
       " 'Rui Fa',\n",
       " 'Stephan Gouws',\n",
       " 'Artem Oboturov',\n",
       " 'Antti Rasmus',\n",
       " 'Alexey Surkov',\n",
       " 'Volker Tresp',\n",
       " 'Chapter 4',\n",
       " 'Tran Lam AnIan Fischer',\n",
       " 'Hu Yuhuang',\n",
       " 'Chapter 5',\n",
       " 'Dzmitry Bahdanau',\n",
       " 'Justin Domingue',\n",
       " 'Nikhil Garg',\n",
       " 'Makoto Otsuka',\n",
       " 'Bob Pepin',\n",
       " 'Philip Popien',\n",
       " 'Emmanuel Rayner',\n",
       " 'Peter Shepard',\n",
       " 'Kee-Bong Song',\n",
       " 'Zheng Sun',\n",
       " 'Andy Wu',\n",
       " 'Chapter 6',\n",
       " 'Uriel Berdugo',\n",
       " 'Fabrizio Bottarel',\n",
       " 'Elizabeth Burl',\n",
       " 'Ishan Durugkar',\n",
       " 'Jeff Hlywa',\n",
       " 'Jong Wook Kim',\n",
       " 'David Krueger',\n",
       " 'Aditya Kumar Praharaj',\n",
       " 'Chapter 7',\n",
       " 'Morten Kolbæk',\n",
       " 'Kshitij Lauria',\n",
       " 'Inkyu Lee',\n",
       " 'Sunil Mohan',\n",
       " 'Hai Phong Phan',\n",
       " 'Joshua Salisbury',\n",
       " 'Chapter 8',\n",
       " 'Marcel Ackermann',\n",
       " 'Peter Armitage',\n",
       " 'Rowel Atienza',\n",
       " 'Andrew Brock',\n",
       " 'Tegan Maharaj',\n",
       " 'James Martens',\n",
       " 'Kashif Rasul',\n",
       " 'Klaus Strobl',\n",
       " 'Nicholas Turner',\n",
       " 'Chapter 9',\n",
       " 'Martín Arjovsky',\n",
       " 'Eugene Brevdo',\n",
       " 'Konstantin Divilov',\n",
       " 'Eric Jensen',\n",
       " 'Mehdi Mirza',\n",
       " 'Alex Paino',\n",
       " 'Marjorie Sayer',\n",
       " 'Ryan Stout',\n",
       " 'Wentao Wu',\n",
       " 'Chapter 10',\n",
       " 'Gökçen Eraslan',\n",
       " 'Steven Hickson',\n",
       " 'Razvan Pascanu',\n",
       " 'Lorenzo von Ritter',\n",
       " 'Rui Rodrigues',\n",
       " 'Dmitriy Serdyuk',\n",
       " 'Dongyu Shi',\n",
       " 'Kaiyu Yang',\n",
       " 'Chapter 11',\n",
       " 'Daniel Beckstein',\n",
       " 'Chapter 12',\n",
       " 'George Dahl',\n",
       " 'Vladimir Nekrasov',\n",
       " 'Ribana Roscher',\n",
       " 'Chapter 13',\n",
       " 'Jayanth Koushik']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tiny = [i.strip() for i in re.sub('\"|}|{||\\[|\\]', \"\", answer).split(\",\")]\n",
    "res_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "81fc7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些基于N-gram的探索，会输出命名实体在文章中出现的次数，没啥用\n",
    "# temp = []\n",
    "# for i in res_tiny:\n",
    "#     ng = len(i.split(' '))\n",
    "#     if ng == 1:\n",
    "#         temp.append((i, ng1[i]))\n",
    "#     elif ng == 2:\n",
    "#         temp.append((i, ng2[tuple(i.split(' '))]))\n",
    "#     elif ng == 3:\n",
    "#         temp.append((i, ng3[tuple(i.split(' '))]))\n",
    "#     elif ng == 4:\n",
    "#         temp.append((i, ng4[tuple(i.split(' '))]))\n",
    "#     else:\n",
    "#         temp.append((i, 0))\n",
    "# entity_frq_dic = dict(temp)\n",
    "# entity_frq = sort_feq(entity_frq_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c698e14c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 尝试批量抽取，一次抽取1000个词，失败，请求数过多\n",
    "# i = 0\n",
    "# span = 1000\n",
    "# res = []\n",
    "# while i * span < len(all_text):\n",
    "#     if (i + 1) * span > len(all_text):\n",
    "#         prompt = all_text[i * span:]\n",
    "#     else:\n",
    "#         prompt = all_text[i * span : (i + 1) * span]\n",
    "#     conversation_list = [\n",
    "#         {'role': 'system', 'content':'请只提取文本中的命名实体，格式为[{entity_A}, {entity_B}, ...], 不要返回任何其他内容'},\n",
    "#         {\"role\": \"user\", \"content\": ' '.join(prompt)}]\n",
    "#     response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=conversation_list)\n",
    "#     tmp = response.choices[0].message['content']\n",
    "#     res += [i.strip() for i in re.sub('\\\"|}|{||\\[|\\]', '', tmp).split(',')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
