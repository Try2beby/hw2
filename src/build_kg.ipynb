{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import pdfplumber\n",
    "import os\n",
    "import json\n",
    "\n",
    "from classBook import Book\n",
    "\n",
    "\n",
    "dataDir = \"../data/\"\n",
    "dataName = \"Deep Learning.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "\n",
    "dataDir = \"../data/\"\n",
    "dataName = \"Deep Learning.pdf\"\n",
    "\n",
    "\n",
    "class Book:\n",
    "    num_pages = -1\n",
    "    book_end_page = \"735\"\n",
    "    page_offset = 15\n",
    "\n",
    "    def __init__(self, name=dataName, dataDir=dataDir):\n",
    "        self.name = name\n",
    "        self.dataDir = dataDir\n",
    "        self.pdf = self.loader()\n",
    "\n",
    "    def loader(self):\n",
    "        print(\"Reading book: \", self.name, \"from directory: \", self.dataDir)\n",
    "        try:\n",
    "            pdf = pdfplumber.open(os.path.join(self.dataDir, self.name))\n",
    "        except:\n",
    "            print(\"Error: File not found\")\n",
    "            return None\n",
    "        self.num_pages = len(pdf.pages)\n",
    "        print(\"Book loaded successfully\")\n",
    "        print(\"Number of pages: \", self.num_pages)\n",
    "        return pdf\n",
    "\n",
    "    def close(self):\n",
    "        self.pdf.close()\n",
    "\n",
    "    def readPage(self, page=-1):\n",
    "        if page == -1:\n",
    "            return self.pdf.pages\n",
    "        else:\n",
    "            return self.pdf.pages[page - 1]\n",
    "\n",
    "    def readPageInInterval(self, start_page, end_page, offset=page_offset):\n",
    "        return self.pdf.pages[start_page - 1 + offset : end_page - 1 + offset]\n",
    "\n",
    "    def searchStrInPage(self, page, str):\n",
    "        page_text = self.readPage(page)\n",
    "        return page_text.extract_text().lower().find(str.lower())\n",
    "\n",
    "    def getToc(self):\n",
    "        pages = []\n",
    "        for i in range(8):\n",
    "            if self.searchStrInPage(i, \"Contents\") != -1:\n",
    "                pages.append(i)\n",
    "        # reg expression to match '6 Deep Feedforward Networks 168'\n",
    "        pattern_chapter = re.compile(r\"(\\d+)\\s+(.*)\\s+(\\d+)\")\n",
    "        # match '6.1 Example: Learning XOR . . . . . . . . . . . . . . . . . . . . . . . 171',\n",
    "        pattern_section = re.compile(\n",
    "            r\"(\\d+)\\.(\\d+)\\s+([\\?\\,\\'\\â€™\\(\\)a-zA-Z\\:\\s\\-]+)\\s+.*\\s+(\\d+)\"\n",
    "        )\n",
    "\n",
    "        # save to dict\n",
    "        toc = {}\n",
    "        for page in pages:\n",
    "            page_text = self.readPage(page)\n",
    "            text = page_text.extract_text()\n",
    "            lines = text.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                match_chapter = pattern_chapter.match(line)\n",
    "                match_section = pattern_section.match(line)\n",
    "                if match_chapter:\n",
    "                    chapter = {\n",
    "                        \"chapter\": match_chapter.group(1),\n",
    "                        \"title\": match_chapter.group(2),\n",
    "                        \"page\": match_chapter.group(3),\n",
    "                    }\n",
    "                elif match_section:\n",
    "                    section = {\n",
    "                        \"chapter\": match_section.group(1),\n",
    "                        \"section\": match_section.group(2),\n",
    "                        \"title\": match_section.group(3),\n",
    "                        \"page\": match_section.group(4),\n",
    "                    }\n",
    "                    if chapter[\"chapter\"] not in toc:\n",
    "                        toc[chapter[\"chapter\"]] = {\n",
    "                            \"title\": chapter[\"title\"],\n",
    "                            \"page\": chapter[\"page\"],\n",
    "                            \"sections\": [],\n",
    "                        }\n",
    "                    toc[chapter[\"chapter\"]][\"sections\"].append(section)\n",
    "\n",
    "        # add end page\n",
    "        for chapter in toc:\n",
    "            try:\n",
    "                toc[chapter][\"end_page\"] = toc[str(int(chapter) + 1)][\"page\"]\n",
    "            except:\n",
    "                toc[chapter][\"end_page\"] = self.book_end_page\n",
    "            for section in toc[chapter][\"sections\"]:\n",
    "                try:\n",
    "                    section[\"end_page\"] = toc[chapter][\"sections\"][\n",
    "                        int(section[\"section\"])\n",
    "                    ][\"page\"]\n",
    "                except:\n",
    "                    section[\"end_page\"] = toc[chapter][\"end_page\"]\n",
    "        # write to json\n",
    "        with open(os.path.join(self.dataDir, \"toc.json\"), \"w\") as f:\n",
    "            json.dump(toc, f, indent=4)\n",
    "        return len(toc)\n",
    "\n",
    "    def loadToc(self):\n",
    "        with open(os.path.join(self.dataDir, \"toc.json\"), \"r\") as f:\n",
    "            toc = json.load(f)\n",
    "        return toc\n",
    "\n",
    "    def getChapter(self, chapter):\n",
    "        toc = self.loadToc()\n",
    "        page = toc[chapter][\"page\"]\n",
    "        end_page = toc[chapter][\"end_page\"]\n",
    "        return self.readPageInInterval(int(page), int(end_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading book:  Deep Learning.pdf from directory:  ../data/\n",
      "Book loaded successfully\n",
      "Number of pages:  800\n"
     ]
    }
   ],
   "source": [
    "book = Book(dataName)\n",
    "# book.getToc()\n",
    "# toc = book.loadToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = book.getChapter(\"1\")[0].extract_text().replace(\"\\n\", \"\\n\")\n",
    "# save to txt\n",
    "with open(os.path.join(dataDir, \"test.txt\"), \"w\") as f:\n",
    "    f.write(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter NOUN nmod\n",
      "1 NUM nummod\n",
      "Introduction PROPN compound\n",
      "Inventors PROPN nsubj\n",
      "have AUX aux\n",
      "long ADV advmod\n",
      "dreamed VERB ROOT\n",
      "of ADP prep\n",
      "creating VERB pcomp\n",
      "machines NOUN dobj\n",
      "that PRON nsubj\n",
      "think VERB relcl\n",
      ". PUNCT punct\n",
      "This DET det\n",
      "desire NOUN nsubj\n",
      "dates VERB ROOT\n",
      "back ADV advmod\n",
      "to ADP prep\n",
      "at ADP advmod\n",
      "least ADJ advmod\n",
      "the DET det\n",
      "time NOUN pobj\n",
      "of ADP prep\n",
      "ancient ADJ amod\n",
      "Greece PROPN pobj\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "mythical ADJ amod\n",
      "figures NOUN nsubjpass\n",
      "Pygmalion PROPN nsubjpass\n",
      ", PUNCT punct\n",
      "Daedalus PROPN appos\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "Hephaestus PROPN conj\n",
      "may AUX aux\n",
      "all ADV advmod\n",
      "be AUX auxpass\n",
      "interpreted VERB ROOT\n",
      "as ADP prep\n",
      "legendary ADJ amod\n",
      "inventors NOUN pobj\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "Galatea PROPN nsubjpass\n",
      ", PUNCT punct\n",
      "Talos PROPN conj\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "Pandora PROPN conj\n",
      "may AUX aux\n",
      "all ADV advmod\n",
      "be AUX auxpass\n",
      "regarded VERB conj\n",
      "as ADP prep\n",
      "artificial ADJ amod\n",
      "life NOUN pobj\n",
      "( PUNCT punct\n",
      "Ovid PROPN appos\n",
      "and CCONJ cc\n",
      "Martin PROPN conj\n",
      ", PUNCT punct\n",
      "2004 NUM appos\n",
      "; PUNCT punct\n",
      "Sparkes NOUN appos\n",
      ", PUNCT punct\n",
      "1996 NUM appos\n",
      "; PUNCT punct\n",
      "Tandy PROPN conj\n",
      ", PUNCT punct\n",
      "1997 NUM appos\n",
      ") PUNCT punct\n",
      ". PUNCT punct\n",
      "When SCONJ advmod\n",
      "programmable ADJ amod\n",
      "computers NOUN nsubjpass\n",
      "were AUX auxpass\n",
      "first ADV advmod\n",
      "conceived VERB advcl\n",
      ", PUNCT punct\n",
      "people NOUN nsubj\n",
      "wondered VERB ROOT\n",
      "whether SCONJ mark\n",
      "such ADJ amod\n",
      "machines NOUN nsubj\n",
      "might AUX aux\n",
      "become VERB ccomp\n",
      "intelligent ADJ acomp\n",
      ", PUNCT punct\n",
      "over ADP quantmod\n",
      "a DET quantmod\n",
      "hundred NUM nummod\n",
      "years NOUN npadvmod\n",
      "before SCONJ mark\n",
      "one NUM nsubjpass\n",
      "was AUX auxpass\n",
      "built VERB advcl\n",
      "( PUNCT punct\n",
      "Lovelace PROPN oprd\n",
      ", PUNCT punct\n",
      "1842 NUM npadvmod\n",
      ") PUNCT punct\n",
      ". PUNCT punct\n",
      "Today NOUN npadvmod\n",
      ", PUNCT punct\n",
      "artificial ADJ amod\n",
      "intelligence NOUN nsubj\n",
      "( PUNCT punct\n",
      "AI PROPN appos\n",
      ") PUNCT punct\n",
      "is AUX ROOT\n",
      "a DET det\n",
      "thriving ADJ amod\n",
      "field NOUN attr\n",
      "with ADP prep\n",
      "many ADJ amod\n",
      "practical ADJ amod\n",
      "applications NOUN pobj\n",
      "and CCONJ cc\n",
      "active ADJ amod\n",
      "research NOUN compound\n",
      "topics NOUN conj\n",
      ". PUNCT punct\n",
      "We PRON nsubj\n",
      "look VERB ROOT\n",
      "to ADP prep\n",
      "intelligent ADJ amod\n",
      "software NOUN pobj\n",
      "to PART aux\n",
      "automate VERB advcl\n",
      "routine ADJ amod\n",
      "labor NOUN dobj\n",
      ", PUNCT punct\n",
      "understand VERB conj\n",
      "speech NOUN dobj\n",
      "or CCONJ cc\n",
      "images NOUN conj\n",
      ", PUNCT punct\n",
      "make VERB conj\n",
      "diagnoses NOUN dobj\n",
      "in ADP prep\n",
      "medicine NOUN pobj\n",
      "and CCONJ cc\n",
      "support VERB conj\n",
      "basic ADJ amod\n",
      "scientific ADJ amod\n",
      "research NOUN dobj\n",
      ". PUNCT punct\n",
      "In ADP prep\n",
      "the DET det\n",
      "early ADJ amod\n",
      "days NOUN pobj\n",
      "of ADP prep\n",
      "artificial ADJ amod\n",
      "intelligence NOUN pobj\n",
      ", PUNCT punct\n",
      "the DET det\n",
      "field NOUN nsubj\n",
      "rapidly ADV advmod\n",
      "tackled VERB ROOT\n",
      "and CCONJ cc\n",
      "solved VERB conj\n",
      "problems NOUN dobj\n",
      "that PRON nsubj\n",
      "are AUX relcl\n",
      "intellectually ADV advmod\n",
      "difficult ADJ acomp\n",
      "for ADP prep\n",
      "human ADJ amod\n",
      "beings NOUN pobj\n",
      "but CCONJ cc\n",
      "relatively ADV advmod\n",
      "straight- ADJ conj\n",
      "forward ADV advmod\n",
      "for ADP prep\n",
      "computers NOUN pobj\n",
      "â€” PUNCT punct\n",
      "problems NOUN dobj\n",
      "that PRON nsubjpass\n",
      "can AUX aux\n",
      "be AUX auxpass\n",
      "described VERB relcl\n",
      "by ADP agent\n",
      "a DET det\n",
      "list NOUN pobj\n",
      "of ADP prep\n",
      "formal ADJ amod\n",
      ", PUNCT punct\n",
      "math- NOUN dep\n",
      "ematical ADJ amod\n",
      "rules NOUN pobj\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "true ADJ amod\n",
      "challenge NOUN nsubj\n",
      "to ADP prep\n",
      "artificial ADJ amod\n",
      "intelligence NOUN pobj\n",
      "proved VERB ROOT\n",
      "to PART aux\n",
      "be AUX aux\n",
      "solving VERB xcomp\n",
      "the DET det\n",
      "tasks NOUN dobj\n",
      "that PRON nsubj\n",
      "are AUX relcl\n",
      "easy ADJ acomp\n",
      "for SCONJ mark\n",
      "people NOUN nsubj\n",
      "to PART aux\n",
      "perform VERB advcl\n",
      "but CCONJ cc\n",
      "hard ADJ conj\n",
      "for SCONJ mark\n",
      "people NOUN nsubj\n",
      "to PART aux\n",
      "describe VERB advcl\n",
      "formally ADV advmod\n",
      "â€” PUNCT punct\n",
      "problems NOUN appos\n",
      "that PRON dobj\n",
      "we PRON nsubj\n",
      "solve VERB relcl\n",
      "intuitively ADV advmod\n",
      ", PUNCT punct\n",
      "that PRON nsubj\n",
      "feel VERB advcl\n",
      "automatic ADJ acomp\n",
      ", PUNCT punct\n",
      "like ADP prep\n",
      "recognizing VERB pcomp\n",
      "spoken ADJ amod\n",
      "words NOUN dobj\n",
      "or CCONJ cc\n",
      "faces NOUN conj\n",
      "in ADP prep\n",
      "images NOUN pobj\n",
      ". PUNCT punct\n",
      "This DET det\n",
      "book NOUN nsubj\n",
      "is AUX ROOT\n",
      "about ADP prep\n",
      "a DET det\n",
      "solution NOUN pobj\n",
      "to ADP prep\n",
      "these DET det\n",
      "more ADJ advmod\n",
      "intuitive ADJ amod\n",
      "problems NOUN pobj\n",
      ". PUNCT punct\n",
      "This DET det\n",
      "solution NOUN nsubj\n",
      "is AUX ROOT\n",
      "to PART aux\n",
      "allow VERB xcomp\n",
      "computers NOUN nsubj\n",
      "to PART aux\n",
      "learn VERB ccomp\n",
      "from ADP prep\n",
      "experience NOUN pobj\n",
      "and CCONJ cc\n",
      "understand VERB conj\n",
      "the DET det\n",
      "world NOUN dobj\n",
      "in ADP prep\n",
      "terms NOUN pobj\n",
      "of ADP prep\n",
      "a DET det\n",
      "hierarchy NOUN pobj\n",
      "of ADP prep\n",
      "concepts NOUN pobj\n",
      ", PUNCT punct\n",
      "with ADP prep\n",
      "each DET det\n",
      "concept NOUN pobj\n",
      "defined VERB acl\n",
      "in ADP prep\n",
      "terms NOUN pobj\n",
      "of ADP prep\n",
      "its PRON poss\n",
      "relation NOUN pobj\n",
      "to ADP prep\n",
      "simpler ADJ amod\n",
      "concepts NOUN pobj\n",
      ". PUNCT punct\n",
      "By ADP prep\n",
      "gathering VERB pcomp\n",
      "knowledge NOUN dobj\n",
      "from ADP prep\n",
      "experience NOUN pobj\n",
      ", PUNCT punct\n",
      "this DET det\n",
      "approach NOUN nsubj\n",
      "avoids VERB ROOT\n",
      "the DET det\n",
      "need NOUN dobj\n",
      "for SCONJ mark\n",
      "human ADJ amod\n",
      "operators NOUN nsubj\n",
      "to PART aux\n",
      "formally ADV advmod\n",
      "specify VERB advcl\n",
      "all PRON dobj\n",
      "of ADP prep\n",
      "the DET det\n",
      "knowledge NOUN pobj\n",
      "that SCONJ dobj\n",
      "the DET det\n",
      "computer NOUN nsubj\n",
      "needs VERB relcl\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "hierarchy NOUN nsubj\n",
      "of ADP prep\n",
      "concepts NOUN pobj\n",
      "allows VERB ROOT\n",
      "the DET det\n",
      "computer NOUN nsubj\n",
      "to PART aux\n",
      "learn VERB ccomp\n",
      "complicated ADJ amod\n",
      "concepts NOUN dobj\n",
      "by ADP prep\n",
      "building VERB pcomp\n",
      "them PRON dobj\n",
      "out ADP prep\n",
      "of ADP prep\n",
      "simpler ADJ amod\n",
      "ones NOUN pobj\n",
      ". PUNCT punct\n",
      "If SCONJ mark\n",
      "we PRON nsubj\n",
      "draw VERB ROOT\n",
      "a DET det\n",
      "graph NOUN dobj\n",
      "showing VERB acl\n",
      "how SCONJ advmod\n",
      "these DET det\n",
      "1 NUM npadvmod\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(test)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
