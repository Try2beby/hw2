{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c427152e-fb64-4fd2-a1d5-e14f848019aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T07:57:48.815737Z",
     "iopub.status.busy": "2024-02-21T07:57:48.815737Z",
     "iopub.status.idle": "2024-02-21T07:57:48.819684Z",
     "shell.execute_reply": "2024-02-21T07:57:48.819684Z",
     "shell.execute_reply.started": "2024-02-21T07:57:48.815737Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GitHub\\kg\\.conda\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import torch\n",
    "from fuzzywuzzy import fuzz\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "dataDir = \"../data/\"\n",
    "dataName = \"Deep Learning.pdf\"\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# openai.api_base = \"https://api.chatanywhere.com.cn/\"\n",
    "openai.api_base = \"https://api.chatanywhere.tech\"\n",
    "openai.api_key = \"sk-LzwgVgu5xvNPpwoqCdeeVcAt7Tu7ZoZICXzzkheldIbXA60h\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f4fef-8b2d-41ae-8af6-552e79070234",
   "metadata": {},
   "source": [
    "# 1. 获取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9e3a41-3514-4a05-ba63-0459ef06b1d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T07:33:37.177648Z",
     "iopub.status.busy": "2024-02-21T07:33:37.176648Z",
     "iopub.status.idle": "2024-02-21T07:35:17.816953Z",
     "shell.execute_reply": "2024-02-21T07:35:17.816953Z",
     "shell.execute_reply.started": "2024-02-21T07:33:37.176648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"bert-large-cased\", cache_dir=\"../../../BERT/large\"\n",
    ")\n",
    "model = BertModel.from_pretrained(\"bert-large-cased\", cache_dir=\"../../../BERT/large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364fd41-4285-4f7d-bdee-b743a822c9de",
   "metadata": {},
   "source": [
    "# 2. 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6304d6-f72e-4c38-b3a2-5548ca3a6459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T07:06:59.601657Z",
     "iopub.status.busy": "2024-02-21T07:06:59.601657Z",
     "iopub.status.idle": "2024-02-21T07:08:29.596720Z",
     "shell.execute_reply": "2024-02-21T07:08:29.596720Z",
     "shell.execute_reply.started": "2024-02-21T07:06:59.601657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd87f3b636841eb8053dc15866b8a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pdfplumber.open(dataDir + dataName) as f:\n",
    "    # 目录架构生成\n",
    "    c, p, n = [], [], []\n",
    "    for i in range(7):\n",
    "        page = f.pages[i]\n",
    "        text = page.extract_text()\n",
    "        text_split = text.split(\"\\n\")\n",
    "        for i in text_split:\n",
    "            if bool(re.match(\"[0-9]+\\.[0-9]+\", i.split(\" \")[0])):\n",
    "                c.append(i.split(\" \")[0])\n",
    "                p.append(int(i.split(\" \")[-1]) + 15)\n",
    "            if bool(re.match(\"[0-9]+\", i.split(\" \")[0])):\n",
    "                for j in i.split(\" \"):\n",
    "                    if bool(re.match(\"[A-Za-z]+\", j)):\n",
    "                        n.append((i.split(\" \")[0], j))\n",
    "\n",
    "p_range = list(zip(p, p[1:]))\n",
    "p_range.append((735, 800))\n",
    "c_p_range = list(zip(c, p_range))\n",
    "index_dict = collections.defaultdict(list)\n",
    "for k, v in c_p_range:\n",
    "    index_dict[k.split(\".\")[0]].append((k, v))\n",
    "\n",
    "with pdfplumber.open(dataDir + dataName) as f:\n",
    "    content_dict = collections.defaultdict(list)\n",
    "\n",
    "    for k, v in tqdm(index_dict.items(), total=len(index_dict)):\n",
    "        for i in v:\n",
    "            page_range = i[-1]\n",
    "            if page_range[0] == page_range[1]:\n",
    "                page_range = (page_range[0], page_range[1] + 1)\n",
    "            for j in range(int(page_range[0]) - 1, int(page_range[1]) - 1):\n",
    "                page = f.pages[j]\n",
    "\n",
    "                text = page.extract_text().replace(\"\\n\", \" \")\n",
    "\n",
    "                content_dict[i[0]].append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb403b",
   "metadata": {},
   "source": [
    "# 3. 定义ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f8717b-9aa9-42ad-9c14-290092ff25b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T09:33:34.102084Z",
     "iopub.status.busy": "2024-02-21T09:33:34.102084Z",
     "iopub.status.idle": "2024-02-21T09:33:34.105930Z",
     "shell.execute_reply": "2024-02-21T09:33:34.105930Z",
     "shell.execute_reply.started": "2024-02-21T09:33:34.102084Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, conversation_list=[]):\n",
    "        self.conversation_list = conversation_list\n",
    "        self.costs_list = []\n",
    "\n",
    "    def show_conversation(self, msg_list):\n",
    "        for msg in msg_list[-2:]:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                pass\n",
    "            else:\n",
    "                message = msg[\"content\"]\n",
    "                pass\n",
    "                # print(f\"\\U0001f47D: {message}\\n\")\n",
    "\n",
    "    def ask(self, prompt):\n",
    "        self.conversation_list.append({\"role\": \"user\", \"content\": prompt})\n",
    "        openai.api_key = \"sk-LzwgVgu5xvNPpwoqCdeeVcAt7Tu7ZoZICXzzkheldIbXA60h\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\", messages=self.conversation_list\n",
    "        )\n",
    "        answer = response.choices[0].message[\"content\"]\n",
    "\n",
    "        self.conversation_list.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.show_conversation(self.conversation_list)\n",
    "\n",
    "        # cost = total_counts(response)\n",
    "        # self.costs_list.append(cost)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d68d24",
   "metadata": {},
   "source": [
    "# 4. 设计Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3640d992-d4e0-4de4-8209-7ecabd55e5da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T09:36:08.229147Z",
     "iopub.status.busy": "2024-02-21T09:36:08.228147Z",
     "iopub.status.idle": "2024-02-21T09:36:08.231752Z",
     "shell.execute_reply": "2024-02-21T09:36:08.231752Z",
     "shell.execute_reply.started": "2024-02-21T09:36:08.229147Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NER_prompt = f\"\"\"\n",
    "角色：\n",
    "你是一个深度学习领域的实体标注专员\n",
    "\n",
    "任务：\n",
    "给定字符串，请找出全部深度学习领域的实体\n",
    "\n",
    "步骤：\n",
    "请以以下步骤执行：\n",
    "1. 找出句子中的所有深度学习领域的实体\n",
    "2. 依次检查实体是否属于深度学习领域\n",
    "3. 将属于深度学习领域的实体返回\n",
    "4. 若没有深度学习领域的实体，则返回()\n",
    "\n",
    "格式：\n",
    "请以以下格式返回：\n",
    "(entity1, entity2, ...)\n",
    "\n",
    "举例如下：\n",
    "An illustration of how the gradient descent algorithm uses the derivatives of a function can be used to follow the function downhill to a minimum.\n",
    "(gradient descent algorithm)\n",
    "\n",
    "an encoder or reader or input RNN processes the input sequence. The encoder emits the context C, usually as a simple function of its final hidden state.\n",
    "(encoder, RNN, hidden state)\n",
    "\n",
    "There is no constraint that the encoder must have the same size of hidden layer as the decoder\n",
    "(hidden layer, decoder)\n",
    "\n",
    "Computer vision has traditionally been one of the most active research areas for deep learning applications, because vision is a task that is effortless for humans and many animals but challenging for computers (Ballard et al., 1983)\n",
    "(Computer vision, deep learning)\n",
    "\n",
    "Dataset augmentation may be seen as a way of preprocessing the training set only.\n",
    "(Dataset augmentation)\n",
    "\n",
    "CHAPTER 1. INTRODUCTION of the flowchart of the computations needed to compute the representation of each concept may be much deeper than the graph of the concepts themselves.\n",
    "()\n",
    "\n",
    "注意事项：\n",
    "1. 请严格遵循字符串中的原本表述\n",
    "2. 除返回结果外，不要返回任何其他内容\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6277d2bc-5c2b-4aa1-a604-fb4b825ae6f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T09:48:04.087938Z",
     "iopub.status.busy": "2024-02-21T09:48:04.087938Z",
     "iopub.status.idle": "2024-02-21T09:48:04.090724Z",
     "shell.execute_reply": "2024-02-21T09:48:04.090724Z",
     "shell.execute_reply.started": "2024-02-21T09:48:04.087938Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_prompt = f\"\"\"\n",
    "任务：\n",
    "请检查所给实体是否属于深度学习领域\n",
    "\n",
    "格式：\n",
    "请以以下格式返回：\n",
    "如果该实体是深度学习领域的实体，返回True，否则返回False\n",
    "\n",
    "举例如下：\n",
    "input: deep learning\n",
    "output: True\n",
    "\n",
    "input: AI system\n",
    "output: True\n",
    "\n",
    "input: image\n",
    "output: False\n",
    "\n",
    "input: Image Net\n",
    "output: True\n",
    "\n",
    "input: face\n",
    "output: False\n",
    "\n",
    "注意事项：\n",
    "1. 请仅返回True或者False，不要返回任何其他内容\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ab818",
   "metadata": {},
   "source": [
    "# 5. 处理数据，获取sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99d20474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_position(content_token, entity_token):\n",
    "    \"\"\"\n",
    "    Finds the position of an entity token within a content token.\n",
    "\n",
    "    Args:\n",
    "        content_token (torch.Tensor): A tensor representing the content token.\n",
    "        entity_token (torch.Tensor): A tensor representing the entity token.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor representing the position of the entity token within the content token.\n",
    "                      Each element in the tensor represents the position of a token in the content token:\n",
    "                      - 0: Token does not match the entity token.\n",
    "                      - 1: Token matches the entity token, but is not the first token.\n",
    "                      - 2: Token matches the entity token and is the first token.\n",
    "    \"\"\"\n",
    "    position = torch.zeros_like(content_token)\n",
    "    for entity in entity_token:\n",
    "        for i in range(len(content_token) - len(entity) + 1):\n",
    "            if torch.all(content_token[i : i + len(entity)] == entity):\n",
    "                position[i] = 2\n",
    "                position[i + 1 : i + len(entity)] = 1\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caabba2f-9476-43b1-8e7f-61c96d38080d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T10:45:57.615752Z",
     "iopub.status.busy": "2024-02-21T10:45:57.615752Z",
     "iopub.status.idle": "2024-02-21T10:49:32.176168Z",
     "shell.execute_reply": "2024-02-21T10:49:32.176168Z",
     "shell.execute_reply.started": "2024-02-21T10:45:57.615752Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_content(content_dict, content_list):\n",
    "    \"\"\"\n",
    "    Process the content dictionary to extract named entities and save them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        content_dict (dict): A dictionary containing the content to process.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for k, v in content_dict.items():\n",
    "        if k in content_list:\n",
    "            print(k+':', end='\\n')\n",
    "            if total >= 1500:\n",
    "                break\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=100, chunk_overlap=20\n",
    "            )\n",
    "            docs = text_splitter.split_text(\" \".join(i for i in v))\n",
    "\n",
    "            # Process each document\n",
    "            for index, content in enumerate(docs):\n",
    "                total += 1\n",
    "                if total == 1500:\n",
    "                    break\n",
    "\n",
    "                # Initialize NER chatbot\n",
    "                if index % 5 == 0:\n",
    "                    conversation_list = [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": NER_prompt,\n",
    "                        }\n",
    "                    ]\n",
    "                    bot_ner = Chat(conversation_list)\n",
    "\n",
    "                # Extract named entities using NER chatbot\n",
    "                answer_ner = bot_ner.ask(\"input: \" + content)\n",
    "                entity_list_temp = re.sub(\"\\(|\\)|\", \"\", answer_ner).split(\", \")\n",
    "                # Initialize check chatbot\n",
    "                conversation_list = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": check_prompt,\n",
    "                    }\n",
    "                ]\n",
    "                bot_check = Chat(conversation_list)\n",
    "\n",
    "                entity_list = []\n",
    "                # Check if each entity is valid using check chatbot\n",
    "                for e in entity_list_temp:\n",
    "                    answer_check = bot_check.ask(\"input: \" + e)\n",
    "                    if answer_check == \"True\":\n",
    "                        entity_list.append(e)\n",
    "                        \n",
    "                if entity_list:\n",
    "                    # Tokenize content and entities\n",
    "                    content_token = tokenizer(content, return_tensors=\"pt\")[\n",
    "                        \"input_ids\"\n",
    "                    ].squeeze(0)\n",
    "                    entity_token = []\n",
    "                    for e in entity_list:\n",
    "                        entity_token.append(\n",
    "                            tokenizer(e, return_tensors=\"pt\")[\"input_ids\"].squeeze(0)[1:-1]\n",
    "                        )\n",
    "\n",
    "                    # Find position of entities in content\n",
    "                    label = find_position(content_token, entity_token)\n",
    "\n",
    "                    # Save the results to a CSV file\n",
    "                    df = pd.DataFrame(\n",
    "                        [\n",
    "                            [\n",
    "                                tokenizer.batch_decode(content_token),\n",
    "                                tokenizer.batch_decode(entity_token),\n",
    "                                label,\n",
    "                            ]\n",
    "                        ],\n",
    "                        columns=[\"text\", \"entity\", \"label\"],\n",
    "                    )\n",
    "                    df.to_csv(\n",
    "                        os.path.join(dataDir + \"/relations\", f\"sample.csv\"),\n",
    "                        mode=\"a\",\n",
    "                        header=not os.path.exists(\n",
    "                            os.path.join(dataDir + \"/relations\", f\"sample.csv\")\n",
    "                        ),\n",
    "                        index=False,\n",
    "                    )\n",
    "                    # Print the content, tokens, entity list, and label\n",
    "                    print(\n",
    "                        \"content: \" + str(content),\n",
    "                        \"content_token: \" + str(content_token),\n",
    "                        \"entity_list: \" + str(entity_list),\n",
    "                        \"entity_token: \" + str(entity_token),\n",
    "                        sep=\"\\n\",\n",
    "                    )\n",
    "                    print(\"label: \" + str(label))\n",
    "                    print(\n",
    "                        \"----------------------------------------------------------------------------------------------------------\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87cb9aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1:\n",
      "content: CHAPTER 6. DEEP FEEDFORWARD NETWORKS mappings from x to y that lack feedback connections. Other\n",
      "content_token: tensor([  101,  8203,   127,   119, 18581, 16668,   143, 27073, 16395,  9565,\n",
      "        11840, 23354, 26546,  1942,  2924,  9565, 25370, 13970,  1116,  1121,\n",
      "          193,  1106,   194,  1115,  2960, 13032,  6984,   119,  2189,   102])\n",
      "entity_list: ['deep feedforward networks']\n",
      "entity_token: [tensor([ 1996,  4877, 14467,  1197,  5984,  6379])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: simple example of a feedforward network. Next, we address each of the design decisions needed to\n",
      "content_token: tensor([  101,  3014,  1859,  1104,   170,  4877, 14467,  1197,  5984,  2443,\n",
      "          119,  5893,   117,  1195,  4134,  1296,  1104,  1103,  1902,  6134,\n",
      "         1834,  1106,   102])\n",
      "entity_list: ['feedforward network']\n",
      "entity_token: [tensor([ 4877, 14467,  1197,  5984,  2443])]\n",
      "label: tensor([0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: decisions needed to deploy a feedforward network. First, training a feedforward network requires\n",
      "content_token: tensor([  101,  6134,  1834,  1106, 23660,   170,  4877, 14467,  1197,  5984,\n",
      "         2443,   119,  1752,   117,  2013,   170,  4877, 14467,  1197,  5984,\n",
      "         2443,  5315,   102])\n",
      "entity_list: ['feedforward network', 'training']\n",
      "entity_token: [tensor([ 4877, 14467,  1197,  5984,  2443]), tensor([2013])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 1, 1, 1, 1, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: for a linear model: choosing the optimizer, the cost function, and the form of the output units. We\n",
      "content_token: tensor([  101,  1111,   170,  7378,  2235,   131, 11027,  1103, 11769,  3121,\n",
      "        19092,  1197,   117,  1103,  2616,  3053,   117,  1105,  1103,  1532,\n",
      "         1104,  1103,  5964,  2338,   119,  1284,   102])\n",
      "entity_list: ['optimizer', 'cost function', 'output units']\n",
      "entity_token: [tensor([11769,  3121, 19092,  1197]), tensor([2616, 3053]), tensor([5964, 2338])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1,\n",
      "        0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: output units. We review these basics of gradient-based learning, then proceed to confront some of\n",
      "content_token: tensor([  101,  5964,  2338,   119,  1284,  3189,  1292,  3501,  1116,  1104,\n",
      "        19848,   118,  1359,  3776,   117,  1173, 10980,  1106, 15034,  1199,\n",
      "         1104,   102])\n",
      "entity_list: ['output units', 'gradient-based learning']\n",
      "entity_token: [tensor([5964, 2338]), tensor([19848,   118,  1359,  3776])]\n",
      "label: tensor([0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: to confront some of the design decisions that are unique to feedforward networks. Feedforward\n",
      "content_token: tensor([  101,  1106, 15034,  1199,  1104,  1103,  1902,  6134,  1115,  1132,\n",
      "         3527,  1106,  4877, 14467,  1197,  5984,  6379,   119, 11907,  1174,\n",
      "        14467,  1197,  5984,   102])\n",
      "entity_list: ['feedforward networks']\n",
      "entity_token: [tensor([ 4877, 14467,  1197,  5984,  6379])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: Feedforward networks have introduced the concept of a hidden layer, and this requires us to choose\n",
      "content_token: tensor([  101, 11907,  1174, 14467,  1197,  5984,  6379,  1138,  2234,  1103,\n",
      "         3400,  1104,   170,  4610,  6440,   117,  1105,  1142,  5315,  1366,\n",
      "         1106,  4835,   102])\n",
      "entity_list: ['hidden layer']\n",
      "entity_token: [tensor([4610, 6440])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: us to choose the activation functions that will be used to compute the hidden layer values. We must\n",
      "content_token: tensor([  101,  1366,  1106,  4835,  1103, 14915,  4226,  1115,  1209,  1129,\n",
      "         1215,  1106,  3254, 22662,  1103,  4610,  6440,  4718,   119,  1284,\n",
      "         1538,   102])\n",
      "entity_list: ['activation functions']\n",
      "entity_token: [tensor([14915,  4226])]\n",
      "label: tensor([0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: values. We must also design the architecture of the network, including how many layers the network\n",
      "content_token: tensor([ 101, 4718,  119, 1284, 1538, 1145, 1902, 1103, 4220, 1104, 1103, 2443,\n",
      "         117, 1259, 1293, 1242, 8798, 1103, 2443,  102])\n",
      "entity_list: ['layers']\n",
      "entity_token: [tensor([8798])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: layers the network should contain, how these layers should be connected to each other, and how many\n",
      "content_token: tensor([ 101, 8798, 1103, 2443, 1431, 4651,  117, 1293, 1292, 8798, 1431, 1129,\n",
      "        3387, 1106, 1296, 1168,  117, 1105, 1293, 1242,  102])\n",
      "entity_list: ['network', 'layers']\n",
      "entity_token: [tensor([2443]), tensor([8798])]\n",
      "label: tensor([0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: other, and how many units should be in each layer. Learning in deep neural networks requires\n",
      "content_token: tensor([  101,  1168,   117,  1105,  1293,  1242,  2338,  1431,  1129,  1107,\n",
      "         1296,  6440,   119,  9681,  1107,  1996, 18250,  6379,  5315,   102])\n",
      "entity_list: ['deep neural networks']\n",
      "entity_token: [tensor([ 1996, 18250,  6379])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: networks requires computing the gradients of complicated functions. We present the back-propagation\n",
      "content_token: tensor([  101,  6379,  5315, 12783,  1103, 19848,  1116,  1104,  8277,  4226,\n",
      "          119,  1284,  1675,  1103,  1171,   118, 25934,   102])\n",
      "entity_list: ['back-propagation']\n",
      "entity_token: [tensor([ 1171,   118, 25934])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: back-propagation algorithm and its modern generalizations, which can be used to efficiently compute\n",
      "content_token: tensor([  101,  1171,   118, 25934,  9932,  1105,  1157,  2030,  1704, 20412,\n",
      "          117,  1134,  1169,  1129,  1215,  1106, 19723,  3254, 22662,   102])\n",
      "entity_list: ['back-propagation algorithm']\n",
      "entity_token: [tensor([ 1171,   118, 25934,  9932])]\n",
      "label: tensor([0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: more concrete, we begin with an example of a fully functioning feedforward network on a very simple\n",
      "content_token: tensor([  101,  1167,  5019,   117,  1195,  3295,  1114,  1126,  1859,  1104,\n",
      "          170,  3106, 12641,  4877, 14467,  1197,  5984,  2443,  1113,   170,\n",
      "         1304,  3014,   102])\n",
      "entity_list: ['feedforward network']\n",
      "entity_token: [tensor([ 4877, 14467,  1197,  5984,  2443])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: is an operation on two binary values, x 1 and x . When exactly one of these binary values is equal\n",
      "content_token: tensor([  101,  1110,  1126,  2805,  1113,  1160, 13480,  4718,   117,   193,\n",
      "          122,  1105,   193,   119,  1332,  2839,  1141,  1104,  1292, 13480,\n",
      "         4718,  1110,  4463,   102])\n",
      "entity_list: ['XOR function']\n",
      "entity_token: [tensor([ 161, 9565, 3053])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: want our network to perform correctly on the four points X = [0,0] , [0,1] ,   { [1,0] , and\n",
      "content_token: tensor([  101,  1328,  1412,  2443,  1106,  3870, 11214,  1113,  1103,  1300,\n",
      "         1827,   161,   134,   164,   121,   117,   121,   166,   117,   164,\n",
      "          121,   117,   122,   166,   117,   196,   164,   122,   117,   121,\n",
      "          166,   117,  1105,   102])\n",
      "entity_list: ['network']\n",
      "entity_token: [tensor([2443])]\n",
      "label: tensor([0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: ,   { [1,0] , and [1,1] . We will train the network on all four of these points. The   } only\n",
      "content_token: tensor([ 101,  117,  196,  164,  122,  117,  121,  166,  117, 1105,  164,  122,\n",
      "         117,  122,  166,  119, 1284, 1209, 2669, 1103, 2443, 1113, 1155, 1300,\n",
      "        1104, 1292, 1827,  119, 1109,  198, 1178,  102])\n",
      "entity_list: ['network']\n",
      "entity_token: [tensor([2443])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: as a regression problem and use a mean squared error loss function. We choose this loss function to\n",
      "content_token: tensor([  101,  1112,   170,  1231, 24032,  2463,  1105,  1329,   170,  1928,\n",
      "        23215,  7353,  2445,  3053,   119,  1284,  4835,  1142,  2445,  3053,\n",
      "         1106,   102])\n",
      "entity_list: ['regression problem', 'mean squared error loss function']\n",
      "entity_token: [tensor([ 1231, 24032,  2463]), tensor([ 1928, 23215,  7353,  2445,  3053])]\n",
      "label: tensor([0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: loss function to simplify the math for this example as much as possible. In practical applications,\n",
      "content_token: tensor([  101,  2445,  3053,  1106, 27466,  8223, 22881,  1103, 12523,  1111,\n",
      "         1142,  1859,  1112,  1277,  1112,  1936,   119,  1130,  6691,  4683,\n",
      "          117,   102])\n",
      "entity_list: ['loss function']\n",
      "entity_token: [tensor([2445, 3053])]\n",
      "label: tensor([0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: appropriate cost function for modeling binary data. More appropriate approaches are described in\n",
      "content_token: tensor([  101,  5806,  2616,  3053,  1111, 13117, 13480,  2233,   119,  3046,\n",
      "         5806,  8015,  1132,  1758,  1107,   102])\n",
      "entity_list: ['appropriate cost function']\n",
      "entity_token: [tensor([5806, 2616, 3053])]\n",
      "label: tensor([0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: are described in section 6.2.2.2. Evaluated on our whole training set, the MSE loss function is 1 2\n",
      "content_token: tensor([  101,  1132,  1758,  1107,  2237,   127,   119,   123,   119,   123,\n",
      "          119,   123,   119,  9734,  7535,  2913,  1113,  1412,  2006,  2013,\n",
      "         1383,   117,  1103, 10978,  2036,  2445,  3053,  1110,   122,   123,\n",
      "          102])\n",
      "entity_list: ['MSE loss function']\n",
      "entity_token: [tensor([10978,  2036,  2445,  3053])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "        1, 1, 1, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of w and b. Our model is defined to be f(x;w,b) = x w +b. (6.2)  We can minimize J(θ) in closed\n",
      "content_token: tensor([  101,  1104,   192,  1105,   171,   119,  3458,  2235,  1110,  3393,\n",
      "         1106,  1129,   175,   113,   193,   132,   192,   117,   171,   114,\n",
      "          134,   193,   192,   116,   171,   119,   113,   127,   119,   123,\n",
      "          114,  1284,  1169, 20220,   147,   113,   425,   114,  1107,  1804,\n",
      "          102])\n",
      "entity_list: ['Jθ']\n",
      "entity_token: [tensor([  147, 28345])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: model is able to represent the solution. Specifically, we will introduce a very simple feedforward\n",
      "content_token: tensor([  101,  2235,  1110,  1682,  1106,  4248,  1103,  5072,   119, 21325,\n",
      "          117,  1195,  1209,  8698,   170,  1304,  3014,  4877, 14467,  1197,\n",
      "         5984,   102])\n",
      "entity_list: ['feedforward model']\n",
      "entity_token: [tensor([ 4877, 14467,  1197,  5984,  2235])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: simple feedforward network with one hidden layer containing two hidden units. See figure 6.2 for an\n",
      "content_token: tensor([  101,  3014,  4877, 14467,  1197,  5984,  2443,  1114,  1141,  4610,\n",
      "         6440,  4051,  1160,  4610,  2338,   119,  3969,  2482,   127,   119,\n",
      "          123,  1111,  1126,   102])\n",
      "entity_list: ['feedforward network']\n",
      "entity_token: [tensor([ 4877, 14467,  1197,  5984,  2443])]\n",
      "label: tensor([0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: figure 6.2 for an illustration of this model. This feedforward network has a vector of hidden units\n",
      "content_token: tensor([  101,  2482,   127,   119,   123,  1111,  1126, 17011,  1104,  1142,\n",
      "         2235,   119,  1188,  4877, 14467,  1197,  5984,  2443,  1144,   170,\n",
      "         9479,  1104,  4610,  2338,   102])\n",
      "entity_list: ['feedforward network']\n",
      "entity_token: [tensor([ 4877, 14467,  1197,  5984,  2443])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: of hidden units h that are computed by a function f(1)(x; W,c). The values of these hidden units\n",
      "content_token: tensor([  101,  1104,  4610,  2338,   177,  1115,  1132,  3254, 18505,  1118,\n",
      "          170,  3053,   175,   113,   122,   114,   113,   193,   132,   160,\n",
      "          117,   172,   114,   119,  1109,  4718,  1104,  1292,  4610,  2338,\n",
      "          102])\n",
      "entity_list: ['hidden units']\n",
      "entity_token: [tensor([4610, 2338])]\n",
      "label: tensor([0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 2, 1, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: layer is the output layer of the network. The output layer is still just a linear regression model,\n",
      "content_token: tensor([  101,  6440,  1110,  1103,  5964,  6440,  1104,  1103,  2443,   119,\n",
      "         1109,  5964,  6440,  1110,  1253,  1198,   170,  7378,  1231, 24032,\n",
      "         2235,   117,   102])\n",
      "entity_list: ['output layer']\n",
      "entity_token: [tensor([5964, 6440])]\n",
      "label: tensor([0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: to make f(1) be linear as well. Unfortunately, if f(1) were linear, then the feedforward network as\n",
      "content_token: tensor([  101,  1106,  1294,   175,   113,   122,   114,  1129,  7378,  1112,\n",
      "         1218,   119,  7595,   117,  1191,   175,   113,   122,   114,  1127,\n",
      "         7378,   117,  1173,  1103,  4877, 14467,  1197,  5984,  2443,  1112,\n",
      "          102])\n",
      "entity_list: ['feedforward network']\n",
      "entity_token: [tensor([ 4877, 14467,  1197,  5984,  2443])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        2, 1, 1, 1, 1, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "content: followed by a fixed, nonlinear function called an activation function. We use that strategy here,\n",
      "content_token: tensor([  101,  1723,  1118,   170,  4275,   117,  1664, 24984,  3053,  1270,\n",
      "         1126, 14915,  3053,   119,  1284,  1329,  1115,  5564,  1303,   117,\n",
      "          102])\n",
      "entity_list: ['activation function']\n",
      "entity_token: [tensor([14915,  3053])]\n",
      "label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_e3353435f5d2cd1db667be34c402d97c in your email.) {\"error\":{\"message\":\"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_e3353435f5d2cd1db667be34c402d97c in your email.)\",\"type\":\"server_error\",\"param\":null,\"code\":null}} 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_e3353435f5d2cd1db667be34c402d97c in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Server': 'Tengine', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Date': 'Mon, 04 Mar 2024 05:30:35 GMT', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'OPTIONS,GET,POST', 'Access-Control-Allow-Headers': '*', 'Access-Control-Max-Age': '6000', 'Vary': 'Origin, Access-Control-Request-Method, Access-Control-Request-Headers', 'Ali-Swift-Global-Savetime': '1709530253', 'Via': 'cache32.l2cn2656[419,419,500-0,M], cache32.l2cn2656[420,0], cache5.cn269[493,502,500-1281,M], cache5.cn269[495,0]', 'Cache-Control': 'no-cache', 'Age': '0', 'X-Cache': 'MISS TCP_MISS dirn:-2:-2', 'X-Swift-Error': 'orig response 5xx error', 'X-Swift-SaveTime': 'Mon, 04 Mar 2024 05:30:53 GMT', 'X-Swift-CacheTime': '0', 'Timing-Allow-Origin': '*', 'EagleId': 'dec0ba1917095302528441705e'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m content_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m11.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12.1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mprocess_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 53\u001b[0m, in \u001b[0;36mprocess_content\u001b[1;34m(content_dict, content_list)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Check if each entity is valid using check chatbot\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m entity_list_temp:\n\u001b[1;32m---> 53\u001b[0m     answer_check \u001b[38;5;241m=\u001b[39m \u001b[43mbot_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer_check \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     55\u001b[0m         entity_list\u001b[38;5;241m.\u001b[39mappend(e)\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36mChat.ask\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt})\n\u001b[0;32m     17\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-LzwgVgu5xvNPpwoqCdeeVcAt7Tu7ZoZICXzzkheldIbXA60h\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-16k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconversation_list\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m answer \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer})\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32me:\\GitHub\\kg\\.conda\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAPIError\u001b[0m: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_e3353435f5d2cd1db667be34c402d97c in your email.) {\"error\":{\"message\":\"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_e3353435f5d2cd1db667be34c402d97c in your email.)\",\"type\":\"server_error\",\"param\":null,\"code\":null}} 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_e3353435f5d2cd1db667be34c402d97c in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Server': 'Tengine', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Date': 'Mon, 04 Mar 2024 05:30:35 GMT', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'OPTIONS,GET,POST', 'Access-Control-Allow-Headers': '*', 'Access-Control-Max-Age': '6000', 'Vary': 'Origin, Access-Control-Request-Method, Access-Control-Request-Headers', 'Ali-Swift-Global-Savetime': '1709530253', 'Via': 'cache32.l2cn2656[419,419,500-0,M], cache32.l2cn2656[420,0], cache5.cn269[493,502,500-1281,M], cache5.cn269[495,0]', 'Cache-Control': 'no-cache', 'Age': '0', 'X-Cache': 'MISS TCP_MISS dirn:-2:-2', 'X-Swift-Error': 'orig response 5xx error', 'X-Swift-SaveTime': 'Mon, 04 Mar 2024 05:30:53 GMT', 'X-Swift-CacheTime': '0', 'Timing-Allow-Origin': '*', 'EagleId': 'dec0ba1917095302528441705e'}"
     ]
    }
   ],
   "source": [
    "content_list = [\"7.1\", \"8.1\", \"9.1\", \"10.1\", \"11.1\", \"12.1\"]\n",
    "process_content(content_dict, content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "35ee6242-c675-42e5-b346-241bbbc10db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T10:30:24.565791Z",
     "iopub.status.busy": "2024-02-21T10:30:24.565791Z",
     "iopub.status.idle": "2024-02-21T10:30:24.570139Z",
     "shell.execute_reply": "2024-02-21T10:30:24.570139Z",
     "shell.execute_reply.started": "2024-02-21T10:30:24.565791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataDir + \"relations/\" + \"sample.csv\", index_col=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
