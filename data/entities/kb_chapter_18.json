{
    "Graphics processing unit": {
        "url": "https://en.wikipedia.org/wiki/Graphics_processing_unit",
        "summary": "A graphics processing unit (GPU) is a specialized electronic circuit initially designed to accelerate computer graphics and image processing (either on a video card or embedded on motherboards, mobile phones, personal computers, workstations, and game consoles). After their initial design, GPUs were found to be useful for non-graphic calculations involving embarrassingly parallel problems due to their parallel structure. Other non-graphical uses include the training of neural networks and cryptocurrency mining."
    },
    "Stochastic gradient descent": {
        "url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent",
        "summary": "Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in exchange for a lower convergence rate.While the basic idea behind stochastic approximation can be traced back to the Robbins\u2013Monro algorithm of the 1950s, stochastic gradient descent has become an important optimization method in machine learning."
    },
    "Machine learning": {
        "url": "https://en.wikipedia.org/wiki/Machine_learning",
        "summary": "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions. Recently, generative artificial neural networks have been able to surpass many previous approaches in performance. Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods."
    },
    "Algorithm": {
        "url": "https://en.wikipedia.org/wiki/Algorithm",
        "summary": "In mathematics and computer science, an algorithm ( ) is a finite sequence of rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning), achieving automation eventually. Using human characteristics as descriptors of machines in metaphorical ways was already practiced by Alan Turing with terms such as \"memory\", \"search\" and \"stimulus\".In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input."
    },
    "Rapid eye movement sleep": {
        "url": "https://en.wikipedia.org/wiki/Rapid_eye_movement_sleep",
        "summary": "Rapid eye movement sleep (REM sleep or REMS) is a unique phase of sleep in mammals (including humans) and birds, characterized by random rapid movement of the eyes, accompanied by low muscle tone throughout the body, and the propensity of the sleeper to dream vividly.\nThe REM phase is also known as paradoxical sleep (PS) and sometimes  desynchronized sleep or dreamy sleep, because of physiological similarities to waking states including rapid, low-voltage desynchronized brain waves. Electrical and chemical activity regulating this phase seems to originate in the brain stem, and is characterized most notably by an abundance of the neurotransmitter acetylcholine, combined with a nearly complete absence of monoamine neurotransmitters histamine, serotonin and norepinephrine. Experiences of REM sleep are not transferred to permanent memory due to absence of norepinephrine.REM sleep is physiologically different from the other phases of sleep, which are collectively referred to as non-REM sleep (NREM sleep, NREMS, synchronized sleep). The absence of visual and auditory stimulation (sensory deprivation) during REM sleep can cause hallucinations. REM and non-REM sleep alternate within one sleep cycle, which lasts about 90 minutes in adult humans. As sleep cycles continue, they shift towards a higher proportion of REM sleep. The transition to REM sleep brings marked physical changes, beginning with electrical bursts called \"ponto-geniculo-occipital waves\" (PGO waves) originating in the brain stem. REM sleep occurs 4 times in a 7 hour sleep. Organisms in REM sleep suspend central homeostasis, allowing large fluctuations in respiration, thermoregulation and circulation which do not occur in any other modes of sleeping or waking. The body abruptly loses muscle tone, a state known as REM atonia.In 1953, Professor Nathaniel Kleitman and his student Eugene Aserinsky defined rapid eye movement and linked it to dreams. REM sleep was further described by researchers, including William Dement and Michel Jouvet. Many experiments have involved awakening test subjects whenever they begin to enter the REM phase, thereby producing a state known as REM deprivation. Subjects allowed to sleep normally again usually experience a modest REM rebound. Techniques of neurosurgery, chemical injection, electroencephalography, positron emission tomography, and reports of dreamers upon waking, have all been used to study this phase of sleep."
    },
    "Dream": {
        "url": "https://en.wikipedia.org/wiki/Dream",
        "summary": "A dream is a succession of images, ideas, emotions, and sensations that usually occur involuntarily in the mind during certain stages of sleep. Humans spend about two hours dreaming per night, and each dream lasts around 5 to 20 minutes, although the dreamer may perceive the dream as being much longer than this.The content and function of dreams have been topics of scientific, philosophical and religious interest throughout recorded history. Dream interpretation, practiced by the Babylonians in the third millennium BCE and even earlier by the ancient Sumerians, figures prominently in religious texts in several traditions, and has played a lead role in psychotherapy. The scientific study of dreams is called oneirology. Most modern dream study focuses on the neurophysiology of dreams and on proposing and testing hypotheses regarding dream function. It is not known where in the brain dreams originate, if there is a single origin for dreams or if multiple regions of the brain are involved, or what the purpose of dreaming is for the body or mind.\nThe human dream experience and what to make of it has undergone sizable shifts over the course of history. Long ago, according to writings from Mesopotamia and Ancient Egypt, dreams dictated post-dream behaviors to an extent that was sharply reduced in later millennia. These ancient writings about dreams highlight visitation dreams, where a dream figure, usually a deity or a prominent forebear, commands the dreamer to take specific actions, and which may predict future events. Framing the dream experience varies across cultures as well as through time.\nDreaming and sleep are intertwined. Dreams occur mainly in the rapid-eye movement (REM) stage of sleep\u2014when brain activity is high and resembles that of being awake. Because REM sleep is detectable in many species, and because research suggests that all mammals experience REM, linking dreams to REM sleep has led to conjectures that animals dream. However, humans dream during non-REM sleep, also, and not all REM awakenings elicit dream reports. To be studied, a dream must first be reduced to a verbal report, which is an account of the subject's memory of the dream, not the subject's dream experience itself. So, dreaming by non-humans is currently unprovable, as is dreaming by human fetuses and pre-verbal infants."
    },
    "Restricted Boltzmann machine": {
        "url": "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine",
        "summary": "A restricted Boltzmann machine (RBM) (also called a restricted Sherrington\u2013Kirkpatrick model with external field or restricted stochastic Ising\u2013Lenz\u2013Little model) is a generative stochastic artificial neural network that can learn a probability distribution over its set of inputs.RBMs were initially proposed under the name Harmonium by Paul Smolensky in 1986, and rose to prominence after Geoffrey Hinton and collaborators used fast learning algorithms for them in the mid-2000. RBMs have found applications in dimensionality reduction, classification, collaborative filtering, feature learning, topic modelling and even many body quantum mechanics. They can be trained in either supervised or unsupervised ways, depending on the task.\nAs their name implies, RBMs are a variant of Boltzmann machines, with the restriction that their neurons must form a bipartite graph: \na pair of nodes from each of the two groups of units (commonly referred to as the \"visible\" and \"hidden\" units respectively) may have a symmetric connection between them; and there are no connections between nodes within a group. By contrast, \"unrestricted\" Boltzmann machines may have connections between hidden units. This restriction allows for more efficient training algorithms than are available for the general class of Boltzmann machines, in particular the gradient-based contrastive divergence algorithm.Restricted Boltzmann machines can also be used in deep learning networks. In particular, deep belief networks can be formed by \"stacking\" RBMs and optionally fine-tuning the resulting deep network with gradient descent and backpropagation."
    },
    "Autoencoder": {
        "url": "https://en.wikipedia.org/wiki/Autoencoder",
        "summary": "An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. The autoencoder learns an efficient representation (encoding) for a set of data, typically for dimensionality reduction.\nVariants exist, aiming to force the learned representations to assume useful properties. Examples are regularized autoencoders (Sparse, Denoising and Contractive), which are effective in learning representations for subsequent classification tasks, and Variational autoencoders, with applications as generative models. Autoencoders are applied to many problems, including facial recognition, feature detection, anomaly detection and acquiring the meaning of words. Autoencoders are also generative models which can randomly generate new data that is similar to the input data (training data)."
    },
    "Deep learning": {
        "url": "https://en.wikipedia.org/wiki/Deep_learning",
        "summary": "Deep learning is the subset of machine learning methods which are based on artificial neural networks with representation learning. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog."
    },
    "Training": {
        "url": "https://en.wikipedia.org/wiki/Training",
        "summary": "Training is teaching, or developing in oneself or others, any skills and knowledge  or fitness that relate to specific useful competencies. Training has specific goals of improving one's capability, capacity, productivity and performance. It forms the core of apprenticeships and provides the backbone of content at institutes of technology (also known as technical colleges or polytechnics). In addition to the basic training required for a trade, occupation or profession, training may continue beyond initial competence to maintain, upgrade and update skills throughout working life. People within some professions and occupations may refer to this sort of training as professional development. Training also refers to the development of physical fitness related to a specific competence, such as sport, martial arts, military applications and some other occupations."
    },
    "G-Eazy discography": {
        "url": "https://en.wikipedia.org/wiki/G-Eazy_discography",
        "summary": "The American rapper G-Eazy has released six studio albums, one compilation album, six mixtapes, nine extended plays and 73 singles (including 24 singles as a featured artist)."
    },
    "Monte Carlo method": {
        "url": "https://en.wikipedia.org/wiki/Monte_Carlo_method",
        "summary": "Monte Carlo methods, or Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle. They are often used in physical and mathematical problems and are most useful when it is difficult or impossible to use other approaches. Monte Carlo methods are mainly used in three problem classes: optimization, numerical integration, and generating draws from a probability distribution.\nIn physics-related problems, Monte Carlo methods are useful for simulating systems with many coupled degrees of freedom, such as fluids, disordered materials, strongly coupled solids, and cellular structures (see cellular Potts model, interacting particle systems, McKean\u2013Vlasov processes, kinetic models of gases).\nOther examples include modeling phenomena with significant uncertainty in inputs such as the calculation of risk in business and, in mathematics, evaluation of multidimensional definite integrals with complicated boundary conditions. In application to systems engineering problems (space, oil exploration, aircraft design, etc.), Monte Carlo\u2013based predictions of failure, cost overruns and schedule overruns are routinely better than human intuition or alternative \"soft\" methods.In principle, Monte Carlo methods can be used to solve any problem having a probabilistic interpretation. By the law of large numbers, integrals described by the expected value of some random variable can be approximated by taking the empirical mean (a.k.a. the 'sample mean') of independent samples of the variable. When the probability distribution of the variable is parameterized, mathematicians often use a Markov chain Monte Carlo (MCMC) sampler. The central idea is to design a judicious Markov chain model with a prescribed stationary probability distribution. That is, in the limit, the samples being generated by the MCMC method will be samples from the desired (target) distribution. By the ergodic theorem, the stationary distribution is approximated by the empirical measures of the random states of the MCMC sampler.\nIn other problems, the objective is generating draws from a sequence of probability distributions satisfying a nonlinear evolution equation. These flows of probability distributions can always be interpreted as the distributions of the random states of a Markov process whose transition probabilities depend on the distributions of the current random states (see McKean\u2013Vlasov processes, nonlinear filtering equation). In other instances we are given a flow of probability distributions with an increasing level of sampling complexity (path spaces models with an increasing time horizon, Boltzmann\u2013Gibbs measures associated with decreasing temperature parameters, and many others). These models can also be seen as the evolution of the law of the random states of a nonlinear Markov chain. A natural way to simulate these sophisticated nonlinear Markov processes is to sample multiple copies of the process, replacing in the evolution equation the unknown distributions of the random states by the sampled empirical measures. In contrast with traditional Monte Carlo and MCMC methodologies, these mean-field particle techniques rely on sequential interacting samples. The terminology mean field reflects the fact that each of the samples (a.k.a. particles, individuals, walkers, agents, creatures, or phenotypes) interacts with the empirical measures of the process. When the size of the system tends to infinity, these random empirical measures converge to the deterministic distribution of the random states of the nonlinear Markov chain, so that the statistical interaction between particles vanishes.\nDespite its conceptual and algorithmic simplicity, the computational cost associated with a Monte Carlo simulation can be staggeringly high. In general the method requires many samples to get a good approximation, which may incur an arbitrarily large total runtime if the processing time of a single sample is high. Although this is a severe limitation in very complex problems, the embarrassingly parallel nature of the algorithm allows this large cost to be reduced (perhaps to a feasible level) through parallel computing strategies in local processors, clusters, cloud computing, GPU, FPGA, etc."
    },
    "Neural coding": {
        "url": "https://en.wikipedia.org/wiki/Neural_coding",
        "summary": "Neural coding (or neural representation) is a neuroscience field concerned with characterising the hypothetical relationship between the stimulus and the individual or ensemble neuronal responses and the relationship among the electrical activity of the neurons in the ensemble. Based on the theory that\nsensory and other information is represented in the brain by networks of neurons, it is thought that neurons can encode both digital and analog information."
    },
    "Boltzmann machine": {
        "url": "https://en.wikipedia.org/wiki/Boltzmann_machine",
        "summary": "A Boltzmann machine (also called Sherrington\u2013Kirkpatrick model with external field or stochastic Ising\u2013Lenz\u2013Little model) is a stochastic spin-glass model with an external field, i.e., a Sherrington\u2013Kirkpatrick model, that is a stochastic Ising model. It is a statistical physics technique applied in the context of cognitive science. It is also classified as a Markov random field.Boltzmann machines are theoretically intriguing because of the locality and Hebbian nature of their training algorithm (being trained by Hebb's rule), and because of their parallelism and the resemblance of their dynamics to simple physical processes.  Boltzmann machines with unconstrained connectivity have not been proven useful for practical problems in machine learning or inference, but if the connectivity is properly constrained, the learning can be made efficient enough to be useful for practical problems.They are named after the Boltzmann distribution in statistical mechanics, which is used in their sampling function.  They were heavily popularized and promoted by Geoffrey Hinton, Terry Sejnowski and Yann LeCun in cognitive sciences communities and in machine learning.  As a more general class within machine learning these models are called \"energy based models\" (EBM), because Hamiltonians of spin glasses are used as a starting point to define the learning task."
    },
    "Summation": {
        "url": "https://en.wikipedia.org/wiki/Summation",
        "summary": "In mathematics, summation is the addition of a sequence of any kind of numbers, called addends or summands; the result is their sum or total. Beside numbers, other types of values can be summed as well: functions, vectors, matrices, polynomials and, in general, elements of any type of mathematical objects on which an operation denoted \"+\" is defined.\nSummations of infinite sequences are called series. They involve the concept of limit, and are not considered in this article.\nThe summation of an explicit sequence is denoted as a succession of additions. For example, summation of [1, 2, 4, 2] is denoted 1 + 2 + 4 + 2, and results in 9, that is, 1 + 2 + 4 + 2 = 9. Because addition is associative and commutative, there is no need of parentheses, and the result is the same irrespective of the order of the summands. Summation of a sequence of only one element results in this element itself. Summation of an empty sequence (a sequence with no elements), by convention, results in 0.\nVery often, the elements of a sequence are defined, through a regular pattern, as a function of their place in the sequence. For simple patterns, summation of long sequences may be represented with most summands replaced by ellipses. For example, summation of the first 100 natural numbers may be written as 1 + 2 + 3 + 4 + \u22ef + 99 + 100. Otherwise, summation is denoted by using \u03a3 notation, where \n  \n    \n      \n        \u2211\n      \n    \n    {\\textstyle \\sum }\n   is an enlarged capital Greek letter sigma. For example, the sum of the first n natural numbers can be denoted as \n  \n    \n      \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        i\n        .\n      \n    \n    {\\textstyle \\sum _{i=1}^{n}i.}\n  \nFor long summations, and summations of variable length (defined with ellipses or \u03a3 notation), it is a common problem to find closed-form expressions for the result. For example,\n\n  \n    \n      \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        i\n        =\n        \n          \n            \n              n\n              (\n              n\n              +\n              1\n              )\n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle \\sum _{i=1}^{n}i={\\frac {n(n+1)}{2}}.}\n  Although such formulas do not always exist, many summation formulas have been discovered\u2014with some of the most common and elementary ones being listed in the remainder of this article."
    },
    "Integral": {
        "url": "https://en.wikipedia.org/wiki/Integral",
        "summary": "In mathematics, an integral is the continuous analog of a sum, which is used to calculate areas, volumes, and their generalizations. Integration, the process of computing an integral, is one of the two fundamental operations of calculus, the other being differentiation. Integration started as a method to solve problems in mathematics and physics, such as finding the area under a curve, or determining displacement from velocity. Today integration is used in a wide variety of scientific fields.\nThe integrals enumerated here are called definite integrals, which can be interpreted as the signed area of the region in the plane that is bounded by the graph of a given function between two points in the real line. Conventionally, areas above the horizontal axis of the plane are positive while areas below are negative. Integrals also refer to the concept of an antiderivative, a function whose derivative is the given function; in this case, they are also called indefinite integrals. The fundamental theorem of calculus relates definite integrals with differentiation and provides a method to compute the definite integral of a function when its antiderivative is known; differentiation and integration are inverse operations.\nAlthough methods of calculating areas and volumes dated from ancient Greek mathematics, the principles of integration were formulated independently by Isaac Newton and Gottfried Wilhelm Leibniz in the late 17th century, who thought of the area under a curve as an infinite sum of rectangles of infinitesimal width. Bernhard Riemann later gave a rigorous definition of integrals, which is based on a limiting procedure that approximates the area of a curvilinear region by breaking the region into infinitesimally thin vertical slabs. In the early 20th century, Henri Lebesgue generalized Riemann's formulation by introducing what is now referred to as the Lebesgue integral; it is more robust than Riemann's in the sense that a wider class of functions are Lebesgue-integrable.\nIntegrals may be generalized depending on the type of the function as well as the domain over which the integration is performed. For example, a line integral is defined for functions of two or more variables, and the interval of integration is replaced by a curve connecting the two endpoints of the interval. In a surface integral, the curve is replaced by a piece of a surface in three-dimensional space."
    },
    "Apathy": {
        "url": "https://en.wikipedia.org/wiki/Apathy",
        "summary": "Apathy is a lack of feeling, emotion, interest, or concern about something. It is a state of indifference, or the suppression of emotions such as concern, excitement, motivation, or passion. An apathetic individual has an absence of interest in or concern about emotional, social, spiritual, philosophical, virtual, or physical life and the world. Apathy can also be defined as a person's lack of goal orientation. Apathy falls in the less extreme spectrum of diminished motivation, with abulia in the middle and akinetic mutism being more extreme than both apathy and abulia.The apathetic may lack a sense of purpose, worth, or meaning in their life. People with severe apathy tend to have a lower quality of life and are at a higher risk for mortality and early institutionalization. They may also exhibit insensibility or sluggishness. In positive psychology, apathy is described as a result of the individuals' feeling they do not possess the level of skill required to confront a challenge (i.e. \"flow\"). It may also be a result of perceiving no challenge at all (e.g., the challenge is irrelevant to them, or conversely, they have learned helplessness). Apathy is usually felt only in the short term, but sometimes it becomes a long-term or even lifelong state, often leading to deeper social and psychological issues.Apathy should be distinguished from reduced affect display, which refers to reduced emotional expression but not necessarily reduced emotion.\nPathological apathy, characterized by extreme forms of apathy, is now known to occur in many different brain disorders, including neurodegenerative conditions often associated with dementia such as Alzheimer's disease, Parkinson's disease, and psychiatric disorders such as schizophrenia. Although many patients with pathological apathy also have depression, several studies have shown that the two syndromes are dissociable: apathy can occur independent of depression and vice versa."
    },
    "Simulation": {
        "url": "https://en.wikipedia.org/wiki/Simulation",
        "summary": "A simulation is an imitative representation of a process or system that could exist in the real world. In this broad sense, simulation can often be used interchangeably with model. Sometimes a clear distinction between the two terms is made, in which simulations require the use of models; the model represents the key characteristics or behaviors of the selected system or process, whereas the simulation represents the evolution of the model over time. Another way to distinguish between the terms is to define simulation as experimentation with the help of a model. This definition includes time-independent simulations. Often, computers are used to execute the simulation.\nSimulation is used in many contexts, such as simulation of technology for performance tuning or optimizing, safety engineering, testing, training, education, and video games. Simulation is also used with scientific modelling of natural systems or human systems to gain insight into their functioning, as in economics. Simulation can be used to show the eventual real effects of alternative conditions and courses of action. Simulation is also used when the real system cannot be engaged, because it may not be accessible, or it may be dangerous or unacceptable to engage, or it is being designed but not yet built, or it may simply not exist.Key issues in modeling and simulation include the acquisition of valid sources of information about the relevant selection of key characteristics and behaviors used to build the model, the use of simplifying approximations and assumptions within the model, and fidelity and validity of the simulation outcomes. Procedures and protocols for model verification and validation are an ongoing field of academic study, refinement, research and development in simulations technology or practice, particularly in the work of computer simulation."
    }
}