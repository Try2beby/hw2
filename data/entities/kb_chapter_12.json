{
    "Neuroscience": {
        "url": "https://en.wikipedia.org/wiki/Neuroscience",
        "summary": "Neuroscience is the scientific study of the nervous system (the brain, spinal cord, and peripheral nervous system), its functions and disorders. It is a multidisciplinary science that combines physiology, anatomy, molecular biology, developmental biology, cytology, psychology, physics, computer science, chemistry, medicine, statistics, and mathematical modeling to understand the fundamental and emergent properties of neurons, glia and neural circuits. The understanding of the biological basis of learning, memory, behavior, perception, and consciousness has been described by Eric Kandel as the \"epic challenge\" of the biological sciences.The scope of neuroscience has broadened over time to include different approaches used to study the nervous system at different scales. The techniques used by neuroscientists have expanded enormously, from molecular and cellular studies of individual neurons to imaging of sensory, motor and cognitive tasks in the brain.\n\n"
    },
    "Neuron": {
        "url": "https://en.wikipedia.org/wiki/Neuron",
        "summary": "Within a nervous system, a neuron, neurone, or nerve cell is an electrically excitable cell that fires electric signals called action potentials across a neural network. Neurons communicate with other cells via synapses, which are specialized connections that commonly use minute amounts of chemical neurotransmitters to pass the electric signal from the presynaptic neuron to the target cell through the synaptic gap. \nThe neuron is the main component of nervous tissue in all animals except sponges and placozoa. Non-animals like plants and fungi do not have nerve cells. The ability to generate electric signals first appeared in evolution 700 million years ago. 800 million years ago, predecessors of neurons were the peptidergic secretory cells. They eventually gained new gene modules which enabled cells to create post-synaptic scaffolds and ion channels that generate fast electrical signals. The ability to generate electric signals was a key innovation in the evolution of the nervous system.Neurons are typically classified into three types based on their function. Sensory neurons respond to stimuli such as touch, sound, or light that affect the cells of the sensory organs, and they send signals to the spinal cord or brain. Motor neurons receive signals from the brain and spinal cord to control everything from muscle contractions to glandular output. Interneurons connect neurons to other neurons within the same region of the brain or spinal cord. When multiple neurons are functionally connected together, they form what is called a neural circuit.\nNeurons are special cells which are made up of some structures that are common to all other eukaryotic cells such as the cell body (soma), a nucleus, smooth and rough endoplasmic reticulum, Golgi apparatus, mitochondria, and other cellular components. Additionally, neurons have other unique structures  such as dendrites, and a single axon. The soma is a compact structure, and the axon and dendrites are filaments extruding from the soma. Dendrites typically branch profusely and extend a few hundred micrometers from the soma. The axon leaves the soma at a swelling called the axon hillock and travels for as far as 1 meter in humans or more in other species. It branches but usually maintains a constant diameter. At the farthest tip of the axon's branches are axon terminals, where the neuron can transmit a signal across the synapse to another cell. Neurons may lack dendrites or have no axon. The term neurite is used to describe either a dendrite or an axon, particularly when the cell is undifferentiated.\nMost neurons receive signals via the dendrites and soma and send out signals down the axon. At the majority of synapses, signals cross from the axon of one neuron to a dendrite of another. However, synapses can connect an axon to another axon or a dendrite to another dendrite.\nThe signaling process is partly electrical and partly chemical. Neurons are electrically excitable, due to maintenance of voltage gradients across their membranes. If the voltage changes by a large enough amount over a short interval, the neuron generates an all-or-nothing electrochemical pulse called an action potential. This potential travels rapidly along the axon and activates synaptic connections as it reaches them. Synaptic signals may be excitatory or inhibitory, increasing or reducing the net voltage that reaches the soma.\nIn most cases, neurons are generated by neural stem cells during brain development and childhood. Neurogenesis largely ceases during adulthood in most areas of the brain."
    },
    "Graphics processing unit": {
        "url": "https://en.wikipedia.org/wiki/Graphics_processing_unit",
        "summary": "A graphics processing unit (GPU) is a specialized electronic circuit initially designed to accelerate computer graphics and image processing (either on a video card or embedded on motherboards, mobile phones, personal computers, workstations, and game consoles). After their initial design, GPUs were found to be useful for non-graphic calculations involving embarrassingly parallel problems due to their parallel structure. Other non-graphical uses include the training of neural networks and cryptocurrency mining.\n\n"
    },
    "CUDA": {
        "url": "https://en.wikipedia.org/wiki/CUDA",
        "summary": "CUDA (or Compute Unified Device Architecture) is a proprietary and closed source parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing units (GPUs) for general purpose processing, an approach called general-purpose computing on GPUs (GPGPU). CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements, for the execution of compute kernels.CUDA is designed to work with programming languages such as C, C++, and Fortran. This accessibility makes it easier for specialists in parallel programming to use GPU resources, in contrast to prior APIs like Direct3D and OpenGL, which required advanced skills in graphics programming. CUDA-powered GPUs also support programming frameworks such as OpenMP, OpenACC and OpenCL; and HIP by compiling such code to CUDA.\nCUDA was created by Nvidia. When it was first introduced, the name was an acronym for Compute Unified Device Architecture, but Nvidia later dropped the common use of the acronym."
    },
    "Nvidia": {
        "url": "https://en.wikipedia.org/wiki/Nvidia",
        "summary": "Nvidia Corporation (; en-VID-ee-\u0259) is an American multinational technology company incorporated in Delaware and based in Santa Clara, California. It is a software and fabless company which designs graphics processing units (GPUs), application programming interface (APIs) for data science and high-performance computing as well as system on a chip units (SoCs) for the mobile computing and automotive market. Nvidia is a dominant supplier of artificial intelligence hardware and software. Its professional line of GPUs are used in workstations for applications in such fields as architecture, engineering and construction, media and entertainment, automotive, scientific research, and manufacturing design.In addition to GPU manufacturing, Nvidia provides an API called CUDA that allows the creation of massively parallel programs which utilize GPUs. They are deployed in supercomputing sites around the world. More recently, it has moved into the mobile computing market, where it produces Tegra mobile processors for smartphones and tablets as well as vehicle navigation and entertainment systems. Its competitors include AMD, Intel, Qualcomm and AI-accelerator companies such as Cerebras and Graphcore. It also makes AI-powered software for audio and video processing, e.g. Nvidia Maxine.Nvidia's GPUs are used for edge-to-cloud computing and supercomputers. Nvidia expanded its presence in the gaming industry with its handheld game consoles Shield Portable, Shield Tablet and Shield TV, and its cloud gaming service GeForce Now.\nNvidia's offer to acquire Arm from SoftBank in September 2020 failed to materialize following extended regulatory scrutiny, leading to the termination of the deal in February 2022 in what would have been the largest semiconductor acquisition."
    },
    "Theano": {
        "url": "https://en.wikipedia.org/wiki/Theano",
        "summary": "In Greek mythology, Theano (; Ancient Greek: \u0398\u03b5\u03b1\u03bd\u03ce) may refer to the following personages:\n\nTheano, wife of Metapontus, king of Icaria. Metapontus demanded that she bear him children, or leave the kingdom. She presented the children of Melanippe to her husband, as if they were her own. Later Theano bore him two sons of her own and, wishing to leave the kingdom to her own children, sent them to kill Melanippe's. In the fight that ensued, her two sons were killed, and she committed suicide upon hearing the news.\nTheano, one of the Dana\u00efdes, daughter of Danaus and Polyxo. She married (and murdered) Phantes, son of Aegyptus and Caliadne.\nTheano, a priestess of Athena in Troy during the Trojan War. She was a daughter of King Cisseus of Thrace and wife of Antenor, one of the Trojan elders.\nTheano or Theona, a character appearing in the Aeneid, the consort of Amycus."
    },
    "Library (computing)": {
        "url": "https://en.wikipedia.org/wiki/Library_(computing)",
        "summary": "In computer science, a library is a collection of non-volatile resources used by computer programs, often for software development. These may include configuration data, documentation, help data, message templates, pre-written code and subroutines, classes, values or type specifications. In IBM's OS/360 and its successors they are referred to as partitioned data sets.A library is also a collection of implementations of behavior, written in terms of a language, that has a well-defined interface by which the behavior is invoked. For instance, people who want to write a higher-level program can use a library to make system calls instead of implementing those system calls over and over again. In addition, the behavior is provided for reuse by multiple independent programs. A program invokes the library-provided behavior via a mechanism of the language. For example, in a simple imperative language such as C, the behavior in a library is invoked by using C's normal function-call. What distinguishes the call as being to a library function, versus being to another function in the same program, is the way that the code is organized in the system.Library code is organized in such a way that it can be used by multiple programs that have no connection to each other, while code that is part of a program is organized to be used only within that one program. This distinction can gain a hierarchical notion when a program grows large, such as a multi-million-line program. In that case, there may be internal libraries that are reused by independent sub-portions of the large program. The distinguishing feature is that a library is organized for the purposes of being reused by independent programs or sub-programs, and the user only needs to know the interface and not the internal details of the library.\nThe value of a library lies in the reuse of standardized program elements. When a program invokes a library, it gains the behavior implemented inside that library without having to implement that behavior itself. Libraries encourage the sharing of code in a modular fashion and ease the distribution of the code.\nThe behavior implemented by a library can be connected to the invoking program at different program lifecycle phases. If the code of the library is accessed during the build of the invoking program, then the library is called a static library. An alternative is to build the executable of the invoking program and distribute that, independently of the library implementation. The library behavior is connected after the executable has been invoked to be executed, either as part of the process of starting the execution, or in the middle of execution. In this case the library is called a dynamic library (loaded at runtime). A dynamic library can be loaded and linked when preparing a program for execution, by the linker. Alternatively, in the middle of execution, an application may explicitly request that a module be loaded.\nMost compiled languages have a standard library, although programmers can also create their own custom libraries. Most modern software systems provide libraries that implement the majority of the system services. Such libraries have organized the services which a modern application requires. As such, most code used by modern applications is provided in these system libraries.\n\n"
    },
    "TensorFlow": {
        "url": "https://en.wikipedia.org/wiki/TensorFlow",
        "summary": "TensorFlow is a free and open-source software library for machine learning and artificial intelligence. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks.TensorFlow was developed by the Google Brain team for internal Google use in research and production. The initial version was released under the Apache License 2.0 in 2015. Google released the updated version of TensorFlow, named TensorFlow 2.0, in September 2019.TensorFlow can be used in a wide variety of programming languages, including Python, JavaScript, C++, and Java. This flexibility lends itself to a range of applications in many different sectors.\n\n"
    },
    "Torch": {
        "url": "https://en.wikipedia.org/wiki/Torch",
        "summary": "A torch is a stick with combustible material at one end which can be used as a light source or to set something on fire. Torches have been used throughout history, and are still used in processions, symbolic and religious events, and in juggling entertainment. In some countries, notably the United Kingdom and Australia, \"torch\" in modern usage is the term for a battery-operated portable light."
    },
    "Computation": {
        "url": "https://en.wikipedia.org/wiki/Computation",
        "summary": "A computation is any type of arithmetic or non-arithmetic calculation that is well-defined. Common examples of computations are mathematical equations and computer algorithms.\nMechanical or electronic devices (or, historically, people) that perform computations are known as computers. The study of computation is the field of computability, itself a sub-field of computer science."
    },
    "Data processing": {
        "url": "https://en.wikipedia.org/wiki/Data_processing",
        "summary": "Data processing is the collection and manipulation of digital data to produce meaningful information.  \nData processing is a form of information processing, which is the modification (processing) of information in any manner detectable by an observer.The term \"Data Processing\", or \"DP\" has also been used to refer to a department within an organization responsible for the operation of data processing programs.\n\n"
    },
    "Computational biology": {
        "url": "https://en.wikipedia.org/wiki/Computational_biology",
        "summary": "Computational biology refers to the use of data analysis, mathematical modeling and computational simulations to understand biological systems and relationships. An intersection of computer science, biology, and big data, the field also has foundations in applied mathematics, chemistry, and genetics. It differs from biological computing, a subfield of computer science and engineering which uses bioengineering to build computers.\n\n"
    },
    "Computer science": {
        "url": "https://en.wikipedia.org/wiki/Computer_science",
        "summary": "Computer science is the study of computation, information, and automation. Computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). Though more often considered an academic discipline, computer science is closely related to computer programming.Algorithms and data structures are central to computer science.\nThe theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human\u2013computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.\nThe fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.\n\n"
    },
    "COVID-19 pandemic": {
        "url": "https://en.wikipedia.org/wiki/COVID-19_pandemic",
        "summary": "The COVID-19 pandemic, also known as the coronavirus pandemic, is a global pandemic of coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The novel virus was first identified in an outbreak in the Chinese city of Wuhan in December 2019. Attempts to contain it there failed, allowing the virus to spread to other areas of Asia and then worldwide in early 2020. The World Health Organization (WHO) declared the outbreak a public health emergency of international concern (PHEIC) on 30 January 2020. The WHO ended its PHEIC declaration on 5 May 2023. As of 5 December 2023, the pandemic has caused 772,051,988 cases and 6,985,265 confirmed deaths, ranking it fifth in the list of the deadliest epidemics and pandemics in history.\nCOVID-19 symptoms range from asymptomatic to deadly, but most commonly include fever, sore throat, nocturnal cough, and fatigue. Transmission of the virus is often through airborne particles. Mutations have produced many strains (variants) with varying degrees of infectivity and virulence.COVID-19 vaccines were widely deployed in various countries beginning in December 2020. Treatments include novel antiviral drugs and symptom control. Common mitigation measures during the public health emergency included travel restrictions, lockdowns, business restrictions and closures, workplace hazard controls, mask mandates, quarantines, testing systems, and contact tracing of the infected.\nThe pandemic caused severe social and economic disruption around the world, including the largest global recession since the Great Depression. Widespread supply shortages, including food shortages, were caused by supply chain disruptions and panic buying. Reduced human activity led to an unprecedented decrease in pollution. Educational institutions and public areas were partially or fully closed in many jurisdictions, and events were cancelled or postponed during 2020, 2021, and 2022. Many white-collar workers began working from home. Misinformation circulated through social media and mass media, and political tensions intensified. The pandemic raised issues of racial and geographic discrimination, health equity, and the balance between public health imperatives and individual rights."
    },
    "2020": {
        "url": "https://en.wikipedia.org/wiki/2020",
        "summary": "2020 (MMXX) was a leap year starting on Wednesday of the Gregorian calendar, the 2020th year of the Common Era (CE) and Anno Domini (AD) designations, the 20th  year of the 3rd millennium and the 21st century, and the  1st   year of the 2020s decade.  \n2020 was heavily defined by the COVID-19 pandemic, which led to global social and economic disruption, mass cancellations and postponements of events, worldwide lockdowns and the largest economic recession since the Great Depression in the 1930s. Geospatial World also called 2020 \"the worst year in terms of climate change\" in part due to major climate disasters worldwide, including major bushfires in Australia and the western United States, as well as extreme tropical cyclone activity affecting large parts of North America. A United Nations progress report published in December 2020 indicated that none of the international Sustainable Development Goals for 2020 were achieved. Time magazine used its sixth ever Red X cover to declare 2020 \"the worst year ever\", although the cover article itself did not go as far, instead saying \"There have been worse years in U.S. history, and certainly worse years in world history, but most of us alive today have seen nothing like this one.\" The Golden Raspberry Awards also awarded the year the Special Governor's Award for The Worst Calendar Year Ever! at their 41st ceremony."
    },
    "Application-specific integrated circuit": {
        "url": "https://en.wikipedia.org/wiki/Application-specific_integrated_circuit",
        "summary": "An application-specific integrated circuit (ASIC ) is an integrated circuit (IC) chip customized for a particular use, rather than intended for general-purpose use, such as a chip designed to run in a digital voice recorder or a high-efficiency video codec. Application-specific standard product chips are intermediate between ASICs and industry standard integrated circuits like the 7400 series or the 4000 series. ASIC chips are typically fabricated using metal\u2013oxide\u2013semiconductor (MOS) technology, as MOS integrated circuit chips.As feature sizes have shrunk and chip design tools improved over the years, the maximum complexity (and hence functionality) possible in an ASIC has grown from 5,000 logic gates to over 100 million. Modern ASICs often include entire microprocessors, memory blocks including ROM, RAM, EEPROM, flash memory and other large building blocks. Such an ASIC is often termed a SoC (system-on-chip). Designers of digital ASICs often use a hardware description language (HDL), such as Verilog or VHDL, to describe the functionality of ASICs.Field-programmable gate arrays (FPGA) are the modern-day technology improvement on breadboards, meaning that they are not made to be application-specific as opposed to ASICs. Programmable logic blocks and programmable interconnects allow the same FPGA to be used in many different applications. For smaller designs or lower production volumes, FPGAs may be more cost-effective than an ASIC design, even in production. The non-recurring engineering (NRE) cost of an ASIC can run into the millions of dollars. Therefore, device manufacturers typically prefer FPGAs for prototyping and devices with low production volume and ASICs for very large production volumes where NRE costs can be amortized across many devices."
    },
    "Central processing unit": {
        "url": "https://en.wikipedia.org/wiki/Central_processing_unit",
        "summary": "A central processing unit (CPU)\u2014also called a central processor or main processor\u2014is the most important processor in a given computer. Its electronic circuitry executes instructions of a computer program, such as arithmetic, logic, controlling, and input/output (I/O) operations. This role contrasts with that of external components, such as main memory and I/O circuitry, and specialized coprocessors such as graphics processing units (GPUs).\nThe form, design, and implementation of CPUs have changed over time, but their fundamental operation remains almost unchanged. Principal components of a CPU include the arithmetic\u2013logic unit (ALU) that performs arithmetic and logic operations, processor registers that supply operands to the ALU and store the results of ALU operations, and a control unit that orchestrates the fetching (from memory), decoding and execution (of instructions) by directing the coordinated operations of the ALU, registers, and other components.\nMost modern CPUs are implemented on integrated circuit (IC) microprocessors, with one or more CPUs on a single IC chip. Microprocessor chips with multiple CPUs are multi-core processors. The individual physical CPUs, processor cores, can also be multithreaded to support CPU-level multithreading. Most modern CPUs have privileged mode to support operating systems and hypervisor mode to support virtualization.\nAn IC that contains a CPU may also contain memory, peripheral interfaces, and other components of a computer; such integrated devices are variously called microcontrollers or systems on a chip (SoC)."
    },
    "Computer vision": {
        "url": "https://en.wikipedia.org/wiki/Computer_vision",
        "summary": "Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions. Understanding in this context means the transformation of visual images (the input to the retina in the human analog) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.\nThe scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner, 3D point clouds from LiDaR sensors, or medical scanning devices. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.\nSub-domains of computer vision include scene reconstruction, object detection, event detection, activity recognition, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration. \nAdopting computer vision technology might be painstaking for organizations as there is no single point solution for it. There are very few companies that provide a unified and distributed platform or an Operating System where computer vision applications can be easily deployed and managed."
    },
    "Artificial intelligence": {
        "url": "https://en.wikipedia.org/wiki/Artificial_intelligence",
        "summary": "Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is a field of study in computer science which develops and studies intelligent machines. It may also refer to the intelligent machines themselves.\nAI technology is widely used throughout industry, government and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Google Assistant, Siri, and Alexa), self-driving cars (e.g., Waymo), generative and creative tools (ChatGPT and AI art), and superhuman play and analysis in strategy games (such as chess and Go).Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by disappointment and loss of funding, but after 2012, when deep learning surpassed all previous AI techniques, there was a vast increase in funding and interest.\nThe various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence (the ability to complete any task performable by a human) is among the field's long-term goals.\nTo solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience and many other fields."
    },
    "Dialect": {
        "url": "https://en.wikipedia.org/wiki/Dialect",
        "summary": "Dialect (from Latin dialectus, dialectos, from the Ancient Greek word \u03b4\u03b9\u03ac\u03bb\u03b5\u03ba\u03c4\u03bf\u03c2, di\u00e1lektos 'discourse', from \u03b4\u03b9\u03ac, di\u00e1 'through' and \u03bb\u03ad\u03b3\u03c9, l\u00e9g\u014d 'I speak') refers to two distinctly different types of linguistic relationships. \nThe more common usage of the term refers to a variety of a language that is a characteristic of a particular group of the language's speakers. The dialects or varieties of a particular language are closely related and, despite their differences, are most often largely mutually intelligible, especially if geographically close to one another in a dialect continuum. The term is applied most often to regional speech patterns, but a dialect may also be defined by other factors, such as social class or ethnicity. A dialect that is associated with a particular social class can be termed a sociolect, a dialect that is associated with a particular ethnic group can be termed an ethnolect, and a geographical/regional dialect may be termed a regiolect (alternative terms include 'regionalect', 'geolect', and 'topolect'). Any variety of a given language can be classified as a \"dialect\", including any standardized varieties.\nThe other usage, which is specific to colloquial settings in a few countries like Italy, such as dialetto, patois in France, much of East Central Europe, and the Philippines, carries a pejorative undertone and underlines the politically and socially subordinated status of a non-national language to the country's single official language. In this case, these \"dialects\" are not actual dialects in the same sense as in the first usage, as they do not derive from one dominant language and are therefore not one of its varieties since they evolved in a separate and parallel way. While they may be historically cognate with and share genetic roots in the same subfamily as the dominant national language and may even, to a varying degree, share some mutual intelligibility with the latter, \"dialects\" under this second definition may be better defined as separate languages from the standard or national language. Under this definition, the standard or national language would not itself be considered a dialect, as it is the dominant language in terms of linguistic prestige, social or political (e.g. official) status, predominance or prevalence, or all of the above. Dialect used this way implies a political connotation, being mostly used to refer to \"low-prestige\" languages (regardless of their actual degree of distance from the national language), languages lacking institutional support, or those perceived as \"unsuitable for writing\". The designation dialect is also used popularly to refer to the unwritten or non-codified languages of developing countries or isolated areas, where the term \"vernacular language\" would be preferred by linguists.Features that distinguish dialects from each other can be found in lexicon (vocabulary) and grammar, as well as in pronunciation (phonology, including prosody). In instances where the salient distinctions are only or mostly to be observed in pronunciation, the more specific term accent may be used instead of dialect.  Differences that are largely concentrated in lexicon may be classified as creoles. When lexical differences are mostly concentrated in the specialized vocabulary of a profession or other organization, they are jargons. Differences in vocabulary that are deliberately cultivated to exclude outsiders or to serve as shibboleths are known as cryptolects or cant, and include slangs and argots. The particular speech patterns used by an individual are referred to as that person's idiolect. \nLanguages are classified as dialects based on linguistic distance. The dialects of a language with a writing system will operate at different degrees of distance from the standardized written form. Some dialects of a language are not mutually intelligible in spoken form, leading to debate as to whether they are regiolects or separate languages."
    },
    "Language": {
        "url": "https://en.wikipedia.org/wiki/Language",
        "summary": "Language is a structured system of communication that consists of grammar and vocabulary. It is the primary means by which humans convey meaning, both in spoken and written forms, and may also be conveyed through sign languages. The vast majority of human languages have developed writing systems that allow for the recording and preservation of the sounds or signs of language. Human language is characterized by its cultural and historical diversity, with significant variations observed between cultures and across time. Human languages possess the properties of productivity and displacement, which enable the creation of an infinite number of sentences, and the ability to refer to objects, events, and ideas that are not immediately present in the discourse. The use of human language relies on social convention and is acquired through learning.\nEstimates of the number of human languages in the world vary between 5,000 and 7,000. Precise estimates depend on an arbitrary distinction (dichotomy) established between languages and dialects. Natural languages are spoken, signed, or both; however, any language can be encoded into secondary media using auditory, visual, or tactile stimuli \u2013 for example, writing, whistling, signing, or braille. In other words, human language is modality-independent, but written or signed language is the way to inscribe or encode the natural human speech or gestures.\nDepending on philosophical perspectives regarding the definition of language and meaning, when used as a general concept, \"language\" may refer to the cognitive ability to learn and use systems of complex communication, or to describe the set of rules that makes up these systems, or the set of utterances that can be produced from those rules. All languages rely on the process of semiosis to relate signs to particular meanings. Oral, manual and tactile languages contain a phonological system that governs how symbols are used to form sequences known as words or morphemes, and a syntactic system that governs how words and morphemes are combined to form phrases and utterances.\nThe scientific study of language is called linguistics. Critical examinations of languages, such as philosophy of language, the relationships between language and thought, how words represent experience, etc., have been debated at least since Gorgias and Plato in ancient Greek civilization. Thinkers such as Jean-Jacques Rousseau (1712\u20131778) have argued that language originated from emotions, while others like Immanuel Kant (1724\u20131804) have argued that languages originated from rational and logical thought. Twentieth century philosophers such as Ludwig Wittgenstein (1889\u20131951) argued that philosophy is really the study of language itself. Major figures in contemporary linguistics of these times include Ferdinand de Saussure and Noam Chomsky.\nLanguage is thought to have gradually diverged from earlier primate communication systems when early hominins acquired the ability to form a theory of mind and shared intentionality. This development is sometimes thought to have coincided with an increase in brain volume, and many linguists see the structures of language as having evolved to serve specific communicative and social functions. Language is processed in many different locations in the human brain, but especially in Broca's and Wernicke's areas. Humans acquire language through social interaction in early childhood, and children generally speak fluently by approximately three years old. Language and culture are codependent. Therefore, in addition to its strictly communicative uses, language has social uses such as signifying group identity, social stratification, as well as use for social grooming and entertainment.\nLanguages evolve and diversify over time, and the history of their evolution can be reconstructed by comparing modern languages to determine which traits their ancestral languages must have had in order for the later developmental stages to occur. A group of languages that descend from a common ancestor is known as a language family; in contrast, a language that has been demonstrated to not have any living or non-living relationship with another language is called a language isolate. There are also many unclassified languages whose relationships have not been established, and spurious languages may have not existed at all. Academic consensus holds that between 50% and 90% of languages spoken at the beginning of the 21st century will probably have become extinct by the year 2100."
    },
    "Deep learning": {
        "url": "https://en.wikipedia.org/wiki/Deep_learning",
        "summary": "Deep learning is the subset of machine learning methods which are based on artificial neural networks with representation learning. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog."
    },
    "Neural network": {
        "url": "https://en.wikipedia.org/wiki/Neural_network",
        "summary": "A neural network is a neural circuit of biological neurons, sometimes also called a biological neural network, or a network of artificial neurons or nodes in the case of an artificial neural network.Artificial neural networks are used for solving artificial intelligence (AI) problems; they model connections of biological neurons as weights between nodes. A positive weight reflects an excitatory connection, while negative values mean inhibitory connections. All inputs are modified by a weight and summed. This activity is referred to as a linear combination. Finally, an activation function controls the amplitude of the output. For example, an acceptable range of output is usually between 0 and 1, or it could be \u22121 and 1.\nThese artificial networks may be used for predictive modeling, adaptive control and applications where they can be trained via a dataset. Self-learning resulting from experience can occur within networks, which can derive conclusions from a complex and seemingly unrelated set of information."
    },
    "Natural language processing": {
        "url": "https://en.wikipedia.org/wiki/Natural_language_processing",
        "summary": "Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\nChallenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation."
    },
    "Natural language": {
        "url": "https://en.wikipedia.org/wiki/Natural_language",
        "summary": "In neuropsychology, linguistics, and philosophy of language, a natural language or ordinary language is any language that occurs naturally in a human community by a process of use, repetition, and change without conscious planning or premeditation. It can take different forms, namely either a spoken language or a sign language. Natural languages are distinguished from constructed and formal languages such as those used to program computers or to study logic."
    },
    "Parsing": {
        "url": "https://en.wikipedia.org/wiki/Parsing",
        "summary": "Parsing, syntax analysis, or syntactic analysis is the process of analyzing a string of symbols, either in natural language, computer languages or data structures, conforming to the rules of a formal grammar.  The term parsing comes from Latin pars (orationis), meaning part (of speech).The term has slightly different meanings in different branches of linguistics and computer science. Traditional sentence parsing is often performed as a method of understanding the exact meaning of a sentence or word, sometimes with the aid of devices such as sentence diagrams. It usually emphasizes the importance of grammatical divisions such as subject and predicate.\nWithin computational linguistics the term is used to refer to the formal analysis by a computer of a sentence or other string of words into its constituents, resulting in a parse tree showing their syntactic relation to each other, which may also contain semantic information. Some parsing algorithms may generate a parse forest or list of parse trees for a syntactically ambiguous input.The term is also used in psycholinguistics when describing language comprehension. In this context, parsing refers to the way that human beings analyze a sentence or phrase (in spoken language or text) \"in terms of grammatical constituents, identifying the parts of speech, syntactic relations, etc.\" This term is especially common when discussing which linguistic cues help speakers interpret garden-path sentences.\nWithin computer science, the term is used in the analysis of computer languages, referring to the syntactic analysis of the input code into its component parts in order to facilitate the writing of compilers and interpreters. The term may also be used to describe a split or separation."
    },
    "Dialectic": {
        "url": "https://en.wikipedia.org/wiki/Dialectic",
        "summary": "Dialectic (Greek: \u03b4\u03b9\u03b1\u03bb\u03b5\u03ba\u03c4\u03b9\u03ba\u03ae, dialektik\u1e17; German: Dialektik), also known as the dialectical method, refers originally to dialogue between people holding different points of view about a subject but wishing to arrive at the truth through reasoned argumentation. Dialectic resembles debate, but the concept excludes subjective elements such as emotional appeal and rhetoric. It has its origins in ancient philosophy and continued to be developed in the Middle Ages.\nIn the modern period, Hegelianism refigured \"dialectic\" to no longer refer to a literal dialogue. Instead, the term takes on the specialized meaning of development by way of overcoming internal contradictions. Dialectical materialism, a theory advanced by Karl Marx and Friedrich Engels, adapted the Hegelian dialectic into a materialist theory of history. The legacy of Hegelian and Marxian dialectics has been criticized by philosophers such as Karl Popper and Mario Bunge, who considered it unscientific.\nDialectic implies a developmental process and so does not naturally fit within classical logic. Nevertheless, some twentieth-century logicians have attempted to formalize it."
    },
    "Linguistics": {
        "url": "https://en.wikipedia.org/wiki/Linguistics",
        "summary": "Linguistics is the scientific study of language.Linguistics is based on theoretical as well as descriptive study of language and is also interlinked with the applied fields of language studies and language learning, which entails the study of specific languages. Before the 20th century, linguistics evolved in conjunction with literary study and did not exclusively employ scientific methods.Traditional areas of linguistic analysis correspond to syntax (rules governing the structure of sentences), semantics (meaning), morphology (structure of words), phonetics (speech sounds and equivalent gestures in sign languages), phonology (the abstract sound system of a particular language), and pragmatics (how social context contributes to meaning). Subdisciplines such as biolinguistics (the study of the biological variables and evolution of language) and psycholinguistics (the study of psychological factors in human language) bridge many of these divisions.Linguistics encompasses many branches and subfields that span both theoretical and practical applications. Theoretical linguistics (including traditional descriptive linguistics) is concerned with understanding the universal and fundamental nature of language and developing a general theoretical framework for describing it. Applied linguistics seeks to utilise the scientific findings of the study of language for practical purposes, such as developing methods of improving language education and literacy.Linguistic features may be studied through a variety of perspectives: synchronically (by describing the shifts in a language at a certain specific point of time) or diachronically (through the historical development of language over several periods of time), in monolinguals or in multilinguals, amongst children or amongst adults, in terms of how it is being learned or how it was acquired, as abstract objects or as cognitive structures, through written texts or through oral elicitation, and finally through mechanical data collection or through practical fieldwork.Linguistics emerged from the field of philology,  of which some branches are more qualitative and holistic in approach. Today, philology and linguistics are now variably described as related fields, subdisciplines, or separate fields of language study but, by and large, linguistics can be seen as an umbrella term. Linguistics is also related to the philosophy of language, stylistics, rhetoric, semiotics, lexicography, and translation."
    },
    "Language model": {
        "url": "https://en.wikipedia.org/wiki/Language_model",
        "summary": "A language model is a probabilistic model of a natural language that can generate probabilities of a series of words, based on text corpora in one or multiple languages it was trained on. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed \u2018Shannon-style\u2019 experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.Language models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, handwriting recognition, grammar induction, and information retrieval.Large language models, currently their most advanced form, are a combination of larger datasets (frequently using scraped words from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model."
    },
    "N-gram": {
        "url": "https://en.wikipedia.org/wiki/N-gram",
        "summary": "n-gram is a series of n adjacent letters (including punctuation marks and blanks), syllables, or rarely whole words found in a language dataset; or adjacent phonemes extracted from a speech-recording dataset, or adjacent base pairs extracted from a genome. They are collected from a text or speech corpus.  If Latin numerical prefixes are used, then n-gram of size 1 is called a \"unigram\", size 2 a \"bigram\" (or, less commonly, a \"digram\") etc. If, instead of the Latin ones, the English cardinal numbers are furtherly used, then they are called \"four-gram\", \"five-gram\", etc. Similarly, using Greek numerical prefixes such as \"monomer\", \"dimer\", \"trimer\", \"tetramer\", \"pentamer\", etc., or English cardinal numbers, \"one-mer\", \"two-mer\", \"three-mer\", etc. are used in computational biology, for polymers or oligomers of a known size, called k-mers. When the items are words, n-grams may also be called shingles."
    },
    "Phylogenetic tree": {
        "url": "https://en.wikipedia.org/wiki/Phylogenetic_tree",
        "summary": "A phylogenetic tree, phylogeny or evolutionary tree is a graphical representation which shows the evolutionary history between a set of species or taxa during a specific time. In other words, it is a branching diagram or a tree showing the evolutionary relationships among various biological species or other entities based upon similarities and differences in their physical or genetic characteristics. In evolutionary biology, all life on Earth is theoretically part of a single phylogenetic tree, indicating common ancestry. Phylogenetics is the study of phylogenetic trees. The main challenge is to find a phylogenetic tree representing optimal evolutionary ancestry between a set of species or taxa. Computational phylogenetics (also phylogeny inference) focuses on the algorithms involved in finding optimal phylogenetic tree in the phylogenetic landscape.Phylogenetic trees may be rooted or unrooted. In a rooted phylogenetic tree, each node with descendants represents the inferred most recent common ancestor of those descendants, and the edge lengths in some trees may be interpreted as time estimates. Each node is called a taxonomic unit. Internal nodes are generally called hypothetical taxonomic units, as they cannot be directly observed. Trees are useful in fields of biology such as bioinformatics, systematics, and phylogenetics. Unrooted trees illustrate only the relatedness of the leaf nodes and do not require the ancestral root to be known or inferred.\n\n"
    },
    "Tree": {
        "url": "https://en.wikipedia.org/wiki/Tree",
        "summary": "In botany, a tree is a perennial plant with an elongated stem, or trunk, usually supporting branches and leaves. In some usages, the definition of a tree may be narrower, including only woody plants with secondary growth, plants that are usable as lumber or plants above a specified height. In wider definitions, the taller palms, tree ferns, bananas, and bamboos are also trees. \nTrees are not a monophyletic taxonomic group but consist of a wide variety of plant species that have independently evolved a trunk and branches as a way to tower above other plants to compete for sunlight. The majority of tree species are angiosperms or hardwoods; of the rest, many are gymnosperms or softwoods. Trees tend to be long-lived, some reaching several thousand years old. Trees have been in existence for 370 million years. It is estimated that there are around three trillion mature trees in the world.\nA tree typically has many secondary branches supported clear of the ground by the trunk. This trunk typically contains woody tissue for strength, and vascular tissue to carry materials from one part of the tree to another. For most trees it is surrounded by a layer of bark which serves as a protective barrier. Below the ground, the roots branch and spread out widely; they serve to anchor the tree and extract moisture and nutrients from the soil. Above ground, the branches divide into smaller branches and shoots. The shoots typically bear leaves, which capture light energy and convert it into sugars by photosynthesis, providing the food for the tree's growth and development.\nTrees usually reproduce using seeds. Flowers and fruit may be present, but some trees, such as conifers, instead have pollen cones and seed cones. Palms, bananas, and bamboos also produce seeds, but tree ferns produce spores instead.\nTrees play a significant role in reducing erosion and moderating the climate. They remove carbon dioxide from the atmosphere and store large quantities of carbon in their tissues. Trees and forests provide a habitat for many species of animals and plants. Tropical rainforests are among the most biodiverse habitats in the world. Trees provide shade and shelter, timber for construction, fuel for cooking and heating, and fruit for food as well as having many other uses. In much of the world, forests are shrinking as trees are cleared to increase the amount of land available for agriculture. Because of their longevity and usefulness, trees have always been revered, with sacred groves in various cultures, and they play a role in many of the world's mythologies."
    },
    "Phylogenetics": {
        "url": "https://en.wikipedia.org/wiki/Phylogenetics",
        "summary": "In biology, phylogenetics () is the study of the evolutionary history and relationships among or within groups of organisms. These relationships are determined by phylogenetic inference methods that focus on observed heritable traits, such as DNA sequences, protein amino acid sequences, or morphology. The result of such an analysis is a phylogenetic tree\u2014a diagram containing a hypothesis of relationships that reflects the evolutionary history of a group of organisms.The tips of a phylogenetic tree can be living taxa or fossils, and represent the \"end\" or the present time in an evolutionary lineage. A phylogenetic diagram can be rooted or unrooted. A rooted tree diagram indicates the hypothetical common ancestor of the tree. An unrooted tree diagram (a network) makes no assumption about the ancestral line, and does not show the origin or \"root\" of the taxa in question or the direction of inferred evolutionary transformations.In addition to their use for inferring phylogenetic patterns among taxa, phylogenetic analyses are often employed to represent relationships among genes or individual organisms. Such uses have become central to understanding biodiversity, evolution, ecology, and genomes.\nPhylogenetics is component of systematics that uses similarities and differences of the characteristics of species to interpret their evolutionary relationships and origins. Phylogenetics focuses on whether the characteristics of a species reinforce a phylogenetic inference that it diverged from the most recent common ancestor of a taxonomic group.In the field of cancer research, phylogenetics can be used to study the clonal evolution of tumors and molecular chronology, predicting and showing how cell populations vary throughout the progression of the disease and during treatment, using whole genome sequencing techniques. The evolutionary processes behind cancer progression are quite different from those in species and are important to phylogenetic inference; these differences manifest in at least four areas: the types of aberrations that occur, the rates of mutation, the intensity, and high heterogeneity - variability - of tumor cell subclones.Phylogenetics can also aid in drug design and discovery. Phylogenetics allows scientists to organize species and can show which species are likely to have inherited particular traits that are medically useful, such as producing biologically active compounds - those that have effects on the human body. For example, in drug discovery, venom-producing animals are particularly useful. Venoms from these animals produce several important drugs, e.g., ACE inhibitors and Prialt (Ziconotide). To find new venoms, scientists turn to phylogenetics to screen for closely related species that may have the same useful traits. The phylogenetic tree shows which species of fish have an origin of venom, and related fish they may contain the trait. Using this approach in studying venomous fish, biologists are able to identify the fish species that may be venomous. Biologist have used this approach in many species such as snakes and lizards.\nIn forensic science, phylogenetic tools are useful to assess DNA evidence for court cases. The simple phylogenetic tree of viruses A-E shows the relationships between viruses e.g., all viruses are descendants of Virus A.\nHIV forensics uses phylogenetic analysis to track the differences in HIV genes and determine the relatedness of two samples. Phylogenetic analysis has been used in criminal trials to exonerate or hold individuals. HIV forensics does have its limitations, i.e., it cannot be the sole proof of transmission between individuals and phylogenetic analysis which shows transmission relatedness does not indicate direction of transmission.\n\n"
    },
    "Branch": {
        "url": "https://en.wikipedia.org/wiki/Branch",
        "summary": "A branch, sometimes called a ramus in botany, is a stem that grows off from another stem, or when structures like veins in leaves are divided into smaller veins."
    },
    "Loss function": {
        "url": "https://en.wikipedia.org/wiki/Loss_function",
        "summary": "In mathematical optimization and decision theory, a loss function or cost function (sometimes also called an error function)  is a function that maps an event or values of one or more variables onto a real number intuitively representing some \"cost\" associated with the event. An optimization problem seeks to minimize a loss function. An objective function is either a loss function or its opposite (in specific domains, variously called a reward function, a profit function, a utility function, a fitness function, etc.), in which case it is to be maximized. The loss function could include terms from several levels of the hierarchy.\nIn statistics, typically a  loss function is used for parameter estimation, and the event in question is some function of the difference between estimated and true values for an instance of data. The concept, as old as Laplace, was reintroduced in statistics by Abraham Wald in the middle of the 20th century.  In the context of economics, for example, this is usually economic cost or regret.  In classification, it is the penalty for an incorrect classification of an example. In actuarial science, it is used in an insurance context to model benefits paid over premiums, particularly since the works of Harald Cram\u00e9r in the 1920s. In optimal control, the loss is the penalty for failing to achieve a desired value. In financial risk management, the function is mapped to a monetary loss."
    },
    "Algorithm": {
        "url": "https://en.wikipedia.org/wiki/Algorithm",
        "summary": "In mathematics and computer science, an algorithm ( ) is a finite sequence of rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning), achieving automation eventually. Using human characteristics as descriptors of machines in metaphorical ways was already practiced by Alan Turing with terms such as \"memory\", \"search\" and \"stimulus\".In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.\n\n"
    },
    "Word n-gram language model": {
        "url": "https://en.wikipedia.org/wiki/Word_n-gram_language_model",
        "summary": "A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network-based models, which has been superseded by large language models.  It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n-1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \n  \n    \n      \n        \u27e8\n        s\n        \u27e9\n      \n    \n    {\\displaystyle \\langle s\\rangle }\n   and \n  \n    \n      \n        \u27e8\n        \n          /\n        \n        s\n        \u27e9\n      \n    \n    {\\displaystyle \\langle /s\\rangle }\n  .\nTo prevent a zero probability being assigned to unseen words, each word's probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good\u2013Turing discounting or back-off models.\n\n"
    },
    "Neural machine translation": {
        "url": "https://en.wikipedia.org/wiki/Neural_machine_translation",
        "summary": "Neural machine translation (NMT) is an approach to machine translation that uses an artificial neural network to predict the likelihood of a sequence of words, typically modeling and then translating entire sentences in a single integrated model."
    },
    "Machine translation": {
        "url": "https://en.wikipedia.org/wiki/Machine_translation",
        "summary": "Machine translation is use of  either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches to translation of text or speech from one language to another, including the contextual, idiomatic and pragmatic nuances of both languages."
    },
    "Convolution": {
        "url": "https://en.wikipedia.org/wiki/Convolution",
        "summary": "In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (f and g) that produces a third function (\n  \n    \n      \n        f\n        \u2217\n        g\n      \n    \n    {\\displaystyle f*g}\n  ) that expresses how the shape of one is modified by the other. The term convolution refers to both the result function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reflected about the y-axis and shifted. The choice of which function is reflected and shifted before the integral does not change the integral result (see commutativity). The integral is evaluated for all values of shift, producing the convolution function.\nSome features of convolution are similar to cross-correlation: for real-valued functions, of a continuous or discrete variable, convolution (\n  \n    \n      \n        f\n        \u2217\n        g\n      \n    \n    {\\displaystyle f*g}\n  ) differs from cross-correlation (\n  \n    \n      \n        f\n        \u22c6\n        g\n      \n    \n    {\\displaystyle f\\star g}\n  ) only in that either f(x) or g(x) is reflected about the y-axis in convolution; thus it is a cross-correlation of g(\u2212x) and f(x), or f(\u2212x) and g(x). For complex-valued functions, the cross-correlation operator is the adjoint of the convolution operator.\nConvolution has applications that include probability, statistics, acoustics, spectroscopy, signal processing and image processing, geophysics, engineering, physics, computer vision and differential equations.The convolution can be defined for functions on Euclidean space and other groups (as algebraic structures). For example, periodic functions, such as the discrete-time Fourier transform, can be defined on a circle and convolved by periodic convolution. (See row 18 at DTFT \u00a7 Properties.) A discrete convolution can be defined for functions on the set of integers.\nGeneralizations of convolution have applications in the field of numerical analysis and numerical linear algebra, and in the design and implementation of finite impulse response filters in signal processing.Computing the inverse of the convolution operation is known as deconvolution."
    },
    "Ancestor": {
        "url": "https://en.wikipedia.org/wiki/Ancestor",
        "summary": "An ancestor, also known as a forefather, fore-elder, or a forebear, is a parent or (recursively) the parent of an antecedent (i.e., a grandparent, great-grandparent, great-great-grandparent and so forth). Ancestor is \"any person from whom one is descended. In law, the person from whom an estate has been inherited.\"\n\n"
    },
    "Family": {
        "url": "https://en.wikipedia.org/wiki/Family",
        "summary": "Family (from Latin: familia) is a group of people related either by consanguinity (by recognized birth) or affinity (by marriage or other relationship). It forms the basis for social order. The purpose of the family is to maintain the well-being of its members and of society. Ideally, families offer predictability, structure, and safety as members mature and learn to participate in the community. Historically, most human societies use family as the primary locus of attachment, nurturance, and socialization.Anthropologists classify most family organizations as matrifocal (a mother and her children), patrifocal (a father and his children), conjugal (a married couple with children, also called the nuclear family), avuncular (a man, his sister, and her children), or extended (in addition to parents and children, may include grandparents, aunts, uncles, or cousins).\nThe field of genealogy aims to trace family lineages through history. The family is also an important economic unit studied in family economics. The word \"families\" can be used metaphorically to create more inclusive categories such as community, nationhood, and global village.\n\n"
    },
    "T-distributed stochastic neighbor embedding": {
        "url": "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding",
        "summary": "t-distributed stochastic neighbor embedding (t-SNE) is a statistical method for visualizing high-dimensional data by giving each datapoint a location in a two or three-dimensional map. It is based on Stochastic Neighbor Embedding originally developed by Geoffrey Hinton and Sam Roweis, where Laurens van der Maaten proposed the t-distributed variant. It is a nonlinear dimensionality reduction technique for embedding high-dimensional data for visualization in a low-dimensional space of two or three dimensions. Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points with high probability.\nThe t-SNE algorithm comprises two main stages. First, t-SNE constructs a probability distribution over pairs of high-dimensional objects in such a way that similar objects are assigned a higher probability while dissimilar points are assigned a lower probability. Second, t-SNE defines a similar probability distribution over the points in the low-dimensional map, and it minimizes the Kullback\u2013Leibler divergence (KL divergence) between the two distributions with respect to the locations of the points in the map. While the original algorithm uses the Euclidean distance between objects as the base of its similarity metric, this can be changed as appropriate. A Riemannian variant is UMAP.\nt-SNE has been used for visualization in a wide range of applications, including genomics, computer security research, natural language processing, music analysis, cancer research, bioinformatics, geological domain interpretation, and biomedical signal processing.While t-SNE plots often seem to display clusters, the visual clusters can be influenced strongly by the chosen parameterization and therefore a good understanding of the parameters for t-SNE is necessary. Such \"clusters\" can be shown to even appear in non-clustered data, and thus may be false findings. Interactive exploration may thus be necessary to choose parameters and validate results. It has been demonstrated that t-SNE is often able to recover well-separated clusters, and with special parameter choices, approximates a simple form of spectral clustering.For a data set with n elements, t-SNE runs in O(n2) time and requires O(n2) space."
    },
    "Teacher": {
        "url": "https://en.wikipedia.org/wiki/Teacher",
        "summary": "A teacher, also called a schoolteacher or formally an educator, is a person who helps students to acquire knowledge, competence, or virtue, via the practice of teaching.\nInformally the role of teacher may be taken on by anyone (e.g. when showing a colleague how to perform a specific task). \nIn some countries, teaching young people of school age may be carried out in an informal setting, such as within the family (homeschooling), rather than in a formal setting such as a school or college. \nSome other professions may involve a significant amount of teaching (e.g. youth worker, pastor).\nIn most countries, formal teaching of students is usually carried out by paid professional teachers. This article focuses on those who are employed, as their main role, to teach others in a formal education context, such as at a school or other place of initial formal education or training."
    },
    "Education": {
        "url": "https://en.wikipedia.org/wiki/Education",
        "summary": "Education is the transmission of knowledge, skills, and character traits. There are many types of education. Formal education happens in a complex institutional framework, like public schools. Non-formal education is also structured but takes place outside the formal schooling system. Informal education is unstructured learning through daily experiences. Formal and non-formal education are divided into levels. They include early childhood education, primary education, secondary education, and tertiary education. Other classifications focus on the teaching method, like teacher-centered and student-centered education. Forms of education can also be distinguished by subject, like science education, language education, and physical education. The term \"education\" can also refer to the mental states and qualities of educated people and the academic field studying educational phenomena.\nThe precise definition of education is disputed and there are disagreements about what the aims of education are and to what extent education is different from indoctrination by fostering critical thinking. These disagreements affect how to identify, measure, and improve forms of education. Fundamentally, education socializes children into society by teaching cultural values and norms. It equips them with the skills needed to become productive members of society. This way, it stimulates economic growth and raises awareness of local and global problems. Organized institutions affect many aspects of education. For example, governments set education policies to determine when school classes happen, what is taught, and who can or must attend. International organizations, like UNESCO, have been influential in promoting primary education for all children.\nMany factors influence whether education is successful. Psychological factors include  motivation, intelligence, and personality. Social factors, like socioeconomic status, ethnicity, and gender, are often linked to discrimination. Further factors include access to educational technology, teacher quality, and parent involvement.\nThe main field investigating education is called education studies. It examines what education is, what aims and effects it has, and how to improve it. Education studies has many subfields, like philosophy, psychology, sociology, and economics of education. It also discusses comparative education, pedagogy, and the history of education. In prehistory, education happened informally through oral communication and imitation. With the rise of ancient civilizations, writing was invented, and the amount of knowledge grew. This caused a shift from informal to formal education. Initially, formal education was mainly available to elites and religious groups. The invention of the printing press in the 15th century made books more widely available. This increased general literacy. Beginning in the 18th and 19th centuries, public education became more important. It led to the worldwide process of making primary education available to all, free of charge, and compulsory up to a certain age."
    },
    "School": {
        "url": "https://en.wikipedia.org/wiki/School",
        "summary": "A school is both the educational institution and building designed to provide learning spaces and learning environments for the teaching of students under the direction of teachers. Most countries have systems of formal education, which is sometimes compulsory. In these systems, students progress through a series of schools that can be built and operated by both government and private organization. The names for these schools vary by country (discussed in the Regional terms section below) but generally include primary school for young children and secondary school for teenagers who have completed primary education. An institution where higher education is taught is commonly called a university college or university.\nIn addition to these core schools, students in a given country may also attend schools before and after primary (elementary in the U.S.) and secondary (middle school in the U.S.) education. Kindergarten or preschool provide some schooling to very young children (typically ages 3\u20135). University, vocational school, college or seminary may be available after secondary school. A school may be dedicated to one particular field, such as a school of economics or dance. Alternative schools may provide nontraditional curriculum and methods.\nNon-government schools, also known as private schools, may be required when the government does not supply adequate or specific educational needs. Other private schools can also be religious, such as Christian schools, gurukula (Hindu schools), madrasa (Arabic schools), hawzas (Shi'i Muslim schools), yeshivas (Jewish schools), and others; or schools that have a higher standard of education or seek to foster other personal achievements. Schools for adults include institutions of corporate training, military education and training and business schools.\nCritics of school often accuse the school system of failing to adequately prepare students for their future lives, of encouraging certain temperaments while inhibiting others, of prescribing students exactly what to do, how, when, where and with whom, which would suppress creativity, and of using extrinsic measures such as grades and homework, which would inhibit children's natural curiosity and desire to learn.In homeschooling and distance education, teaching and learning take place independent from the institution of school or in a virtual school outside a traditional school building, respectively. Schools are organized in several different organizational models, including departmental, small learning communities, academies, integrated, and schools-within-a-school."
    },
    "Machine learning": {
        "url": "https://en.wikipedia.org/wiki/Machine_learning",
        "summary": "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions. Recently, generative artificial neural networks have been able to surpass many previous approaches in performance. Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods."
    },
    "Reinforcement learning": {
        "url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
        "summary": "Reinforcement learning (RL) is an interdisciplinary area of machine learning and optimal control concerned with how an intelligent agent ought to take actions in a dynamic environment in order to maximize the cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\nReinforcement learning differs from supervised learning in not needing labelled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).\nThe environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques. The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the Markov decision process and they target large Markov decision processes where exact methods become infeasible."
    },
    "Cyc": {
        "url": "https://en.wikipedia.org/wiki/Cyc",
        "summary": "Cyc (pronounced  SYKE) is a long-term artificial intelligence project that aims to assemble a comprehensive ontology and knowledge base that spans the basic concepts and rules about how the world works. Hoping to capture common sense knowledge, Cyc focuses on implicit knowledge that other AI platforms may take for granted. This is contrasted with facts one might find somewhere on the internet or retrieve via a search engine or Wikipedia. Cyc enables semantic reasoners to perform human-like reasoning and be less \"brittle\" when confronted with novel situations.\nDouglas Lenat began the project in July 1984 at MCC, where he was Principal Scientist 1984\u20131994, and then, since January 1995, has been under active development by the Cycorp company, where he was the CEO."
    },
    "Knowledge base": {
        "url": "https://en.wikipedia.org/wiki/Knowledge_base",
        "summary": "In computer science, a knowledge base (KB) is a set of sentences, each sentence given in a knowledge representation language, with interfaces to tell new sentences and to ask questions about what is known, where either of these interfaces might use inference. It is a technology used to store complex structured data used by a computer system. The initial use of the term was in connection with expert systems, which were the first knowledge-based systems. \n\n"
    },
    "WordNet": {
        "url": "https://en.wikipedia.org/wiki/WordNet",
        "summary": "WordNet is a lexical database of semantic relations between words that links words into semantic relations including synonyms, hyponyms, and meronyms. The synonyms are grouped into synsets with short definitions and usage examples. It can thus be seen as a combination and extension of a dictionary and thesaurus. While it is accessible to human users via a web browser, its primary use is in automatic text analysis and artificial intelligence applications. It was first created in the English language and the English WordNet database and software tools have been released under a BSD style license and are freely available for download from that WordNet website. There are now WordNets in more than 200 languages.\n\n"
    },
    "Learning": {
        "url": "https://en.wikipedia.org/wiki/Learning",
        "summary": "Learning is the process of acquiring new understanding, knowledge, behaviors, skills, values, attitudes, and preferences. The ability to learn is possessed by humans, animals, and some machines; there is also evidence for some kind of learning in certain plants. Some learning is immediate, induced by a single event (e.g. being burned by a hot stove), but much skill and knowledge accumulate from repeated experiences. The changes induced by learning often last a lifetime, and it is hard to distinguish learned material that seems to be \"lost\" from that which cannot be retrieved.Human learning starts at birth (it might even start before in terms of an embryo's need for both interaction with, and freedom within its environment within the womb.) and continues until death as a consequence of ongoing interactions between people and their environment. The nature and processes involved in learning are studied in many established fields (including educational psychology, neuropsychology, experimental psychology, cognitive sciences, and pedagogy), as well as emerging fields of knowledge (e.g. with a shared interest in the topic of learning from safety events such as incidents/accidents, or in collaborative learning health systems). Research in such fields has led to the identification of various sorts of learning. For example, learning may occur as a result of habituation, or classical conditioning, operant conditioning or as a result of more complex activities such as play, seen only in relatively intelligent animals. Learning may occur consciously or without conscious awareness. Learning that an aversive event cannot be avoided or escaped may result in a condition called learned helplessness. There is evidence for human behavioral learning prenatally, in which habituation has been observed as early as 32 weeks into gestation, indicating that the central nervous system is sufficiently developed and primed for learning and memory to occur very early on in development.Play has been approached by several theorists as a form of learning. Children experiment with the world, learn the rules, and learn to interact through play. Lev Vygotsky agrees that play is pivotal for children's development, since they make meaning of their environment through playing educational games. For Vygotsky, however, play is the first form of learning language and communication, and the stage where a child begins to understand rules and symbols. This has led to a view that learning in organisms is always related to semiosis, and is often associated with representational systems/activity."
    },
    "Unsupervised": {
        "url": "https://en.wikipedia.org/wiki/Unsupervised",
        "summary": "Unsupervised is an American adult animated sitcom created by David Hornsby, Rob Rosell, and Scott Marder which ran on FX from January 19 to December 20, 2012. The show was created, and for the most part, written by David Hornsby, Scott Marder, and Rob Rosell.On November 17, 2012, the series was canceled after one season."
    },
    "Supervised learning": {
        "url": "https://en.wikipedia.org/wiki/Supervised_learning",
        "summary": "Supervised learning (SL) is a paradigm in machine learning where input objects (for example, a vector of predictor variables) and a desired output value (also known as human-labeled supervisory signal) train a model. The training data is processed, building a function that maps new data on expected output values.  An optimal scenario will allow for the algorithm to correctly determine output values for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way (see inductive bias). This statistical quality of an algorithm is measured through the so-called generalization error.\n\n"
    },
    "Gradient": {
        "url": "https://en.wikipedia.org/wiki/Gradient",
        "summary": "In vector calculus, the gradient of a scalar-valued differentiable function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   of several variables is the vector field (or vector-valued function) \n  \n    \n      \n        \u2207\n        f\n      \n    \n    {\\displaystyle \\nabla f}\n   whose value at a point \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   gives the direction and the rate of fastest increase. The gradient transforms like a vector under change of basis of the space of variables of \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  . If the gradient of a function is non-zero at a point \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  , the direction of the gradient is the direction in which the function increases most quickly from \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  , and the magnitude of the gradient is the rate of increase in that direction, the greatest absolute directional derivative. Further, a point where the gradient is the zero vector is known as a stationary point. The gradient thus plays a fundamental role in optimization theory, where it is used to maximize a function by gradient ascent. In coordinate-free terms, the gradient of a function \n  \n    \n      \n        f\n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle f(\\mathbf {r} )}\n   may be defined by:\n\nwhere \n  \n    \n      \n        d\n        f\n      \n    \n    {\\displaystyle df}\n   is the total infinitesimal change in \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   for an infinitesimal displacement  \n  \n    \n      \n        d\n        \n          r\n        \n      \n    \n    {\\displaystyle d\\mathbf {r} }\n  , and is seen to be maximal when \n  \n    \n      \n        d\n        \n          r\n        \n      \n    \n    {\\displaystyle d\\mathbf {r} }\n   is in the direction of the gradient \n  \n    \n      \n        \u2207\n        f\n      \n    \n    {\\displaystyle \\nabla f}\n  . The nabla symbol \n  \n    \n      \n        \u2207\n      \n    \n    {\\displaystyle \\nabla }\n  , written as an upside-down triangle and pronounced \"del\", denotes the vector differential operator.\nWhen a coordinate system is used in which the basis vectors are not functions of position, the gradient is given by the vector whose components are the partial derivatives of \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   at \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  . That is, for \n  \n    \n      \n        f\n        :\n        \n          \n            R\n          \n          \n            n\n          \n        \n        \u2192\n        \n          R\n        \n      \n    \n    {\\displaystyle f\\colon \\mathbb {R} ^{n}\\to \\mathbb {R} }\n  , its gradient \n  \n    \n      \n        \u2207\n        f\n        :\n        \n          \n            R\n          \n          \n            n\n          \n        \n        \u2192\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\nabla f\\colon \\mathbb {R} ^{n}\\to \\mathbb {R} ^{n}}\n   is defined at the point \n  \n    \n      \n        p\n        =\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle p=(x_{1},\\ldots ,x_{n})}\n   in n-dimensional space as the vector\nNote that the above definition for gradient is only defined for the function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  , if it is differentiable at \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  . There can be functions for which partial derivatives exist in every direction but still fail to be differentiable. For example, the function \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        )\n        =\n        \n          \n            \n              \n                x\n                \n                  2\n                \n              \n              y\n            \n            \n              \n                x\n                \n                  2\n                \n              \n              +\n              \n                y\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle f(x,y)={\\frac {x^{2}y}{x^{2}+y^{2}}}}\n   unless at origin where \n  \n    \n      \n        f\n        (\n        0\n        ,\n        0\n        )\n        =\n        0\n      \n    \n    {\\displaystyle f(0,0)=0}\n  , is not differentiable at origin as it does not have a well defined tangent plane despite having well defined partial derivatives in every direction at the origin. In the particular example, under rotation of x-y coordinate system, the above formula for gradient fails to transform like a vector (gradient becomes dependent on choice of basis for coordinate system) and also fails to point towards the steepest ascent in some orientations. For differentiable functions where the formula for gradient holds, it can be shown to always transform as a vector under transformation of the basis so as to always \"point towards the fastest increase\".\nThe gradient is dual to the total derivative \n  \n    \n      \n        d\n        f\n      \n    \n    {\\displaystyle df}\n  : the value of the gradient at a point is a tangent vector \u2013 a vector at each point; while the value of the derivative at a point is a cotangent vector \u2013 a linear functional on vectors. They are related in that the dot product of the gradient of \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   at a point \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   with another tangent vector \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   equals the directional derivative of \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   at \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   of the function along \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n  ; that is, \n  \n    \n      \n        \u2207\n        f\n        (\n        p\n        )\n        \u22c5\n        \n          v\n        \n        =\n        \n          \n            \n              \u2202\n              f\n            \n            \n              \u2202\n              \n                v\n              \n            \n          \n        \n        (\n        p\n        )\n        =\n        d\n        \n          f\n          \n            p\n          \n        \n        (\n        \n          v\n        \n        )\n      \n    \n    {\\textstyle \\nabla f(p)\\cdot \\mathbf {v} ={\\frac {\\partial f}{\\partial \\mathbf {v} }}(p)=df_{p}(\\mathbf {v} )}\n  . \nThe gradient admits multiple generalizations to more general functions on manifolds; see \u00a7 Generalizations."
    }
}